\documentclass[11pt]{article}

    \usepackage[breakable]{tcolorbox}
    \usepackage{parskip} % Stop auto-indenting (to mimic markdown behaviour)
    

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % Keep aspect ratio if custom image width or height is specified
    \setkeys{Gin}{keepaspectratio}
    % Maintain compatibility with old templates. Remove in nbconvert 6.0
    \let\Oldincludegraphics\includegraphics
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionFormat{nocaption}{}
    \captionsetup{format=nocaption,aboveskip=0pt,belowskip=0pt}

    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro

    \usepackage{iftex}
    \ifPDFTeX
        \usepackage[T1]{fontenc}
        \IfFileExists{alphabeta.sty}{
              \usepackage{alphabeta}
          }{
              \usepackage[mathletters]{ucs}
              \usepackage[utf8x]{inputenc}
          }
    \else
        \usepackage{fontspec}
        \usepackage{unicode-math}
    \fi

    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics
                         % to support a larger range
    \makeatletter % fix for old versions of grffile with XeLaTeX
    \@ifpackagelater{grffile}{2019/11/01}
    {
      % Do nothing on new versions
    }
    {
      \def\Gread@@xetex#1{%
        \IfFileExists{"\Gin@base".bb}%
        {\Gread@eps{\Gin@base.bb}}%
        {\Gread@@xetex@aux#1}%
      }
    }
    \makeatother
    \usepackage[Export]{adjustbox} % Used to constrain images to a maximum size
    \adjustboxset{max size={0.9\linewidth}{0.9\paperheight}}

    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    % The default LaTeX title has an obnoxious amount of whitespace. By default,
    % titling removes some of it. It also provides customization options.
    \usepackage{titling}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage{array}     % table support for pandoc >= 2.11.3
    \usepackage{calc}      % table minipage width calculation for pandoc >= 2.11.1
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{soul}      % strikethrough (\st) support for pandoc >= 3.0.0
    \usepackage{mathrsfs}
    

    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % common color for the border for error outputs.
    \definecolor{outerrorbackground}{HTML}{FFDFDF}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}

    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \makeatletter
    \newsavebox\pandoc@box
    \newcommand*\pandocbounded[1]{%
      \sbox\pandoc@box{#1}%
      % scaling factors for width and height
      \Gscale@div\@tempa\textheight{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
      \Gscale@div\@tempb\linewidth{\wd\pandoc@box}%
      % select the smaller of both
      \ifdim\@tempb\p@<\@tempa\p@
        \let\@tempa\@tempb
      \fi
      % scaling accordingly (\@tempa < 1)
      \ifdim\@tempa\p@<\p@
        \scalebox{\@tempa}{\usebox\pandoc@box}%
      % scaling not needed, use as it is
      \else
        \usebox{\pandoc@box}%
      \fi
    }
    \makeatother

    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{PD3-Power\_Plant-MTI850-A24}
    
    
    
    
    
    
    
% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\@namedef{PY@tok@w}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\@namedef{PY@tok@c}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cp}{\def\PY@tc##1{\textcolor[rgb]{0.61,0.40,0.00}{##1}}}
\@namedef{PY@tok@k}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kt}{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\@namedef{PY@tok@o}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ow}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@nb}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nf}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@ne}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.80,0.25,0.22}{##1}}}
\@namedef{PY@tok@nv}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@no}{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\@namedef{PY@tok@nl}{\def\PY@tc##1{\textcolor[rgb]{0.46,0.46,0.00}{##1}}}
\@namedef{PY@tok@ni}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@na}{\def\PY@tc##1{\textcolor[rgb]{0.41,0.47,0.13}{##1}}}
\@namedef{PY@tok@nt}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nd}{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@s}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sd}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@si}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@se}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.36,0.12}{##1}}}
\@namedef{PY@tok@sr}{\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@ss}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sx}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@m}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@gh}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@gu}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\@namedef{PY@tok@gd}{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\@namedef{PY@tok@gi}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.52,0.00}{##1}}}
\@namedef{PY@tok@gr}{\def\PY@tc##1{\textcolor[rgb]{0.89,0.00,0.00}{##1}}}
\@namedef{PY@tok@ge}{\let\PY@it=\textit}
\@namedef{PY@tok@gs}{\let\PY@bf=\textbf}
\@namedef{PY@tok@ges}{\let\PY@bf=\textbf\let\PY@it=\textit}
\@namedef{PY@tok@gp}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@go}{\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@gt}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\@namedef{PY@tok@err}{\def\PY@bc##1{{\setlength{\fboxsep}{\string -\fboxrule}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}}
\@namedef{PY@tok@kc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kd}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kr}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@bp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@fm}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@vc}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vg}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vi}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vm}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sa}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sb}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sc}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@dl}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s2}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sh}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s1}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@mb}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mf}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mh}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mi}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@il}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mo}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ch}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cm}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cpf}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@c1}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cs}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % For linebreaks inside Verbatim environment from package fancyvrb.
    \makeatletter
        \newbox\Wrappedcontinuationbox
        \newbox\Wrappedvisiblespacebox
        \newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}}
        \newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}}
        \newcommand*\Wrappedcontinuationindent {3ex }
        \newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox}
        % Take advantage of the already applied Pygments mark-up to insert
        % potential linebreaks for TeX processing.
        %        {, <, #, %, $, ' and ": go to next line.
        %        _, }, ^, &, >, - and ~: stay at end of broken line.
        % Use of \textquotesingle for straight quote.
        \newcommand*\Wrappedbreaksatspecials {%
            \def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}%
            \def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}%
            \def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}%
            \def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}%
            \def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}%
            \def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}%
            \def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}%
            \def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}%
            \def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}%
            \def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}%
            \def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}%
            \def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}%
            \def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}%
            \def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}%
        }
        % Some characters . , ; ? ! / are not pygmentized.
        % This macro makes them "active" and they will insert potential linebreaks
        \newcommand*\Wrappedbreaksatpunct {%
            \lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}%
            \lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}%
            \lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}%
            \lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}%
            \lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}%
            \lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}%
            \lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}%
            \catcode`\.\active
            \catcode`\,\active
            \catcode`\;\active
            \catcode`\:\active
            \catcode`\?\active
            \catcode`\!\active
            \catcode`\/\active
            \lccode`\~`\~
        }
    \makeatother

    \let\OriginalVerbatim=\Verbatim
    \makeatletter
    \renewcommand{\Verbatim}[1][1]{%
        %\parskip\z@skip
        \sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
        \sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
        \def\FancyVerbFormatLine ##1{\hsize\linewidth
            \vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
                \doublehyphendemerits\z@\finalhyphendemerits\z@
                \strut ##1\strut}%
        }%
        % If the linebreak is at a space, the latter will be displayed as visible
        % space at end of first line, and a continuation symbol starts next line.
        % Stretch/shrink are however usually zero for typewriter font.
        \def\FV@Space {%
            \nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
            \discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
            {\kern\fontdimen2\font}%
        }%

        % Allow breaks at special characters using \PYG... macros.
        \Wrappedbreaksatspecials
        % Breaks at punctuation characters . , ; ? ! and / need catcode=\active
        \OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
    }
    \makeatother

    % Exact colors from NB
    \definecolor{incolor}{HTML}{303F9F}
    \definecolor{outcolor}{HTML}{D84315}
    \definecolor{cellborder}{HTML}{CFCFCF}
    \definecolor{cellbackground}{HTML}{F7F7F7}

    % prompt
    \makeatletter
    \newcommand{\boxspacing}{\kern\kvtcb@left@rule\kern\kvtcb@boxsep}
    \makeatother
    \newcommand{\prompt}[4]{
        {\ttfamily\llap{{\color{#2}[#3]:\hspace{3pt}#4}}\vspace{-\baselineskip}}
    }
    

    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

\begin{document}
    
    \maketitle
    
    

    
    \hypertarget{pd3-power-plant-machine-learning-pipeline-application}{%
\section{PD3: Power Plant Machine Learning Pipeline
Application}\label{pd3-power-plant-machine-learning-pipeline-application}}

\hypertarget{mti850---big-data-analytics}{%
\subsection{MTI850 - Big Data
Analytics}\label{mti850---big-data-analytics}}

\hypertarget{fall-2024}{%
\subsubsection{Fall 2024}\label{fall-2024}}

    \begin{longtable}[]{@{}ll@{}}
\toprule
Equipe & 9 \\
\midrule
\endhead
\bottomrule
\end{longtable}

    \textbf{Background}

Power generation is a complex process, and understanding and predicting
power output is an important element in managing a plant and its
connection to the power grid. The operators of a regional power grid
create predictions of power demand based on historical information and
environmental factors (e.g., temperature). They then compare the
predictions against available resources (e.g., coal, natural gas,
nuclear, solar, wind, hydro power plants).

Power generation technologies such as solar and wind are highly
dependent on environmental conditions, and all generation technologies
are subject to planned and unplanned maintenance. Here is an real-world
example of predicted demand (on two time scales), actual demand, and
available resources from the California power grid:
https://www.caiso.com/todays-outlook

The challenge for a power grid operator is how to handle a shortfall in
available resources versus actual demand. There are three solutions to a
power shortfall: build more base load power plants (this process can
take many years to decades of planning and construction), buy and import
power from other regional power grids (this choice can be very expensive
and is limited by the power transmission interconnects between grids and
the excess power available from other grids), or turn on small
\href{https://en.wikipedia.org/wiki/Peaking_power_plant}{Peaker or
Peaking Power Plants}. Because grid operators need to respond quickly to
a power shortfall to avoid a power outage, grid operators rely on a
combination of the last two choices. In this exercise, we'll focus on
the last choice.

\textbf{The Business Problem}

Because they supply power only occasionally, the power supplied by a
peaker power plant commands a much higher price per kilowatt hour than
power from a power grid's base power plants. A peaker plant may operate
many hours a day, or it may operate only a few hours per year, depending
on the condition of the region's electrical grid. Because of the cost of
building an efficient power plant, if a peaker plant is only going to be
run for a short or highly variable time it does not make economic sense
to make it as efficient as a base load power plant. In addition, the
equipment and fuels used in base load plants are often unsuitable for
use in peaker plants because the fluctuating conditions would severely
strain the equipment.

The power output of a peaker power plant varies depending on
environmental conditions, so the business problem is \emph{predicting
the power output of a peaker power plant as a function of the
environmental conditions} -- since this would enable the grid operator
to make economic tradeoffs about the number of peaker plants to turn on
(or whether to buy expensive power from another grid).

Given this business problem, we need to first perform Exploratory Data
Analysis to understand the data and then translate the business problem
(predicting power output as a function of envionmental conditions) into
a Machine Learning task. In this instance, the ML task is regression
since the label (or target) we are trying to predict is numeric. We will
use an
\href{https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html}{Apache
Spark ML Pipeline} to perform the regression.

The real-world data we are using in this notebook consists of 9,568 data
points, each with 4 environmental attributes collected from a Combined
Cycle Power Plant over 6 years (2006-2011), and is provided by the
University of California, Irvine at
\href{https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant}{UCI
Machine Learning Repository Combined Cycle Power Plant Data Set}. You
can find more details about the dataset on the UCI page, including the
following background publications: * Pinar Tüfekci,
\href{https://www.sciencedirect.com/science/article/abs/pii/S0142061514000908}{Prediction
of full load electrical power output of a base load operated combined
cycle power plant using machine learning methods}, International Journal
of Electrical Power \& Energy Systems, Volume 60, September 2014, Pages
126-140, ISSN 0142-0615. * Heysem Kaya, Pinar Tüfekci and Fikret S.
Gürgen:
\href{https://www.researchgate.net/publication/269108474_Local_and_Global_Learning_Methods_for_Predicting_Power_of_a_Combined_Gas_Steam_Turbine}{Local
and Global Learning Methods for Predicting Power of a Combined Gas \&
Steam Turbine}, Proceedings of the International Conference on Emerging
Trends in Computer and Electronics Engineering ICETCEE 2012, pp.~13-18
(Mar.~2012, Dubai).

This is an end-to-end assignment of performing on a real-world dataset:
* Extract-Transform-Load (ETL), * Exploratory data analysis (EDA), and *
Applying machine learning (ML) algorithms

to solve a supervised regression problem on the dataset.

\textbf{To Do}: Read the documentation and examples for
\href{https://spark.apache.org/docs/latest/ml-pipeline.html}{Spark
Machine Learning Pipeline}.

\textbf{This assignment covers:} * \emph{Part 1: Business Understanding}
* \emph{Part 2: Load Your Data} * \emph{Part 3: Explore Your Data} *
\emph{Part 4: Visualize Your Data} * \emph{Part 5: Data Preparation} *
\emph{Part 6: Data Modeling} * \emph{Part 7: Tuning and Evaluation}

\hypertarget{our-goal-is-to-accurately-predict-power-output-given-a-set-of-environmental-readings-from-various-sensors-in-a-natural-gas-fired-power-generation-plant.}{%
\paragraph{Our goal is to accurately predict power output given a set of
environmental readings from various sensors in a natural gas-fired power
generation
plant.}\label{our-goal-is-to-accurately-predict-power-output-given-a-set-of-environmental-readings-from-various-sensors-in-a-natural-gas-fired-power-generation-plant.}}

    \hypertarget{part-1-business-understanding}{%
\subsection{Part 1: Business
Understanding}\label{part-1-business-understanding}}

The first step in any machine learning task is to understand the
business need. As described in the overview we are trying to predict
power output given a set of readings from various sensors in a gas-fired
power generation plant. The problem is a regression problem since the
label (or target) we are trying to predict is numeric.

    \hypertarget{part-2-extract-transform-load-etl-your-data}{%
\subsection{Part 2: Extract-Transform-Load (ETL) Your
Data}\label{part-2-extract-transform-load-etl-your-data}}

Now that we understand what we are trying to do, the first step is to
load our data into a format we can query and use. This is known as ETL
or ``Extract-Transform-Load''. To download the dataset and put it into
HDFS, run the following commands in a terminal:

\begin{verbatim}
wget https://risk-engineering.org/static/data/CCPP.csv
hdfs dfs -put CCPP.csv /CCPP.csv
\end{verbatim}

Now, let us create the application enviroment, and then load and display
the dataset:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{9}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{findspark}
\PY{n}{findspark}\PY{o}{.}\PY{n}{init}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Test module for MTI850}
\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{testmti850}
\PY{c+c1}{\PYZsh{} Util module for MTI850}
\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{utilmti850}

\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{pyspark}
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{sql}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{SparkSession}

\PY{n}{spark} \PY{o}{=} \PY{n}{SparkSession}\PY{o}{.}\PY{n}{builder} \PYZbs{}
\PY{o}{.}\PY{n}{master}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{local}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)} \PYZbs{}
\PY{o}{.}\PY{n}{appName}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Power Plant Machine Learning Pipeline Application}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)} \PYZbs{}
\PY{o}{.}\PY{n}{config}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{spark.some.config.option}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{some\PYZhy{}value}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)} \PYZbs{}
\PY{o}{.}\PY{n}{getOrCreate}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} load the dataset}
\PY{n}{powerPlantDF} \PY{o}{=} \PY{n}{spark}\PY{o}{.}\PY{n}{read}\PY{o}{.}\PY{n}{csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/home/vboxuser/data/CCPP.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{sep}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{,}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{header}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{inferSchema}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}

\PY{n}{powerPlantDF}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
+-----+-----+-------+-----+------+
|   AT|    V|     AP|   RH|    PE|
+-----+-----+-------+-----+------+
|14.96|41.76|1024.07|73.17|463.26|
|25.18|62.96|1020.04|59.08|444.37|
| 5.11| 39.4|1012.16|92.14|488.56|
|20.86|57.32|1010.24|76.64|446.48|
|10.82| 37.5|1009.23|96.62| 473.9|
|26.27|59.44|1012.23|58.77|443.67|
|15.89|43.96|1014.02|75.24|467.35|
| 9.48|44.71|1019.12|66.43|478.42|
|14.64| 45.0|1021.78|41.25|475.98|
|11.74|43.56|1015.14|70.72| 477.5|
|17.99|43.72|1008.64|75.04|453.02|
|20.14|46.93|1014.66|64.22|453.99|
|24.34| 73.5|1011.31|84.15|440.29|
|25.71|58.59|1012.77|61.83|451.28|
|26.19|69.34|1009.48|87.59|433.99|
|21.42|43.79|1015.76|43.08|462.19|
|18.21| 45.0|1022.86|48.84|467.54|
|11.04|41.74| 1022.6|77.51| 477.2|
|14.45|52.75|1023.97|63.59|459.85|
|13.97|38.47|1015.15|55.28| 464.3|
+-----+-----+-------+-----+------+
only showing top 20 rows
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{10}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{powerPlantDF}\PY{o}{.}\PY{n}{printSchema}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
root
 |-- AT: double (nullable = true)
 |-- V: double (nullable = true)
 |-- AP: double (nullable = true)
 |-- RH: double (nullable = true)
 |-- PE: double (nullable = true)

    \end{Verbatim}

    From our initial exploration of a sample of the data, we can make
several observations for the ETL process: - The data is .csv (Comma
Seperated Values) file (i.e., each row of the data is separated using
commas) - There is a header row, which is the name of the columns - It
looks like the type of the data in each column is consistent (i.e., each
column is of type double)

Our schema definition from UCI appears below: - AT = Atmospheric
Temperature in C - V = Exhaust Vacuum Speed - AP = Atmospheric Pressure
- RH = Relative Humidity - PE = Power Output. This is the value we are
trying to predict given the measurements above.

The following three options were used as loading the dataset: -
\texttt{sep=\textquotesingle{},\textquotesingle{}} because our data is
comma delimited -
\texttt{header=\textquotesingle{}true\textquotesingle{}} because our
data has a header row -
\texttt{inferSchema=\textquotesingle{}true\textquotesingle{}} because we
believe that all of the data is double values, so the package can
dynamically infer the type of each column. \emph{Note that this will
require two pass over the data.}

The next nell tests whether the schema is correct, i.e., whether all the
columns are double valued.

    Check the names and types of the columns using the
\href{https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.dtypes.html?highlight=dtypes\#pyspark.sql.DataFrame.dtypes}{dtypes}
method.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{11}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{powerPlantDF}\PY{o}{.}\PY{n}{dtypes}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{11}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
[('AT', 'double'),
 ('V', 'double'),
 ('AP', 'double'),
 ('RH', 'double'),
 ('PE', 'double')]
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{12}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} TEST}
\PY{n}{column\PYZus{}types\PYZus{}expected} \PY{o}{=} \PY{n+nb}{set}\PY{p}{(}\PY{p}{[}\PY{p}{(}\PY{n}{s}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{double}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{for} \PY{n}{s} \PY{o+ow}{in} \PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{AP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{AT}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{PE}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{V}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{]}\PY{p}{)}
\PY{n}{testmti850}\PY{o}{.}\PY{n}{Test}\PY{o}{.}\PY{n}{assertEquals}\PY{p}{(}\PY{n}{column\PYZus{}types\PYZus{}expected}\PY{p}{,} \PY{n+nb}{set}\PY{p}{(}\PY{n}{powerPlantDF}\PY{o}{.}\PY{n}{dtypes}\PY{p}{)}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Incorrect schema for powerPlantDF}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
1 test passed.
    \end{Verbatim}

    We can examine the data by converting part of powerPlantDF into a
{[}Pandas{]}
(https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)
dataframe and using the \texttt{head()} method.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{13}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{powerPlantDF}\PY{o}{.}\PY{n}{limit}\PY{p}{(}\PY{l+m+mi}{20}\PY{p}{)}\PY{o}{.}\PY{n}{toPandas}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{13}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
      AT      V       AP     RH      PE
0  14.96  41.76  1024.07  73.17  463.26
1  25.18  62.96  1020.04  59.08  444.37
2   5.11  39.40  1012.16  92.14  488.56
3  20.86  57.32  1010.24  76.64  446.48
4  10.82  37.50  1009.23  96.62  473.90
\end{Verbatim}
\end{tcolorbox}
        
    \hypertarget{part-2-alternative-method-to-load-your-data}{%
\subsubsection{Part 2: Alternative Method to Load your
Data}\label{part-2-alternative-method-to-load-your-data}}

Instead of inferring the types of the columns, we can specify the schema
as a
\href{https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.types.DataType.html?highlight=datatypes}{DataType},
which is a list of
\href{https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.types.StructField.html?highlight=structfield}{StructField}.

You can find a list of types in the
\href{https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/data_types.html}{pyspark.sql.types}
module. For our data, we will use
\href{https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.types.DoubleType.html}{DoubleType()}.

For example, to specify that a column's name and type, we use:
\texttt{StructField(}\emph{name}\texttt{,} \emph{type}\texttt{,\ True)}.
(The third parameter, \texttt{True}, signifies that the column is
nullable.)

\hypertarget{exercise-2a}{%
\subsubsection{Exercise 2(a)}\label{exercise-2a}}

Create a custom schema for the power plant data.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{14}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} TO DO: Fill in the custom schema.}
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{sql}\PY{n+nn}{.}\PY{n+nn}{types}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{StructType}\PY{p}{,} \PY{n}{StructField}\PY{p}{,} \PY{n}{DoubleType}

\PY{c+c1}{\PYZsh{} Custom Schema for Power Plant}
\PY{n}{customSchema} \PY{o}{=} \PY{n}{StructType}\PY{p}{(}\PY{p}{[} \PYZbs{}
    \PY{n}{StructField}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AT}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{DoubleType}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{k+kc}{True}\PY{p}{)}\PY{p}{,}\PYZbs{}
    \PY{n}{StructField}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{V}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{DoubleType}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{k+kc}{True}\PY{p}{)}\PY{p}{,}\PYZbs{}
    \PY{n}{StructField}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{DoubleType}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{k+kc}{True}\PY{p}{)}\PY{p}{,} \PYZbs{}
    \PY{n}{StructField}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{RH}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{DoubleType}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{k+kc}{True}\PY{p}{)}\PY{p}{,} \PYZbs{}
    \PY{n}{StructField}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{PE}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{DoubleType}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{k+kc}{True}\PY{p}{)} \PYZbs{}
                          \PY{p}{]}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{15}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} TEST}
\PY{n}{testmti850}\PY{o}{.}\PY{n}{Test}\PY{o}{.}\PY{n}{assertEquals}\PY{p}{(}\PY{n+nb}{set}\PY{p}{(}\PY{p}{[}\PY{n}{f}\PY{o}{.}\PY{n}{name} \PY{k}{for} \PY{n}{f} \PY{o+ow}{in} \PY{n}{customSchema}\PY{o}{.}\PY{n}{fields}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{n+nb}{set}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{AT}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{V}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{AP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{PE}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Incorrect column names in schema.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{testmti850}\PY{o}{.}\PY{n}{Test}\PY{o}{.}\PY{n}{assertEquals}\PY{p}{(}\PY{n+nb}{set}\PY{p}{(}\PY{p}{[}\PY{n}{f}\PY{o}{.}\PY{n}{dataType} \PY{k}{for} \PY{n}{f} \PY{o+ow}{in} \PY{n}{customSchema}\PY{o}{.}\PY{n}{fields}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{n+nb}{set}\PY{p}{(}\PY{p}{[}\PY{n}{DoubleType}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{DoubleType}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{DoubleType}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{DoubleType}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{DoubleType}\PY{p}{(}\PY{p}{)}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Incorrect column types in schema.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
1 test passed.
1 test passed.
    \end{Verbatim}

    \hypertarget{exercise-2b}{%
\subsubsection{Exercise 2(b)}\label{exercise-2b}}

Now, let's use the schema to read the data. To do this, we will modify
the earlier \texttt{spark.read.format} step. We can specify the schema
by: - Adding \texttt{schema\ =\ customSchema} to the load method (use a
comma and add it after the file name) - Removing the
\texttt{inferschema=\textquotesingle{}true\textquotesingle{}}option
because we are explicitly specifying the schema

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{19}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} TODO: Use the schema you created above to load the data again.}
\PY{n}{altPowerPlantDF} \PY{o}{=} \PY{n}{spark}\PY{o}{.}\PY{n}{read}\PY{o}{.}\PY{n}{csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/home/vboxuser/data/CCPP.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{sep}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{,}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{header}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{schema} \PY{o}{=} \PY{n}{customSchema}\PY{p}{)}

\PY{n}{altPowerPlantDF}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
+-----+-----+-------+-----+------+
|   AT|    V|     AP|   RH|    PE|
+-----+-----+-------+-----+------+
|14.96|41.76|1024.07|73.17|463.26|
|25.18|62.96|1020.04|59.08|444.37|
| 5.11| 39.4|1012.16|92.14|488.56|
|20.86|57.32|1010.24|76.64|446.48|
|10.82| 37.5|1009.23|96.62| 473.9|
|26.27|59.44|1012.23|58.77|443.67|
|15.89|43.96|1014.02|75.24|467.35|
| 9.48|44.71|1019.12|66.43|478.42|
|14.64| 45.0|1021.78|41.25|475.98|
|11.74|43.56|1015.14|70.72| 477.5|
|17.99|43.72|1008.64|75.04|453.02|
|20.14|46.93|1014.66|64.22|453.99|
|24.34| 73.5|1011.31|84.15|440.29|
|25.71|58.59|1012.77|61.83|451.28|
|26.19|69.34|1009.48|87.59|433.99|
|21.42|43.79|1015.76|43.08|462.19|
|18.21| 45.0|1022.86|48.84|467.54|
|11.04|41.74| 1022.6|77.51| 477.2|
|14.45|52.75|1023.97|63.59|459.85|
|13.97|38.47|1015.15|55.28| 464.3|
+-----+-----+-------+-----+------+
only showing top 20 rows
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{20}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} TEST}
\PY{n}{expected} \PY{o}{=} \PY{n+nb}{set}\PY{p}{(}\PY{p}{[}\PY{p}{(}\PY{n}{s}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{double}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{for} \PY{n}{s} \PY{o+ow}{in} \PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{AP}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{AT}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{PE}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{V}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{]}\PY{p}{)}
\PY{n}{testmti850}\PY{o}{.}\PY{n}{Test}\PY{o}{.}\PY{n}{assertEquals}\PY{p}{(}\PY{n}{expected}\PY{p}{,} \PY{n+nb}{set}\PY{p}{(}\PY{n}{altPowerPlantDF}\PY{o}{.}\PY{n}{dtypes}\PY{p}{)}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Incorrect schema for powerPlantDF}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
1 test passed.
    \end{Verbatim}

    \textbf{Note that no Spark jobs are launched this time} That is because
we specified the schema, so Spark does not have to read the data to
infer the schema. We can use the
\href{https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.dtypes.html?highlight=dtypes\#pyspark.sql.DataFrame.dtypes}{dtypes}
method (implemented as \texttt{property}) to examine the names and types
of the columns. They should be identical to the names and types of the
columns that were earlier inferred from the data.

When you run the following cell, data would not be read.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{21}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{altPowerPlantDF}\PY{o}{.}\PY{n}{dtypes}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{21}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
[('AT', 'double'),
 ('V', 'double'),
 ('AP', 'double'),
 ('RH', 'double'),
 ('PE', 'double')]
\end{Verbatim}
\end{tcolorbox}
        
    Now we can examine the data using the show() method. \emph{Note that
this operation will cause the data to be read and the DataFrame will be
created.}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{22}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{altPowerPlantDF}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
+-----+-----+-------+-----+------+
|   AT|    V|     AP|   RH|    PE|
+-----+-----+-------+-----+------+
|14.96|41.76|1024.07|73.17|463.26|
|25.18|62.96|1020.04|59.08|444.37|
| 5.11| 39.4|1012.16|92.14|488.56|
|20.86|57.32|1010.24|76.64|446.48|
|10.82| 37.5|1009.23|96.62| 473.9|
|26.27|59.44|1012.23|58.77|443.67|
|15.89|43.96|1014.02|75.24|467.35|
| 9.48|44.71|1019.12|66.43|478.42|
|14.64| 45.0|1021.78|41.25|475.98|
|11.74|43.56|1015.14|70.72| 477.5|
|17.99|43.72|1008.64|75.04|453.02|
|20.14|46.93|1014.66|64.22|453.99|
|24.34| 73.5|1011.31|84.15|440.29|
|25.71|58.59|1012.77|61.83|451.28|
|26.19|69.34|1009.48|87.59|433.99|
|21.42|43.79|1015.76|43.08|462.19|
|18.21| 45.0|1022.86|48.84|467.54|
|11.04|41.74| 1022.6|77.51| 477.2|
|14.45|52.75|1023.97|63.59|459.85|
|13.97|38.47|1015.15|55.28| 464.3|
+-----+-----+-------+-----+------+
only showing top 20 rows
    \end{Verbatim}

    \hypertarget{part-3-explore-your-data}{%
\subsection{Part 3: Explore Your Data}\label{part-3-explore-your-data}}

Now that your data is loaded, the next step is to explore it and perform
some basic analysis and visualizations.

This is a step that you should always perform \textbf{before} trying to
fit a model to the data, as this step will often lead to important
insights about your data.

    First, let's learn how to run SQL Queries programmatically and return
the results as \texttt{DataFrame}. To this purpose, we can register our
DataFrame as a temporary SQL virtual table (view) named
\texttt{power\_plant} using the
\href{https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.createOrReplaceTempView.html?highlight=createorreplacetempview\#pyspark.sql.DataFrame.createOrReplaceTempView}{createOrReplaceTempView()}.

\hypertarget{a-execute-the-prepared-code-in-the-following-cell.}{%
\subsubsection{3(a) Execute the prepared code in the following
cell.}\label{a-execute-the-prepared-code-in-the-following-cell.}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{25}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{powerPlantDF}\PY{o}{.}\PY{n}{createOrReplaceTempView}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{power\PYZus{}plant}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \textbf{PS}: Notice that if there was table with the same name it would
be replaced by calling the \texttt{createOrReplaceTempView()} method.

    Now that our DataFrame exists as a SQL table, we can explore it using
SQL commands using the
\href{https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.sparkSession.html?highlight=sparksession\#pyspark.sql.DataFrame.sparkSession}{spark.sql()}
method.

\hypertarget{b-execute-the-prepared-code-in-the-following-cell.}{%
\subsubsection{3(b) Execute the prepared code in the following
cell.}\label{b-execute-the-prepared-code-in-the-following-cell.}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{26}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{sqlDF} \PY{o}{=} \PY{n}{spark}\PY{o}{.}\PY{n}{sql}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{SELECT * FROM power\PYZus{}plant}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)} \PY{c+c1}{\PYZsh{} equivalent to powerPlantDF.select(\PYZdq{}*\PYZdq{})}
\PY{n}{sqlDF}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
+-----+-----+-------+-----+------+
|   AT|    V|     AP|   RH|    PE|
+-----+-----+-------+-----+------+
|14.96|41.76|1024.07|73.17|463.26|
|25.18|62.96|1020.04|59.08|444.37|
| 5.11| 39.4|1012.16|92.14|488.56|
|20.86|57.32|1010.24|76.64|446.48|
|10.82| 37.5|1009.23|96.62| 473.9|
|26.27|59.44|1012.23|58.77|443.67|
|15.89|43.96|1014.02|75.24|467.35|
| 9.48|44.71|1019.12|66.43|478.42|
|14.64| 45.0|1021.78|41.25|475.98|
|11.74|43.56|1015.14|70.72| 477.5|
|17.99|43.72|1008.64|75.04|453.02|
|20.14|46.93|1014.66|64.22|453.99|
|24.34| 73.5|1011.31|84.15|440.29|
|25.71|58.59|1012.77|61.83|451.28|
|26.19|69.34|1009.48|87.59|433.99|
|21.42|43.79|1015.76|43.08|462.19|
|18.21| 45.0|1022.86|48.84|467.54|
|11.04|41.74| 1022.6|77.51| 477.2|
|14.45|52.75|1023.97|63.59|459.85|
|13.97|38.47|1015.15|55.28| 464.3|
+-----+-----+-------+-----+------+
only showing top 20 rows
    \end{Verbatim}

    \hypertarget{c-use-the-sql-desc-command-to-describe-the-schema.}{%
\subsubsection{\texorpdfstring{3(c) Use the SQL \texttt{desc} command to
describe the
schema.}{3(c) Use the SQL desc command to describe the schema.}}\label{c-use-the-sql-desc-command-to-describe-the-schema.}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{27}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{spark}\PY{o}{.}\PY{n}{sql}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{desc power\PYZus{}plant}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{27}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
DataFrame[col\_name: string, data\_type: string, comment: string]
\end{Verbatim}
\end{tcolorbox}
        
    \textbf{Schema Definition}

Once again, here's our schema definition:

\begin{itemize}
\tightlist
\item
  AT = Atmospheric Temperature in C
\item
  V = Exhaust Vacuum Speed
\item
  AP = Atmospheric Pressure
\item
  RH = Relative Humidity
\item
  PE = Power Output
\end{itemize}

PE is our label or target. This is the value we are trying to predict
given the measurements AT, V, AP and RH.

\emph{Reference
\href{https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant}{UCI
Machine Learning Repository Combined Cycle Power Plant Data Set}}

    Let's perform some basic statistical analyses of all the columns.

We can get the DataFrame associated with a SQL table by using the
\href{https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.table.html?highlight=sparksession\%20table\#pyspark.sql.SparkSession.table}{spark.table()}
method and passing in the name of the SQL table. Then, we can use the
DataFrame
\href{https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.describe.html?highlight=describe\#pyspark.sql.DataFrame.describe}{describe()}
method with no arguments to compute some basic statistics for each
column like count, mean, max, min and standard deviation.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{28}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{df} \PY{o}{=} \PY{n}{spark}\PY{o}{.}\PY{n}{table}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{power\PYZus{}plant}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{df}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
25/10/06 20:40:47 WARN SparkStringUtils: Truncated the string representation of
a plan since it was too large. This behavior can be adjusted by setting
'spark.sql.debug.maxToStringFields'.
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
+-------+------------------+------------------+------------------+--------------
----+------------------+
|summary|                AT|                 V|                AP|
RH|                PE|
+-------+------------------+------------------+------------------+--------------
----+------------------+
|  count|              9568|              9568|              9568|
9568|              9568|
|   mean| 19.65123118729102| 54.30580372073601|1013.2590781772603|
73.30897784280926| 454.3650094063554|
| stddev|7.4524732296110825|12.707892998326784|
5.938783705811581|14.600268756728964|17.066994999803402|
|    min|              1.81|             25.36|            992.89|
25.56|            420.26|
|    max|             37.11|             81.56|            1033.3|
100.16|            495.76|
+-------+------------------+------------------+------------------+--------------
----+------------------+

    \end{Verbatim}

    \hypertarget{part-4-visualize-your-data}{%
\subsection{Part 4: Visualize Your
Data}\label{part-4-visualize-your-data}}

To understand our data, we will look for correlations between features
and the label. This can be important when choosing a model. E.g., if
features and a label are linearly correlated, a linear model like Linear
Regression can do well; if the relationship is very non-linear, more
complex models such as Decision Trees can be better. In the next cell,
we use SQL to extract and show a DataFrame with the Temperature and
Power Output columns.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{29}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{sqlDF} \PY{o}{=} \PY{n}{spark}\PY{o}{.}\PY{n}{sql}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{select AT as Temperature, PE as Power from power\PYZus{}plant}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{sqlDF}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
+-----------+------+
|Temperature| Power|
+-----------+------+
|      14.96|463.26|
|      25.18|444.37|
|       5.11|488.56|
|      20.86|446.48|
|      10.82| 473.9|
|      26.27|443.67|
|      15.89|467.35|
|       9.48|478.42|
|      14.64|475.98|
|      11.74| 477.5|
|      17.99|453.02|
|      20.14|453.99|
|      24.34|440.29|
|      25.71|451.28|
|      26.19|433.99|
|      21.42|462.19|
|      18.21|467.54|
|      11.04| 477.2|
|      14.45|459.85|
|      13.97| 464.3|
+-----------+------+
only showing top 20 rows
    \end{Verbatim}

    Notice that we are visualizing only 20 of the 9568 rows, thus little
insigth can be gained from displaying the DataFrame.

    \hypertarget{exercise-4a}{%
\subsubsection{Exercise 4(a)}\label{exercise-4a}}

Let's see if there is a corellation between Temperature and Power
Output. We can use the \texttt{sqlDF} DataFrame to build a
\href{https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.scatter.html}{scatter
plot} with Temperature on the X axis and Power on the Y axis to
visualize the relationship (if any) between Temperature and Power.

To do this, complete the code in the cell so that:

\begin{itemize}
\tightlist
\item
  The scatter plot shows red points with markersize 1
\item
  The title of the chart is `Correlation between Power and Temperature'
\item
  The X axis is labeled as `Temperature' and its markers are
  \(0, 5, 10, \ldots, 40\)
\item
  The Y axis is labeled as `Power' and its markers are
  \(410, 420, 430, \ldots, 500\)
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{33}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} TODO: Replace \PYZlt{}FILL IN\PYZgt{} with appropriate code}
\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{numpy}\PY{+w}{ }\PY{k}{as}\PY{+w}{ }\PY{n+nn}{np}
\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot}\PY{+w}{ }\PY{k}{as}\PY{+w}{ }\PY{n+nn}{plt}

\PY{n}{data} \PY{o}{=} \PY{n}{sqlDF}\PY{o}{.}\PY{n}{collect}\PY{p}{(}\PY{p}{)}

\PY{n}{x}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{n+nb}{zip}\PY{p}{(}\PY{o}{*}\PY{n}{data}\PY{p}{)} \PY{c+c1}{\PYZsh{} split Temperature (x) and Power (y)}

\PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{nrows}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{ncols}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{x}\PY{p}{,}\PY{n}{y}\PY{p}{,}\PY{n}{color} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{red}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{s}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)} \PY{c+c1}{\PYZsh{} scatter plot command}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Correlation between Power and Temperature}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}  \PY{c+c1}{\PYZsh{} title}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Temperature}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)} \PY{c+c1}{\PYZsh{} xlabel}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Power}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)} \PY{c+c1}{\PYZsh{} ylabel}
\PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{45}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{)}\PY{p}{)}  \PY{c+c1}{\PYZsh{} xticks}
\PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{410}\PY{p}{,} \PY{l+m+mi}{505}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{)}\PY{p}{)} \PY{c+c1}{\PYZsh{} yticks}

\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_38_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    It looks like there is strong linear correlation between Temperature and
Power Output.

\textbf{ASIDE: A quick physics lesson}: This correlation is to be
expected as the second law of thermodynamics puts a fundamental limit on
the \href{https://en.wikipedia.org/wiki/Thermal_efficiency}{thermal
efficiency} of all heat-based engines. The limiting factors are: - The
temperature at which the heat enters the engine \textbackslash( T\_\{H\}
\textbackslash) - The temperature of the environment into which the
engine exhausts its waste heat \textbackslash( T\_C \textbackslash)

Our temperature measurements are the temperature of the environment.
From
\href{https://en.wikipedia.org/wiki/Carnot\%27s_theorem_\%28thermodynamics\%29}{Carnot's
theorem}, no heat engine working between these two temperatures can
exceed the Carnot Cycle efficiency: \textbackslash{[} n\_\{th\} \le 1 -
\frac{T_C}{T_H} \textbackslash{]}

Note that as the environmental temperature increases, the efficiency
decreases -- \emph{this is the effect that we see in the above graph.}

    \hypertarget{exercise-4b}{%
\subsubsection{Exercise 4(b)}\label{exercise-4b}}

Use SQL to create a scatter plot of Power (PE) as a function of
ExhaustVacuum (V). Name the y-axis ``Power'' and the x-axis
``ExhaustVacuum''

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{36}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} TODO: Replace \PYZlt{}FILL IN\PYZgt{} with appropriate code}

\PY{n}{data} \PY{o}{=} \PY{n}{spark}\PY{o}{.}\PY{n}{sql}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{select V as ExhaustVacuum, PE as Power from power\PYZus{}plant}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{collect}\PY{p}{(}\PY{p}{)}

\PY{n}{x}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{n+nb}{zip}\PY{p}{(}\PY{o}{*}\PY{n}{data}\PY{p}{)} \PY{c+c1}{\PYZsh{} split ExhaustVacuum (x) and Power (y)}

\PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{nrows}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{ncols}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{x}\PY{p}{,}\PY{n}{y}\PY{p}{,}\PY{n}{color} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{red}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{s}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)} \PY{c+c1}{\PYZsh{} scatter plot command}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Power (PE) as a function of ExhaustVacuum (V)}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)} \PY{c+c1}{\PYZsh{} title}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ExhaustVacuum}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)} \PY{c+c1}{\PYZsh{} xlabel}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Power}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)} \PY{c+c1}{\PYZsh{} ylabel}

\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_41_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Let's continue exploring the relationships (if any) between the
variables and Power Output.

\hypertarget{exercise-4c}{%
\subsubsection{Exercise 4(c)}\label{exercise-4c}}

Use SQL to create two side-by-side scatter plots: - Power(PE) as a
function of Pressure (AP) - Power(PE) as a function of Humidity (RH)
Name the y-axis ``Power'' and the x-axis with the respective label
(``Pressure'' or ``Humidity'')

    Let's take a look at some of the data.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{38}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} TODO: Replace \PYZlt{}FILL IN\PYZgt{} with appropriate code}

\PY{n}{data} \PY{o}{=} \PY{n}{spark}\PY{o}{.}\PY{n}{sql}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{select AP as Pressure, RH as Humidity, PE as Power from power\PYZus{}plant}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{collect}\PY{p}{(}\PY{p}{)} \PY{c+c1}{\PYZsh{} select Pressure, Humidity, and Power in a single query}

\PY{n}{x1}\PY{p}{,} \PY{n}{x2}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{n+nb}{zip}\PY{p}{(}\PY{o}{*}\PY{n}{data}\PY{p}{)} \PY{c+c1}{\PYZsh{} split Pressure (x1), Humidity (x2) and Power (y)}

\PY{n}{fig}\PY{p}{,} \PY{n}{axes} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{nrows}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{ncols}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{)}\PY{p}{,} \PY{n}{sharey}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)} \PY{c+c1}{\PYZsh{} two\PYZhy{}column chart (side\PYZhy{}by\PYZhy{}side) }

\PY{c+c1}{\PYZsh{} left chart (axes[0])}
\PY{n}{axes}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{x1}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{red}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{s}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)} \PY{c+c1}{\PYZsh{} scatter plot command}
\PY{n}{axes}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Pressure}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{c+c1}{\PYZsh{} xlabel}
\PY{n}{axes}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Power}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{c+c1}{\PYZsh{} ylabel (you only need to set the ylabel for axes[0])}

\PY{c+c1}{\PYZsh{} left chart (axes[1])}
\PY{n}{axes}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{x2}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{red}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{s}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)} \PY{c+c1}{\PYZsh{} scatter plot command}
\PY{n}{axes}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Humidity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{c+c1}{\PYZsh{} xlabel}

\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_44_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \hypertarget{part-5-data-preparation}{%
\subsection{Part 5: Data Preparation}\label{part-5-data-preparation}}

The next step is to prepare the data for machine learning. Since all of
this data is numeric and consistent this is a simple and straightforward
task.

The goal is to use machine learning to determine a function that yields
the output power as a function of a set of predictor features. The first
step in building our ML pipeline is to convert the predictor features
from DataFrame columns to Feature Vectors using the
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.VectorAssembler.html?highlight=vectorassembler\#pyspark.ml.feature.VectorAssembler}{pyspark.ml.feature.VectorAssembler()}
method.

The \texttt{VectorAssembler} is a transformer that combines a given list
of columns into a single vector column. It is useful for combining raw
features and features generated by different feature transformers into a
single feature vector, in order to train ML models like logistic
regression and decision trees. \texttt{VectorAssembler} takes a list of
input column names (each is a string) and the name of the output column
(as a string).

\hypertarget{exercise-5a}{%
\subsubsection{Exercise 5(a)}\label{exercise-5a}}

\begin{itemize}
\tightlist
\item
  Read the Spark documentation and useage examples for
  \href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.VectorAssembler.html?highlight=vectorassembler\#pyspark.ml.feature.VectorAssembler}{VectorAssembler}
\item
  Convert the \texttt{power\_plant} SQL table into a DataFrame named
  \texttt{dataset}
\item
  Set the vectorizer's input columns to a list of the four columns of
  the input DataFrame: \texttt{{[}"AT",\ "V",\ "AP",\ "RH"{]}}
\item
  Set the vectorizer's output column name to \texttt{"features"}
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{42}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} TODO: Replace \PYZlt{}FILL\PYZus{}IN\PYZgt{} with the appropriate code}
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{feature}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{VectorAssembler}

\PY{n}{datasetDF} \PY{o}{=} \PY{n}{spark}\PY{o}{.}\PY{n}{sql}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{select * from power\PYZus{}plant}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{n}{vectorizer} \PY{o}{=} \PY{n}{VectorAssembler}\PY{p}{(}\PY{p}{)}

\PY{n}{vectorizer}\PY{o}{.}\PY{n}{setInputCols}\PY{p}{(}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AT}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{V}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{RH}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
\PY{n}{vectorizer}\PY{o}{.}\PY{n}{setOutputCol}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{features}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{42}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
VectorAssembler\_475e1dce67f8
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{40}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} TEST}
\PY{n}{testmti850}\PY{o}{.}\PY{n}{Test}\PY{o}{.}\PY{n}{assertEquals}\PY{p}{(}\PY{n+nb}{set}\PY{p}{(}\PY{n}{vectorizer}\PY{o}{.}\PY{n}{getInputCols}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{p}{\PYZob{}}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AT}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{V}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{RH}\PY{l+s+s2}{\PYZdq{}}\PY{p}{\PYZcb{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Incorrect vectorizer input columns}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{testmti850}\PY{o}{.}\PY{n}{Test}\PY{o}{.}\PY{n}{assertEquals}\PY{p}{(}\PY{n}{vectorizer}\PY{o}{.}\PY{n}{getOutputCol}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{features}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Incorrect vectorizer output column}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
1 test passed.
1 test passed.
    \end{Verbatim}

    \hypertarget{part-6-data-modeling}{%
\subsection{Part 6: Data Modeling}\label{part-6-data-modeling}}

Now let's model our data to predict what the power output will be given
a set of sensor readings

Our first model will be based on simple linear regression since we saw
some linear patterns in our data based on the scatter plots during the
exploration stage.

We need a way of evaluating how well our linear regression model
predicts power output as a function of input parameters. We can do this
by splitting up our initial data set into a \emph{Training Set} used to
train our model and a \emph{Test Set} used to evaluate the model's
performance in giving predictions.

We can use a DataFrame's
\href{https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.randomSplit.html?highlight=randomsplit\#pyspark.sql.DataFrame.randomSplit}{randomSplit()}
method to split our dataset. The method takes a list of weights and an
optional random seed. The seed is used to initialize the random number
generator used by the splitting function.

\hypertarget{exercise-6a}{%
\subsubsection{Exercise 6(a)}\label{exercise-6a}}

Use the
\href{https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.randomSplit.html?highlight=randomsplit\#pyspark.sql.DataFrame.randomSplit}{randomSplit()}
method to divide up \texttt{datasetDF} into a trainingSetDF (80\% of the
input DataFrame) and a testSetDF (20\% of the input DataFrame), and for
reproducibility, use the seed 1800009193.

Then cache each DataFrame in memory to maximize performance.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{43}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} TODO: Replace \PYZlt{}FILL\PYZus{}IN\PYZgt{} with the appropriate code.}
\PY{c+c1}{\PYZsh{} We\PYZsq{}ll hold out 20\PYZpc{} of our data for testing and leave 80\PYZpc{} for training}
\PY{n}{seed} \PY{o}{=} \PY{l+m+mi}{1800009193}

\PY{p}{(}\PY{n}{split20DF}\PY{p}{,} \PY{n}{split80DF}\PY{p}{)} \PY{o}{=} \PY{n}{datasetDF}\PY{o}{.}\PY{n}{randomSplit}\PY{p}{(}\PY{p}{[}\PY{l+m+mf}{0.2}\PY{p}{,} \PY{l+m+mf}{0.8}\PY{p}{]}\PY{p}{,} \PY{n}{seed}\PY{o}{=}\PY{n}{seed}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Let\PYZsq{}s cache these datasets for performance}
\PY{n}{testSetDF} \PY{o}{=} \PY{n}{split20DF}
\PY{n}{trainingSetDF} \PY{o}{=} \PY{n}{split80DF}

\PY{n}{trainingSetDF}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
+----+-----+-------+-----+------+
|  AT|    V|     AP|   RH|    PE|
+----+-----+-------+-----+------+
|1.81|39.42|1026.92|76.97|490.55|
|2.58|39.42|1028.68|69.03|488.69|
|2.64|39.64|1011.02|85.24|481.29|
|2.71|39.42|1026.66|81.11| 489.3|
| 3.0|39.64| 1011.0|80.14| 485.2|
| 3.2|41.31| 997.67|98.84|489.86|
|3.21|38.44| 1016.9|86.34|491.35|
|3.21|38.44|1017.11|84.86|492.93|
|3.26|41.31| 996.32|100.0|489.38|
|3.31|39.42|1024.05|84.31|487.19|
|3.38|39.64| 1011.0|81.22|488.92|
|3.38|41.31| 998.79|97.76|489.11|
| 3.4|39.64| 1011.1|83.43|459.86|
|3.51|35.47|1017.53|86.56|489.07|
| 3.6|35.19|1018.73| 99.1|488.98|
|3.63|38.44|1016.16|87.38|487.87|
|3.68|39.64|1011.31|84.05|490.02|
|3.69|38.44|1016.74|82.87|490.78|
|3.73|39.42| 1024.4|82.42|488.58|
|3.74|35.19|1018.58|98.84| 490.5|
+----+-----+-------+-----+------+
only showing top 20 rows
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{44}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} TEST}
\PY{n}{testmti850}\PY{o}{.}\PY{n}{Test}\PY{o}{.}\PY{n}{assertEquals}\PY{p}{(}\PY{n}{trainingSetDF}\PY{o}{.}\PY{n}{count}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{l+m+mi}{7712}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Incorrect size for training data set}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{testmti850}\PY{o}{.}\PY{n}{Test}\PY{o}{.}\PY{n}{assertEquals}\PY{p}{(}\PY{n}{testSetDF}\PY{o}{.}\PY{n}{count}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{l+m+mi}{1856}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Incorrect size for test data set}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
1 test passed.
1 test passed.
    \end{Verbatim}

    Next we'll create a Linear Regression Model and use the built in help to
identify how to train it. See API details for
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.LinearRegression.html?highlight=linearregression\#pyspark.ml.regression.LinearRegression}{Linear
Regression} in the ML guide.

\hypertarget{exercise-6b}{%
\subsubsection{Exercise 6(b)}\label{exercise-6b}}

\begin{itemize}
\tightlist
\item
  Read the documentation and examples for
  \href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.LinearRegression.html?highlight=linearregression\#pyspark.ml.regression.LinearRegression}{Linear
  Regression}
\item
  Run the next cell
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{45}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} LINEAR REGRESSION MODEL}

\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{regression}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{LinearRegression}
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{regression}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{LinearRegressionModel}
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{Pipeline}

\PY{c+c1}{\PYZsh{} Let\PYZsq{}s initialize our linear regression learner}
\PY{n}{lr} \PY{o}{=} \PY{n}{LinearRegression}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} We use explain params to dump the parameters we can use}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{lr}\PY{o}{.}\PY{n}{explainParams}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
aggregationDepth: suggested depth for treeAggregate (>= 2). (default: 2)
elasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha =
0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default:
0.0)
epsilon: The shape parameter to control the amount of robustness. Must be > 1.0.
Only valid when loss is huber (default: 1.35)
featuresCol: features column name. (default: features)
fitIntercept: whether to fit an intercept term. (default: True)
labelCol: label column name. (default: label)
loss: The loss function to be optimized. Supported options: squaredError, huber.
(default: squaredError)
maxBlockSizeInMB: maximum memory in MB for stacking input data into blocks. Data
is stacked within partitions. If more than remaining data size in a partition
then it is adjusted to the data size. Default 0.0 represents choosing optimal
value, depends on specific algorithm. Must be >= 0. (default: 0.0)
maxIter: max number of iterations (>= 0). (default: 100)
predictionCol: prediction column name. (default: prediction)
regParam: regularization parameter (>= 0). (default: 0.0)
solver: The solver algorithm for optimization. Supported options: auto, normal,
l-bfgs. (default: auto)
standardization: whether to standardize the training features before fitting the
model. (default: True)
tol: the convergence tolerance for iterative algorithms (>= 0). (default: 1e-06)
weightCol: weight column name. If this is not set or empty, we treat all
instance weights as 1.0. (undefined)
    \end{Verbatim}

    The cell below is based on the
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.LinearRegression.html?highlight=linearregression\#pyspark.ml.regression.LinearRegression}{Spark
ML Pipeline API for Linear Regression}

The first step is to set the parameters for the method: - Set the name
of the prediction column to ``Predicted\_PE'' - Set the name of the
label column to ``PE'' - Set the maximum number of iterations to 100 -
Set the regularization parameter to 0.1

Next, we create the
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.Pipeline.html}{ML
Pipeline} and set the stages to the Vectorizer and Linear Regression
learner we created earlier.

Finally, we create a model by training on \texttt{trainingSetDF}.

\hypertarget{exercise-6c}{%
\subsubsection{Exercise 6(c)}\label{exercise-6c}}

\begin{itemize}
\tightlist
\item
  Read the
  \href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.LinearRegression.html?highlight=linearregression\#pyspark.ml.regression.LinearRegression}{Linear
  Regression} documentation
\item
  Run the next cell, and be sure you understand what's going on.
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{46}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Now we set the parameters for the method}
\PY{n}{lr}\PY{o}{.}\PY{n}{setPredictionCol}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Predicted\PYZus{}PE}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PYZbs{}
  \PY{o}{.}\PY{n}{setLabelCol}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{PE}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PYZbs{}
  \PY{o}{.}\PY{n}{setMaxIter}\PY{p}{(}\PY{l+m+mi}{100}\PY{p}{)}\PYZbs{}
  \PY{o}{.}\PY{n}{setRegParam}\PY{p}{(}\PY{l+m+mf}{0.1}\PY{p}{)}

\PY{c+c1}{\PYZsh{} We will use the new spark.ml pipeline API. If you have worked with scikit\PYZhy{}learn this will be very familiar.}
\PY{n}{lrPipeline} \PY{o}{=} \PY{n}{Pipeline}\PY{p}{(}\PY{p}{)}

\PY{n}{lrPipeline}\PY{o}{.}\PY{n}{setStages}\PY{p}{(}\PY{p}{[}\PY{n}{vectorizer}\PY{p}{,} \PY{n}{lr}\PY{p}{]}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Let\PYZsq{}s first train on the entire dataset to see what we get}
\PY{n}{lrModel} \PY{o}{=} \PY{n}{lrPipeline}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{trainingSetDF}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
25/10/06 21:50:24 WARN InstanceBuilder: Failed to load implementation
from:dev.ludovic.netlib.blas.JNIBLAS
25/10/06 21:50:25 WARN InstanceBuilder: Failed to load implementation
from:dev.ludovic.netlib.lapack.JNILAPACK
    \end{Verbatim}

    From the Wikipedia article on
\href{https://en.wikipedia.org/wiki/Linear_regression}{Linear
Regression}: \textgreater{} In statistics, linear regression is an
approach for modeling the relationship between a scalar dependent
variable \textbackslash( y \textbackslash) and one or more explanatory
variables (or independent variables) denoted
\textbackslash(X\textbackslash). In linear regression, the relationships
are modeled using linear predictor functions whose unknown model
parameters are estimated from the data. Such models are called linear
models.

Linear regression has many practical uses. Most applications fall into
one of the following two broad categories: - If the goal is prediction,
or forecasting, or error reduction, linear regression can be used to fit
a predictive model to an observed data set of
\textbackslash(y\textbackslash) and \textbackslash(X\textbackslash)
values. After developing such a model, if an additional value of
\textbackslash(X\textbackslash) is then given without its accompanying
value of \textbackslash(y\textbackslash), the fitted model can be used
to make a prediction of the value of \textbackslash(y\textbackslash). -
Given a variable \textbackslash(y\textbackslash) and a number of
variables \textbackslash( X\_1 \textbackslash), \ldots, \textbackslash(
X\_p \textbackslash) that may be related to
\textbackslash(y\textbackslash), linear regression analysis can be
applied to quantify the strength of the relationship between
\textbackslash(y\textbackslash) and the \textbackslash(
X\_j\textbackslash), to assess which \textbackslash( X\_j
\textbackslash) may have no relationship with
\textbackslash(y\textbackslash) at all, and to identify which subsets of
the \textbackslash( X\_j \textbackslash) contain redundant information
about \textbackslash(y\textbackslash).

We are interested in both uses, as we would like to predict power output
as a function of the input variables, and we would like to know which
input variables are weakly or strongly correlated with power output.

Since Linear Regression is simply a Line of best fit over the data that
minimizes the square of the error, given multiple input dimensions we
can express each predictor as a line function of the form:

\textbackslash{[} y = a + b x\_1 + b x\_2 + b x\_i \ldots{}
\textbackslash{]}

where \textbackslash(a\textbackslash) is the intercept and the
\textbackslash(b\textbackslash) are the coefficients.

To express the coefficients of that line we can retrieve the Estimator
stage from the PipelineModel and express the weights and the intercept
for the function.

\hypertarget{exercise-6d}{%
\subsubsection{Exercise 6(d)}\label{exercise-6d}}

Run the next cell. Ensure that you understand what's going on.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{50}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} The intercept is as follows:}
\PY{n}{intercept} \PY{o}{=} \PY{n}{lrModel}\PY{o}{.}\PY{n}{stages}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{intercept}

\PY{c+c1}{\PYZsh{} The coefficents (i.e., weights) are as follows:}
\PY{n}{weights} \PY{o}{=} \PY{n}{lrModel}\PY{o}{.}\PY{n}{stages}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{coefficients}

\PY{c+c1}{\PYZsh{} Create a list of the column names (without PE)}
\PY{n}{featuresNoLabel} \PY{o}{=} \PY{p}{[}\PY{n}{col} \PY{k}{for} \PY{n}{col} \PY{o+ow}{in} \PY{n}{datasetDF}\PY{o}{.}\PY{n}{columns} \PY{k}{if} \PY{n}{col} \PY{o}{!=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{PE}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}

\PY{c+c1}{\PYZsh{} Merge the weights and labels}
\PY{n}{coefficents} \PY{o}{=} \PY{n+nb}{zip}\PY{p}{(}\PY{n}{weights}\PY{p}{,} \PY{n}{featuresNoLabel}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Now let\PYZsq{}s sort the coefficients from greatest absolute weight most to the least absolute weight}
\PY{n}{coefficents\PYZus{}sorted} \PY{o}{=} \PY{n+nb}{sorted}\PY{p}{(}\PY{n}{coefficents}\PY{p}{,} \PY{n}{key} \PY{o}{=} \PY{k}{lambda} \PY{n}{tup}\PY{p}{:}\PY{n+nb}{abs}\PY{p}{(}\PY{n}{tup}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{n}{reverse}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}

\PY{n}{equation} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{y = }\PY{l+s+si}{\PYZob{}intercept\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{intercept}\PY{o}{=}\PY{n}{intercept}\PY{p}{)}
\PY{n}{variables} \PY{o}{=} \PY{p}{[}\PY{p}{]}

\PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{coefficents\PYZus{}sorted}\PY{p}{:}
    \PY{n}{weight} \PY{o}{=} \PY{n+nb}{abs}\PY{p}{(}\PY{n}{x}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}
    \PY{n}{name} \PY{o}{=} \PY{n}{x}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}
    \PY{n}{symbol} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{+}\PY{l+s+s2}{\PYZdq{}} \PY{k}{if} \PY{p}{(}\PY{n}{x}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{\PYZgt{}} \PY{l+m+mi}{0}\PY{p}{)} \PY{k}{else} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZhy{}}\PY{l+s+s2}{\PYZdq{}}
    \PY{n}{equation} \PY{o}{+}\PY{o}{=} \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{ (}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{ * }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{)}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{symbol}\PY{p}{,} \PY{n}{weight}\PY{p}{,} \PY{n}{name}\PY{p}{)}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Finally here is our equation}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Linear Regression Equation: }\PY{l+s+s2}{\PYZdq{}} \PY{o}{+} \PY{n}{equation}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Linear Regression Equation: y = 434.0183482458498 - (1.9288465830311992 * AT) -
(0.2493165946592376 * V) - (0.14587975219954638 * RH) + (0.08140785421512364 *
AP)
    \end{Verbatim}

    Recall \textbf{Part 4: Visualize Your Data} when we visualized each
predictor against Power Output using a Scatter Plot, does the final
equation seems logical given those visualizations?

\hypertarget{exercise-6e}{%
\subsubsection{Exercise 6(e)}\label{exercise-6e}}

Now let's see what our predictions look like given this model. We apply
our Linear Regression model to the 20\% of the data that we split from
the input dataset. The output of the model will be a predicted Power
Output column named ``Predicted\_PE''.

\begin{itemize}
\tightlist
\item
  Run the next cell
\item
  Scroll through the resulting table and notice how the values in the
  Power Output (PE) column compare to the corresponding values in the
  predicted Power Output (Predicted\_PE) column
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{52}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Apply our LR model to the test data and predict power output}
\PY{k+kn}{import}\PY{+w}{ }\PY{n+nn}{pandas}\PY{+w}{ }\PY{k}{as}\PY{+w}{ }\PY{n+nn}{pd}

\PY{n}{pd}\PY{o}{.}\PY{n}{set\PYZus{}option}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{display.max\PYZus{}rows}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{k+kc}{None}\PY{p}{)}

\PY{n}{predictionsAndLabelsDF} \PY{o}{=} \PY{n}{lrModel}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{testSetDF}\PY{p}{)}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AT}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{V}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{RH}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{PE}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Predicted\PYZus{}PE}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{n}{predictionsAndLabelsDF}\PY{o}{.}\PY{n}{toPandas}\PY{p}{(}\PY{p}{)} \PY{c+c1}{\PYZsh{} convert into a Pandas DataFrame and display }
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{52}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
         AT      V       AP      RH      PE  Predicted\_PE
0      2.34  39.42  1028.47   69.68  490.34    493.237422
1      2.80  39.64  1011.01   82.96  482.66    488.936638
2      3.82  35.47  1016.62   84.34  489.04    488.264249
3      3.98  35.47  1017.22   86.53  489.64    487.685002
4      4.23  38.44  1016.46   76.64  489.00    487.843201
5      4.32  35.47  1017.80   88.51  488.03    486.787569
6      4.43  38.91  1019.04   88.17  491.90    485.868291
7      4.65  35.19  1018.23   94.78  489.36    485.341197
8      4.78  42.85  1013.39   93.36  481.47    482.993817
9      4.87  42.85  1012.69   94.72  482.05    482.564839
10     4.96  40.07  1011.80   67.38  494.75    487.000242
11     4.97  42.85  1014.02   88.78  482.98    483.346753
12     5.01  39.40  1003.69   91.90  475.34    482.833653
13     5.06  40.64  1021.49   93.70  483.73    483.614534
14     5.15  35.19  1018.63   93.94  488.42    484.531876
15     5.15  40.07  1012.27   63.31  495.35    487.265754
16     5.17  35.57  1026.68   79.86  491.32    487.107879
17     5.21  41.31  1003.51   91.23  486.46    482.054775
18     5.23  40.78  1025.13   92.74  483.12    483.688095
19     5.25  40.07  1019.48   67.70  495.23    487.019408
20     5.28  45.87  1008.25   97.88  479.91    480.198645
21     5.29  41.38  1020.62   83.83  492.12    484.355414
22     5.42  41.38  1020.77   86.02  491.38    483.797398
23     5.47  40.62  1018.66   83.61  481.56    484.070236
24     5.51  41.03  1022.28   84.50  491.84    484.055726
25     5.53  35.79  1011.19   94.01  484.64    483.033438
26     5.54  41.38  1020.47   82.91  490.07    483.995200
27     5.54  45.87  1008.69   95.91  478.02    480.020347
28     5.56  45.87  1006.99   96.48  476.61    479.760226
29     5.65  40.72  1022.46   85.17  487.09    483.779889
30     5.70  40.62  1016.07   84.94  482.82    483.221735
31     5.80  45.87  1009.14   92.06  481.60    480.117118
32     5.82  40.78  1024.82   96.01  470.02    482.047813
33     5.84  43.02  1013.88   87.42  489.05    481.813272
34     5.97  36.25  1029.65   86.74  487.03    484.633395
35     6.02  41.38  1021.20   88.71  490.57    482.282679
36     6.03  41.17  1019.81   84.20  488.57    482.860508
37     6.04  41.14  1027.80   86.40  480.39    483.178212
38     6.04  41.14  1027.92   87.12  481.37    483.082948
39     6.06  41.17  1019.67   84.70  489.62    482.718305
40     6.13  40.64  1020.69   94.57  481.13    481.358627
41     6.14  39.40  1011.21   90.87  485.94    481.416500
42     6.15  40.77  1022.42   88.57  482.49    482.303753
43     6.17  36.25  1028.68   90.59  483.77    483.607023
44     6.22  39.33  1012.31   93.23  491.77    481.024916
45     6.25  39.64  1010.98   83.45  483.43    482.208194
46     6.30  41.14  1027.45   86.11  481.49    482.690524
47     6.34  40.64  1020.62   94.39  478.78    480.974129
48     6.38  40.07  1018.53   60.20  492.96    485.856572
49     6.45  40.02  1032.08   79.70  481.36    483.992440
50     6.48  40.27  1010.55   82.12  486.68    481.766505
51     6.49  43.65  1020.41   72.78  484.94    483.069725
52     6.52  39.85  1012.55   86.36  483.01    481.338350
53     6.59  39.37  1020.34   77.92  488.17    483.188395
54     6.65  39.33  1011.29   92.85  490.41    480.167911
55     6.71  40.72  1022.78   80.69  483.11    482.414904
56     6.72  38.91  1016.89   90.47  485.89    480.940682
57     6.76  39.22  1013.91   77.00  487.08    482.508645
58     6.80  41.16  1023.17   95.40  477.80    480.017466
59     6.84  41.06  1021.04   89.59  489.96    480.639407
60     6.86  38.08  1019.62   77.37  486.92    483.010845
61     6.91  36.08  1021.82   84.31  486.37    482.579727
62     6.91  39.37  1019.58   71.02  488.20    483.515864
63     6.93  41.14  1027.18   84.67  479.06    481.663438
64     6.99  35.19  1019.32   68.95  480.05    484.684505
65     6.99  39.37  1020.19   75.06  487.18    482.821861
66     7.05  43.65  1018.41   72.36  480.47    481.888024
67     7.10  35.77  1015.39   92.10  480.36    480.630679
68     7.11  41.74  1022.35   90.68  487.85    479.896718
69     7.11  43.13  1018.96   87.82  486.11    479.691412
70     7.24  38.06  1020.60   85.36  481.83    481.197070
71     7.30  43.65  1019.33   67.62  482.96    482.172178
72     7.34  40.72  1023.01   80.08  483.92    481.307441
73     7.40  41.04  1024.44   90.90  477.69    479.649923
74     7.41  40.71  1023.07   83.32  474.25    480.707149
75     7.44  41.04  1021.84   88.56  479.08    479.702468
76     7.45  39.61  1017.88   79.73  478.89    481.005445
77     7.46  41.82  1032.67   74.59  483.11    482.389011
78     7.48  38.50  1014.01   77.35  488.43    481.256466
79     7.52  41.66  1015.20   78.41  483.28    480.333715
80     7.54  38.56  1016.49   69.10  486.76    482.531176
81     7.55  41.04  1027.03   83.32  476.58    480.677211
82     7.55  43.65  1019.09   61.71  481.61    482.532578
83     7.57  41.14  1028.23   87.97  477.80    480.033051
84     7.60  41.04  1021.82   88.97  475.32    479.332413
85     7.65  41.01  1024.31   97.17  475.89    478.249942
86     7.67  41.66  1016.25   77.00  485.03    480.335557
87     7.69  36.24  1013.08   88.37  482.46    479.731560
88     7.70  40.35  1011.72   92.88  484.57    477.918948
89     7.73  37.80  1020.71   63.93  483.94    483.451915
90     7.73  39.04  1018.61   68.23  482.39    482.344523
91     7.76  42.28  1008.52   83.31  483.80    478.457600
92     7.81  39.64  1011.42   86.68  482.22    478.763822
93     7.82  40.72  1022.17   88.13  481.52    479.138880
94     7.84  43.52  1022.23   96.51  483.79    477.184629
95     7.87  42.85  1012.18   94.21  480.54    476.811180
96     7.89  40.46  1019.61   74.53  477.27    480.844244
97     7.90  40.00  1018.74   79.55  474.50    480.136500
98     7.91  39.96  1023.57   88.44  475.52    479.223513
99     7.92  39.54  1011.51   84.41  481.44    478.915054
100    7.95  41.26  1008.48   97.92  480.60    476.210863
101    7.97  38.50  1013.84   72.36  487.19    481.025432
102    8.01  40.46  1019.42   76.15  475.42    480.360989
103    8.01  40.62  1015.62   86.43  476.22    478.512105
104    8.01  41.66  1014.49   76.72  485.13    479.577317
105    8.03  40.07  1016.06   47.46  488.02    484.331406
106    8.04  40.64  1020.64   89.26  477.78    478.445081
107    8.05  40.62  1018.16   73.67  477.20    480.503153
108    8.07  43.41  1016.02   76.26  467.56    479.216941
109    8.07  43.69  1017.05   87.34  485.18    477.614635
110    8.11  41.92  1029.61   91.92  483.52    478.333125
111    8.16  39.72  1020.54   82.11  480.21    479.477890
112    8.18  40.02  1031.45   73.66  478.81    481.485362
113    8.23  43.79  1016.11   82.11  484.67    477.967515
114    8.24  39.61  1017.99   78.42  477.90    479.681713
115    8.25  41.26  1020.59   91.84  475.17    477.505007
116    8.26  40.96  1025.23   89.22  485.73    478.320451
117    8.27  39.64  1011.00   84.64  479.91    478.139956
118    8.28  40.56  1023.29   79.44  486.40    479.650373
119    8.28  40.77  1011.55   89.79  480.15    477.132433
120    8.30  36.30  1015.97   60.62  480.58    482.823436
121    8.30  43.13  1020.02   83.11  484.07    478.169470
122    8.33  38.08  1018.94   73.78  481.89    480.643791
123    8.34  40.72  1023.62   83.75  483.14    478.892874
124    8.35  43.52  1022.78   97.34  479.31    476.124611
125    8.35  43.79  1016.20   85.23  484.21    477.288236
126    8.37  40.92  1021.82   86.03  476.02    478.306006
127    8.39  36.24  1013.39   89.13  480.69    478.295735
128    8.42  42.28  1008.40   87.78  481.91    476.522710
129    8.46  40.80  1023.57   81.27  485.06    478.999179
130    8.48  38.50  1013.50   66.51  485.29    480.867438
131    8.51  38.50  1013.33   64.28  482.39    481.121045
132    8.61  43.80  1021.90   74.35  478.25    478.835439
133    8.63  39.96  1024.39   99.47  475.79    476.292444
134    8.65  40.56  1023.23   78.85  485.87    479.017884
135    8.67  40.77  1011.81   89.40  479.23    476.458242
136    8.68  41.82  1032.83   73.62  478.61    480.190347
137    8.72  36.25  1029.31   85.73  479.94    479.448727
138    8.73  36.18  1013.66   77.74  479.25    479.338437
139    8.73  41.92  1029.41   89.72  480.99    477.441894
140    8.74  40.03  1016.81   93.37  481.07    476.335614
141    8.75  36.30  1015.61   57.53  480.40    482.376917
142    8.75  40.22  1008.96   90.53  482.80    476.044202
143    8.76  41.82  1033.29   76.50  480.08    479.653353
144    8.77  40.46  1019.68   77.84  475.00    478.669695
145    8.80  42.32  1017.91   86.80  483.88    476.696926
146    8.81  43.56  1014.99   81.50  482.52    476.903937
147    8.83  36.25  1028.86   85.60  478.45    479.218884
148    8.85  40.22  1008.61   90.60  482.30    475.812613
149    8.87  41.16  1023.17   94.13  472.45    476.210021
150    8.88  36.66  1026.61   76.16  480.20    480.214160
151    8.91  43.52  1022.78   98.00  478.38    474.948176
152    8.93  40.46  1019.03   71.00  472.77    479.305982
153    8.94  41.74  1022.55   90.74  483.53    476.374458
154    8.96  40.02  1031.21   82.32  475.47    478.698005
155    8.96  40.05  1015.91   89.40  467.24    476.412157
156    8.99  36.66  1028.11   71.98  481.03    480.733876
157    9.01  38.56  1016.67   63.61  482.37    480.511305
158    9.03  40.71  1025.98   81.94  484.97    478.020628
159    9.04  44.68  1023.14   90.73  479.53    475.498072
160    9.06  43.79  1016.05   81.32  482.80    476.476933
161    9.08  36.18  1020.24   68.37  477.26    480.565897
162    9.08  36.71  1025.07   81.32  479.02    478.937817
163    9.08  40.02  1031.20   75.34  476.69    479.483970
164    9.11  40.64  1020.68   86.91  476.62    476.727289
165    9.12  41.49  1020.58   96.23  475.69    475.128341
166    9.12  41.54  1018.61   79.26  482.95    477.431081
167    9.13  39.04  1022.36   74.60  483.24    479.020163
168    9.13  39.16  1014.14   86.17  484.86    476.633244
169    9.14  37.36  1015.22   78.06  491.97    478.333731
170    9.15  39.61  1018.11   75.29  474.88    478.392836
171    9.15  39.61  1018.69   84.47  475.64    477.100876
172    9.16  41.03  1021.30   76.08  484.96    478.163964
173    9.19  40.62  1017.78   68.91  475.42    478.967720
174    9.20  40.03  1017.05   92.46  480.38    475.600633
175    9.26  44.68  1023.22   91.44  478.82    474.976663
176    9.29  39.04  1022.72   74.29  482.55    478.786078
177    9.30  38.18  1017.19   71.51  480.14    478.936562
178    9.31  43.56  1015.09   79.96  482.55    476.172309
179    9.32  37.73  1022.14   79.49  477.91    478.249026
180    9.35  44.03  1011.02   88.11  476.25    474.457727
181    9.37  40.11  1024.94   75.03  471.13    478.437775
182    9.39  39.66  1019.22   75.33  482.16    478.001974
183    9.41  34.69  1027.02   78.91  480.87    479.315232
184    9.41  39.61  1016.14   78.38  477.34    477.280194
185    9.45  39.04  1023.08   75.81  483.66    478.285032
186    9.46  42.28  1008.67   78.16  481.95    475.942053
187    9.47  41.40  1026.49   87.90  479.68    476.171982
188    9.48  44.68  1023.29   92.90  478.66    474.345031
189    9.50  37.36  1015.13   63.41  478.80    479.769158
190    9.51  43.79  1016.02   79.81  481.12    475.826789
191    9.53  38.18  1018.43   75.33  476.54    478.036612
192    9.53  38.38  1020.49   80.08  478.03    477.461520
193    9.55  38.08  1019.34   68.38  479.23    479.110912
194    9.55  39.66  1018.80   74.88  480.74    477.724813
195    9.59  34.69  1027.65   75.32  478.88    479.543035
196    9.59  38.56  1017.52   61.89  481.05    479.712684
197    9.61  44.03  1008.30   91.36  473.54    473.260688
198    9.63  41.14  1027.99   87.89  469.73    476.051760
199    9.68  38.16  1015.54   79.67  475.51    476.883884
200    9.68  41.06  1022.75   87.44  476.67    475.614331
201    9.69  40.46  1019.10   71.91  472.16    477.713007
202    9.72  41.44  1015.17   84.41  481.85    475.267381
203    9.75  36.66  1026.21   70.12  479.45    479.384614
204    9.76  39.16  1014.19   85.40  482.38    475.534469
205    9.78  52.75  1022.97   78.31  469.58    473.856728
206    9.82  39.64  1010.79   69.22  477.93    477.382614
207    9.83  41.17  1019.34   72.29  478.21    477.230057
208    9.84  36.66  1026.70   70.02  477.62    479.265495
209    9.86  37.83  1005.05  100.15  472.46    472.777381
210    9.86  41.01  1018.49   98.71  467.37    473.288742
211    9.87  40.81  1017.17   84.25  473.20    475.321280
212    9.88  39.66  1017.81   76.05  480.05    476.837021
213    9.92  40.64  1020.39   95.41  469.65    473.901337
214    9.93  40.67  1018.08   69.74  485.23    477.431250
215    9.95  43.56  1014.85   82.62  477.88    474.530270
216    9.96  41.26  1022.90   83.83  475.21    475.563228
217    9.96  41.55  1002.59   65.86  475.91    476.458992
218    9.96  42.03  1017.78   82.39  477.85    475.164513
219    9.97  41.62  1013.99   96.02  464.86    472.950567
220    9.98  41.01  1017.83   98.07  466.05    473.096915
221    9.98  41.62  1013.56   95.77  463.16    472.932744
222    9.99  41.82  1033.14   68.36  475.75    478.456122
223    9.99  42.07  1018.78   85.68  471.60    474.698138
224   10.01  40.78  1023.71   88.11  470.82    475.028033
225   10.02  41.44  1017.37   77.65  479.63    475.853972
226   10.06  34.69  1027.90   71.73  477.68    479.180538
227   10.08  43.14  1010.67   85.90  478.73    473.565462
228   10.09  37.14  1012.99   72.59  473.66    477.172599
229   10.10  41.40  1024.29   85.94  474.28    475.063636
230   10.10  41.58  1021.26   94.06  468.19    473.587549
231   10.11  41.62  1017.17   97.82  463.57    472.676822
232   10.12  41.55  1005.78   62.34  475.46    476.923564
233   10.12  43.72  1011.33   97.62  473.05    471.687723
234   10.13  38.16  1013.57   79.04  474.92    475.947434
235   10.15  41.46  1019.78   83.56  481.31    474.932279
236   10.15  43.41  1018.40   82.07  473.43    474.551130
237   10.16  41.55  1005.69   58.04  477.27    477.466367
238   10.18  43.50  1022.84   88.70  476.91    473.865094
239   10.20  41.01  1021.39   96.64  468.27    473.170989
240   10.20  41.46  1019.12   83.26  480.11    474.825871
241   10.22  37.83  1005.94   93.53  471.79    473.121173
242   10.23  41.46  1020.45   84.95  480.87    474.629742
243   10.24  39.28  1010.13   81.61  477.53    474.801073
244   10.25  41.26  1007.44   98.08  476.03    471.666511
245   10.25  41.46  1018.67   84.41  479.28    474.525034
246   10.27  52.75  1026.19   76.78  470.76    473.396922
247   10.28  39.64  1010.45   74.15  477.65    475.748478
248   10.31  37.50  1008.55   99.31  474.16    472.399141
249   10.31  38.18  1018.02   70.10  476.31    477.261686
250   10.32  38.91  1012.11   81.49  479.17    474.917705
251   10.33  40.62  1017.41   64.22  473.16    477.422890
252   10.34  41.46  1017.75   89.73  478.03    473.500462
253   10.37  37.83  1006.50   90.99  470.66    473.247969
254   10.39  40.22  1006.59   87.77  479.14    473.090585
255   10.40  42.44  1014.24   93.48  480.04    472.307610
256   10.42  41.26  1008.48   96.76  472.54    471.615832
257   10.42  41.46  1021.04   89.16  479.24    473.697138
258   10.44  37.83  1006.31   97.20  474.42    472.191569
259   10.45  39.61  1020.23   73.39  477.41    476.335091
260   10.46  37.50  1013.12   76.74  472.16    475.774354
261   10.47  43.14  1010.35   86.86  476.55    472.647117
262   10.51  37.50  1010.70   96.29  474.24    472.628955
263   10.58  42.34  1022.32   94.01  474.91    472.565809
264   10.59  38.38  1021.58   68.23  474.94    477.234352
265   10.60  41.17  1018.38   87.92  478.47    473.386593
266   10.60  41.46  1021.23   89.02  481.30    473.385836
267   10.63  44.20  1018.63   90.26  477.19    472.252292
268   10.66  41.93  1016.12   94.16  479.61    471.987110
269   10.68  37.92  1009.59   65.05  474.03    476.663259
270   10.70  44.77  1017.80   82.37  484.94    473.058585
271   10.71  41.93  1018.23   90.88  478.76    472.540924
272   10.73  40.35  1012.27   89.65  477.23    472.590509
273   10.74  40.05  1015.45   87.33  477.93    473.243333
274   10.76  44.58  1016.41   79.24  483.54    473.333671
275   10.77  44.78  1012.87   84.16  470.66    472.258607
276   10.82  39.96  1025.53   95.89  468.57    472.683324
277   10.82  42.02   996.03   99.34  475.46    469.264915
278   10.84  40.62  1015.53   60.90  467.60    476.770452
279   10.89  44.20  1018.30   86.32  479.16    472.298693
280   10.91  37.92  1008.66   66.53  473.72    475.928013
281   10.94  25.36  1009.47  100.10  470.90    474.170321
282   10.94  39.04  1021.81   86.02  479.20    473.818230
283   10.94  40.81  1026.03   80.79  476.32    474.483432
284   10.94  43.67  1012.36   73.30  477.34    473.750180
285   10.98  37.50  1011.12   97.51  472.34    471.578615
286   10.99  44.63  1020.67   90.09  473.29    471.641572
287   11.01  43.69  1016.70   81.48  477.30    472.770189
288   11.02  38.28  1013.51   95.66  472.11    471.771437
289   11.02  40.00  1015.75   74.83  468.09    474.563641
290   11.02  41.17  1018.18   86.86  477.62    472.714828
291   11.04  39.96  1025.75   94.44  468.84    472.488414
292   11.04  41.74  1022.60   77.51  477.20    474.257939
293   11.06  37.92  1008.76   67.32  473.16    475.531582
294   11.06  41.16  1018.52   89.14  467.46    472.335241
295   11.06  41.50  1013.09   89.80  476.24    471.712148
296   11.10  40.92  1021.98   94.14  462.07    471.870195
297   11.16  40.96  1023.49   83.70  478.30    473.390402
298   11.17  39.72  1002.40   81.40  474.64    472.298898
299   11.17  40.27  1009.54   74.56  476.18    473.740843
300   11.18  37.50  1013.32   74.32  472.02    474.754895
301   11.18  39.61  1018.56   68.00  468.75    475.577374
302   11.20  41.38  1021.65   61.89  476.87    476.240382
303   11.20  42.02   999.99   96.69  472.27    469.240910
304   11.22  40.22  1011.01   81.67  476.70    472.739331
305   11.22  43.13  1017.24   80.90  473.93    472.633319
306   11.29  41.50  1013.39   89.15  476.04    471.387757
307   11.31  39.61  1018.74   68.90  471.92    475.209986
308   11.38  52.75  1026.19   72.71  469.90    471.849633
309   11.41  39.61  1018.69   69.44  467.19    474.934255
310   11.48  41.14  1027.67   90.50  464.07    472.076597
311   11.49  35.76  1019.08   60.04  472.45    477.142835
312   11.49  44.20  1018.79   91.14  475.51    470.478135
313   11.51  41.06  1021.30   78.11  476.91    473.327559
314   11.53  41.14  1025.63   88.54  469.04    472.100007
315   11.53  41.39  1018.39   85.52  474.49    471.888842
316   11.54  40.05  1014.78   87.05  474.29    471.686559
317   11.54  40.77  1022.13   83.50  465.61    472.623272
318   11.56  39.28  1011.27   82.05  477.71    472.283613
319   11.56  41.62  1012.50   91.42  460.60    470.433451
320   11.57  39.72  1002.26   78.69  474.72    471.911296
321   11.57  41.54  1020.13   69.14  476.89    474.305450
322   11.62  39.72  1018.40   68.06  471.56    474.679479
323   11.67  37.73  1021.20   68.88  473.54    475.187497
324   11.67  44.60  1018.09   92.53  467.96    469.771457
325   11.68  40.55  1022.21   85.76  475.13    472.084907
326   11.70  25.36  1008.65   92.11  470.88    473.803223
327   11.71  41.44  1015.37   79.95  474.22    472.095882
328   11.72  40.35  1012.08   83.98  476.41    471.492621
329   11.76  41.58  1020.91   88.35  465.45    471.190145
330   11.77  39.39  1012.90   85.80  478.51    471.436776
331   11.80  40.66  1017.13   97.20  464.43    469.743605
332   11.80  41.20  1017.18   82.71  475.19    471.726842
333   11.80  41.54  1020.00   65.85  476.12    474.331177
334   11.80  42.34  1020.25   93.54  466.52    470.112665
335   11.80  43.99  1020.86   98.44  466.75    469.036141
336   11.82  41.54  1019.96   67.65  476.97    474.026760
337   11.82  41.67  1012.94   84.51  476.73    470.963333
338   11.84  40.05  1014.54   86.78  473.82    471.127755
339   11.86  39.85  1013.00   66.92  478.29    473.910845
340   11.87  40.55  1019.06   94.11  473.79    470.243896
341   11.90  39.16  1016.53   84.59  477.75    471.715394
342   11.92  43.80  1022.96   60.49  470.33    474.559142
343   11.93  38.78  1013.15   96.08  474.57    469.800952
344   11.95  41.58  1015.83   89.35  464.57    470.264232
345   11.96  43.41  1017.42   79.44  469.34    471.363801
346   12.02  41.92  1030.10   84.45  465.82    471.920946
347   12.02  43.69  1016.12   74.07  477.74    471.855806
348   12.04  40.10  1014.42   89.65  474.28    470.301076
349   12.05  48.04  1009.14  100.13  464.14    466.343560
350   12.05  49.83  1008.54   95.11  454.18    466.580755
351   12.06  52.72  1024.53   80.05  467.21    469.339602
352   12.07  38.25  1012.67   81.66  470.36    471.727561
353   12.08  40.75  1015.84   86.90  476.84    470.578634
354   12.09  40.60  1013.85   85.72  474.35    470.606880
355   12.10  40.27  1005.53   68.37  477.61    472.523566
356   12.10  41.17  1013.72   75.61  478.10    471.909742
357   12.12  40.00  1018.72   84.42  462.10    471.284704
358   12.14  40.83  1010.56   78.31  474.82    471.266232
359   12.17  41.58  1013.89   88.98  463.03    469.735930
360   12.19  40.05  1014.65   85.10  472.68    470.706691
361   12.19  40.23  1017.45   82.07  474.91    471.331772
362   12.19  44.63  1018.96   80.91  468.91    470.526925
363   12.23  41.58  1018.76   87.66  464.45    470.209217
364   12.24  49.83  1007.90   94.28  466.83    466.283253
365   12.25  44.58  1016.47   81.15  475.24    470.185943
366   12.27  41.17  1019.39   52.18  473.84    475.461384
367   12.27  41.17  1019.41   58.10  475.13    474.599404
368   12.30  39.85  1012.59   73.38  476.42    472.086392
369   12.30  40.69  1015.74   82.58  474.46    470.791307
370   12.31  44.03  1007.78   94.42  468.13    467.564078
371   12.32  41.26  1022.42   79.74  470.27    471.568723
372   12.32  43.69  1016.26   83.18  471.60    469.959584
373   12.33  38.91  1017.24   79.84  472.49    471.699047
374   12.33  39.85  1012.53   66.04  479.32    473.094399
375   12.35  44.20  1017.81   82.49  471.65    470.001407
376   12.36  40.56  1022.11   72.99  474.71    472.625542
377   12.36  45.09  1013.05   88.40  467.20    468.510576
378   12.36  48.04  1012.80   93.59  468.37    466.997624
379   12.37  46.97  1013.95   90.76  464.40    467.751563
380   12.38  45.09  1013.26   90.55  467.47    468.175453
381   12.39  49.83  1007.60   92.43  468.43    466.239382
382   12.42  41.58  1019.49   86.31  466.05    470.099102
383   12.42  43.14  1015.88   79.48  471.10    470.412644
384   12.43  43.22  1008.93   77.42  468.01    470.108138
385   12.45  40.56  1017.84   66.52  477.41    473.048176
386   12.47  38.25  1012.74   82.89  469.56    470.782289
387   12.47  45.01  1017.80   95.25  467.18    467.705759
388   12.49  41.62  1011.37   82.68  461.35    469.822621
389   12.50  41.38  1021.87   57.59  474.40    474.378074
390   12.50  43.67  1013.99   90.91  473.26    468.304932
391   12.54  43.69  1017.26   83.59  470.04    469.556835
392   12.55  39.58  1010.68   76.90  472.31    471.002510
393   12.56  43.41  1016.93   81.02  467.19    469.936113
394   12.57  39.16  1016.53   88.91  476.20    469.792866
395   12.57  41.79  1014.99   87.80  461.88    469.173722
396   12.58  39.72  1017.85   57.74  471.24    474.288491
397   12.58  43.67  1014.36   91.72  473.02    468.062583
398   12.59  39.18  1024.18   67.57  471.32    473.485147
399   12.60  41.74  1022.13   67.89  474.23    472.614040
400   12.61  43.22  1013.41   78.94  466.85    469.903916
401   12.64  41.26  1020.79   83.66  465.78    470.246948
402   12.65  44.34  1014.74   92.81  473.46    467.632447
403   12.68  41.40  1021.59   78.57  466.64    470.942544
404   12.71  43.80  1023.15   71.16  466.20    471.494284
405   12.72  39.13  1008.36   92.59  467.28    468.309079
406   12.72  40.64  1021.11   93.24  475.73    468.875739
407   12.73  37.73  1021.89   61.76  470.89    474.237755
408   12.74  49.83  1007.44   91.47  466.09    465.691305
409   12.75  39.85  1012.51   62.37  475.61    472.818034
410   12.79  44.68  1022.51   99.55  465.75    466.926951
411   12.83  41.67  1012.84   84.29  474.81    469.039151
412   12.83  44.88  1017.86   87.88  474.26    468.123804
413   12.87  39.30  1019.26   71.55  471.48    471.934024
414   12.87  45.51  1015.30   86.67  475.77    467.857691
415   12.88  44.00  1022.71   88.58  470.31    468.539472
416   12.88  44.71  1018.73   51.95  469.12    473.382030
417   12.89  36.71  1013.36   87.29  475.13    469.764723
418   12.90  44.63  1020.72   89.51  467.41    468.046156
419   12.92  39.35  1014.56   88.29  469.83    469.000472
420   12.95  41.38  1021.97   53.83  474.46    474.066742
421   12.99  40.55  1007.52   94.15  472.18    467.138306
422   13.02  45.51  1015.24   80.05  468.46    468.529203
423   13.03  42.86  1014.39   86.25  475.03    468.196953
424   13.04  40.69  1015.96   82.37  473.49    469.412505
425   13.06  44.20  1018.95   85.68  469.02    468.259374
426   13.07  38.47  1015.16   57.26  468.90    473.506037
427   13.07  40.83  1010.00   84.84  471.19    468.474221
428   13.08  39.28  1012.41   77.98  474.13    470.038302
429   13.08  44.90  1020.47   86.46  472.01    468.056229
430   13.09  39.85  1012.86   58.42  475.89    472.766944
431   13.09  54.30  1017.61   82.38  471.00    466.055728
432   13.10  40.55  1007.59   95.46  472.37    466.740729
433   13.10  49.83  1007.29   92.79  466.08    464.792147
434   13.11  41.44  1015.55   74.45  471.61    470.212489
435   13.12  39.18  1023.11   64.33  471.44    472.848402
436   13.15  40.78  1024.13   79.59  462.30    470.248541
437   13.15  41.14  1026.72   80.31  461.49    470.264600
438   13.18  43.72  1010.59   99.09  464.70    465.510768
439   13.19  44.88  1017.61   94.95  467.68    466.377697
440   13.20  40.83  1007.75   94.98  472.41    466.561083
441   13.20  41.78  1010.49   64.96  468.58    470.926600
442   13.25  43.70  1013.61   76.05  472.22    468.987656
443   13.25  44.92  1024.11   89.34  469.18    467.599530
444   13.27  40.27  1006.10   40.04  473.88    474.445992
445   13.34  41.79  1011.48   86.66  461.12    467.569071
446   13.41  40.89  1010.85   89.61  472.40    467.176805
447   13.42  40.92  1022.84   75.89  458.49    470.127587
448   13.43  43.69  1016.21   73.01  475.36    469.298091
449   13.44  40.69  1014.54   77.97  473.00    469.167238
450   13.44  41.14  1026.41   77.26  461.44    470.124931
451   13.48  41.92  1030.20   65.96  463.90    471.810288
452   13.49  43.41  1015.75   57.86  461.06    471.424800
453   13.51  39.31  1012.18   75.19  466.46    469.589699
454   13.53  38.73  1004.86   85.38  472.46    467.613305
455   13.53  42.86  1014.00   90.63  471.73    466.561827
456   13.54  40.69  1015.85   77.55  471.05    469.142267
457   13.55  40.71  1019.13   75.44  467.21    469.692816
458   13.56  40.03  1017.73   83.76  472.59    468.515373
459   13.56  49.83  1007.01   89.86  466.33    464.309511
460   13.57  42.99  1007.51   88.95  472.04    466.169003
461   13.58  39.28  1016.17   79.17  472.17    469.206375
462   13.61  38.47  1015.10   54.98  466.51    472.792181
463   13.65  41.58  1020.56   72.17  460.80    469.876466
464   13.67  41.48  1017.51   63.54  463.97    470.873469
465   13.67  42.32  1015.41   79.04  464.56    468.231951
466   13.69  34.03  1018.45   65.76  469.12    472.444971
467   13.69  40.83  1008.53   84.81  471.26    467.163043
468   13.71  43.41  1015.45   69.26  466.06    469.313002
469   13.72  44.47  1027.20   68.89  470.66    470.039956
470   13.72  49.83  1006.88   89.49  463.65    464.044288
471   13.73  45.08  1023.55   81.64  470.35    467.711479
472   13.74  42.74  1029.54   70.00  465.92    470.461265
473   13.74  44.21  1023.26   84.20  466.67    467.512035
474   13.77  42.86  1030.72   77.30  471.38    469.404620
475   13.77  43.13  1016.63   62.13  468.45    470.403264
476   13.78  44.47  1027.94   71.09  467.22    469.663531
477   13.78  45.78  1025.27   95.72  462.88    465.526549
478   13.80  39.82  1012.37   83.69  473.56    467.678672
479   13.83  38.73   999.62   91.95  469.81    465.649644
480   13.84  42.18  1015.74   79.76  468.66    467.860782
481   13.85  45.08  1024.86   83.85  468.35    467.264267
482   13.86  37.85  1011.40   89.70  469.94    467.098391
483   13.86  40.66  1017.15   83.82  463.49    467.723680
484   13.87  45.08  1024.42   81.69  465.48    467.504971
485   13.88  48.79  1017.28   79.40  464.14    466.313531
486   13.90  39.54  1007.01   81.33  471.16    467.463526
487   13.91  44.58  1021.36   78.98  472.67    467.698702
488   13.93  42.86  1032.37   71.11  468.88    470.133323
489   13.95  40.20  1013.18   90.77  464.79    466.327716
490   13.95  71.14  1019.76   75.51  461.18    461.375649
491   13.96  39.54  1011.05   85.72  468.82    467.036270
492   13.97  45.01  1017.44   89.15  461.96    465.673049
493   13.98  44.84  1023.60   89.09  462.81    466.206369
494   14.00  41.78  1010.96   48.37  465.62    471.841929
495   14.01  45.08  1023.28   82.49  464.79    467.025424
496   14.02  40.66  1017.05   84.14  465.39    467.360242
497   14.03  44.88  1019.60   57.63  465.51    470.363700
498   14.04  40.20  1013.29   89.54  465.25    466.342507
499   14.04  40.83  1008.98   82.04  469.75    466.928668
500   14.04  44.21  1021.93   86.12  468.64    466.545020
501   14.07  40.78  1024.67   72.66  456.71    469.528909
502   14.07  42.99  1007.57   96.05  468.87    464.173718
503   14.07  43.34  1015.79   86.00  463.77    466.221721
504   14.08  39.31  1011.67   72.00  464.16    468.914095
505   14.09  41.20  1016.45   67.27  472.42    469.502739
506   14.09  44.84  1023.65   94.29  466.12    465.239692
507   14.10  41.04  1026.11   74.25  465.89    469.291500
508   14.10  42.18  1015.05   78.25  463.30    467.523389
509   14.12  39.52  1016.79   75.89  472.32    468.633920
510   14.12  41.39  1018.73   76.51  472.88    468.235184
511   14.14  39.82  1012.46   81.15  472.52    467.400725
512   14.17  42.86  1030.94   66.47  466.20    470.230869
513   14.18  39.30  1020.10   67.48  464.32    470.069348
514   14.18  40.69  1014.73   74.88  471.52    468.206128
515   14.22  37.85  1011.24   88.49  471.05    466.567496
516   14.22  42.32  1015.54   77.23  465.00    467.445711
517   14.24  39.52  1018.22   77.19  468.51    468.329228
518   14.24  39.99  1009.30   83.75  466.20    466.528920
519   14.24  44.84  1023.60   94.06  466.67    464.979847
520   14.27  41.48  1014.83   62.70  458.19    469.620527
521   14.28  42.77  1020.06   81.77  466.75    466.923457
522   14.28  43.02  1012.97   49.44  467.83    471.000238
523   14.31  40.78  1024.30   76.41  463.54    468.488816
524   14.32  45.08  1023.24   84.53  467.21    466.126630
525   14.33  45.51  1015.42   71.55  468.92    467.257046
526   14.34  42.86  1031.75   66.81  466.17    469.919306
527   14.35  40.71  1023.09   69.50  473.56    469.338640
528   14.35  49.83  1006.39   91.23  462.54    462.535394
529   14.36  40.00  1016.16   68.79  460.42    469.035785
530   14.38  40.66  1016.34   92.37  463.10    465.407467
531   14.39  43.56  1012.97   59.17  469.35    469.234024
532   14.40  40.20  1013.04   90.50  464.50    465.487725
533   14.41  40.71  1016.78   69.77  467.01    468.669838
534   14.41  40.83  1009.82   80.43  470.13    466.518243
535   14.42  41.16  1004.32   88.42  467.25    464.803358
536   14.43  35.85  1021.99   78.25  464.60    469.030014
537   14.48  39.00  1016.75   75.97  464.56    468.054254
538   14.48  40.89  1011.39   82.18  470.44    466.240786
539   14.50  41.76  1023.94   84.42  464.23    466.680201
540   14.52  40.35  1011.11   69.84  470.80    468.075625
541   14.54  41.17  1015.15   67.78  470.19    468.462008
542   14.54  43.14  1010.26   82.98  465.45    465.355398
543   14.55  44.84  1023.83   87.60  465.14    465.343011
544   14.57  41.79  1007.61   82.85  457.21    465.437344
545   14.58  41.92  1030.42   61.96  462.69    470.289985
546   14.58  42.07  1017.90   86.14  460.66    465.705989
547   14.64  44.92  1025.54   91.12  462.64    464.775181
548   14.64  45.00  1021.78   41.25  475.98    471.724165
549   14.65  35.40  1016.16   60.26  469.61    470.867630
550   14.65  41.92  1030.61   63.07  464.95    470.008507
551   14.65  44.84  1023.39   87.76  467.18    465.090967
552   14.66  41.76  1022.12   78.13  463.60    467.141007
553   14.66  42.07  1018.14   84.68  462.77    465.784203
554   14.72  39.00  1016.42   76.42  464.93    467.498820
555   14.74  43.71  1024.35   81.53  465.49    466.186081
556   14.76  39.64  1010.37   81.99  465.82    465.957036
557   14.77  48.06  1010.92   69.81  461.52    465.660091
558   14.77  58.20  1018.78   83.83  460.54    461.726652
559   14.78  38.58  1017.02   82.40  460.54    466.664286
560   14.79  47.83  1007.27   92.04  463.22    462.138811
561   14.81  39.58  1011.62   73.64  467.32    467.195408
562   14.81  40.71  1018.54   73.00  467.66    467.570386
563   14.81  43.69  1017.19   71.90  470.71    466.877989
564   14.82  42.74  1028.04   69.81  466.34    468.283716
565   14.83  53.82  1016.57   63.47  464.00    465.493129
566   14.84  71.14  1019.61   66.78  454.16    460.920295
567   14.85  45.01  1013.12   85.53  460.19    464.152067
568   14.86  37.85  1010.58   86.80  467.71    465.525842
569   14.87  41.23   997.39   82.06  465.01    464.281564
570   14.87  54.30  1017.17   71.57  462.87    464.163522
571   14.88  42.28  1007.26   71.30  466.73    466.373654
572   14.91  39.28  1014.57   75.23  469.34    467.085523
573   14.91  40.73  1017.44   86.91  458.99    465.253779
574   14.92  41.16  1004.83   83.70  465.72    464.569005
575   14.92  46.18  1014.21   98.82  465.63    461.875340
576   14.93  42.44  1012.65   86.80  471.24    464.414974
577   14.94  40.00  1017.69   65.43  456.41    468.531763
578   14.94  42.77  1018.06   75.35  460.51    466.424150
579   14.98  39.58  1011.78   75.07  467.77    466.671921
580   15.00  40.66  1016.28   89.62  456.63    464.607867
581   15.01  39.52  1017.53   72.00  468.02    467.544961
582   15.02  37.64  1016.49   83.28  463.93    466.264200
583   15.03  43.71  1025.07   83.25  463.12    465.434416
584   15.03  44.45  1020.94   65.57  460.06    467.492861
585   15.08  42.77  1018.67   73.89  461.60    466.416755
586   15.09  41.76  1022.40   76.22  463.27    466.613028
587   15.11  43.67  1012.06   91.75  467.82    462.990986
588   15.12  48.92  1011.80   72.93  462.59    464.387077
589   15.14  39.72  1002.96   72.52  460.15    465.982378
590   15.14  44.21  1019.97   83.86  463.10    464.593417
591   15.15  53.82  1016.34   62.59  461.60    464.985548
592   15.19  42.03  1017.38   71.66  462.64    466.609372
593   15.21  50.88  1014.24  100.11  460.56    459.958443
594   15.24  48.60  1007.08   86.49  459.85    461.873022
595   15.27  38.73  1002.83   77.77  465.99    465.201999
596   15.27  39.54  1010.64   81.91  464.49    465.031906
597   15.29  38.73  1000.90   81.17  468.62    464.510314
598   15.31  40.66  1016.46   84.64  458.26    464.751060
599   15.31  41.35  1005.09   95.25  466.50    462.105640
600   15.32  45.01  1013.30   83.72  459.31    463.524204
601   15.34  43.50  1021.18   79.44  459.77    465.127955
602   15.34  71.14  1019.79   77.56  457.10    458.397941
603   15.40  38.73  1000.67   79.71  469.18    464.492402
604   15.41  42.44  1012.60   86.74  472.28    463.493810
605   15.46  42.07  1017.90   81.12  459.15    464.740920
606   15.47  43.13  1015.11   50.50  466.63    468.697066
607   15.48  53.82  1016.10   64.77  462.69    464.011473
608   15.50  44.34  1019.21   65.21  468.53    466.525409
609   15.50  49.25  1021.41   77.92  453.99    463.626230
610   15.52  41.93  1022.97   52.92  471.97    469.186641
611   15.52  58.59  1014.12   91.22  457.74    458.725372
612   15.55  39.63  1004.98   89.82  466.83    462.854713
613   15.55  43.02  1011.97   44.66  466.20    469.166500
614   15.55  43.71  1024.34   79.61  465.14    464.902990
615   15.55  45.09  1014.33   62.19  457.36    466.285266
616   15.61  38.52  1018.40   80.99  439.21    465.396335
617   15.62  40.12  1013.03   96.26  462.59    462.313396
618   15.62  58.59  1013.91   97.60  457.30    457.584679
619   15.66  41.35  1001.68   86.26  463.57    462.464402
620   15.67  45.17  1018.73   94.74  462.09    461.643667
621   15.69  37.87  1021.18   84.38  465.41    465.135865
622   15.69  39.30  1019.03   60.57  464.17    468.077712
623   15.70  42.99  1007.51   76.05  464.59    463.942409
624   15.75  36.99  1007.67   93.80  464.38    462.765525
625   15.75  39.99  1007.02   77.44  464.95    464.351253
626   15.79  58.86  1015.85   91.91  455.15    458.177447
627   15.81  58.59  1014.41   90.03  456.91    458.363212
628   15.84  41.04  1025.64   63.43  456.21    467.475464
629   15.85  42.28  1007.40   82.12  467.30    462.935651
630   15.85  49.69  1015.48   88.65  464.72    460.793396
631   15.86  38.62  1016.65   67.51  462.58    466.713187
632   15.86  43.02  1012.18   40.33  466.60    469.217313
633   15.86  43.50  1021.22   75.38  459.42    464.720483
634   15.92  37.64  1014.93   83.73  464.14    464.335596
635   15.92  39.16  1006.59   71.32  460.45    465.088061
636   15.92  41.20  1016.04   73.37  468.91    465.049706
637   15.96  41.66  1011.93   55.47  466.39    467.134528
638   15.98  39.64  1009.31   81.21  467.22    463.631337
639   15.98  44.68  1018.48   85.94  462.77    462.431280
640   15.99  39.63  1006.09   89.92  464.95    462.081795
641   16.00  40.66  1016.12   89.23  457.12    462.722889
642   16.00  44.90  1020.50   80.89  461.50    463.238990
643   16.00  45.09  1014.31   60.02  458.46    465.732216
644   16.01  43.69  1017.12   62.43  465.89    465.939156
645   16.02  39.54  1007.73   72.81  466.15    464.675880
646   16.02  44.90  1009.30   82.62  455.48    462.036273
647   16.09  44.71  1017.86   42.74  464.95    468.463160
648   16.09  65.46  1013.84   85.52  454.88    456.721845
649   16.12  45.87  1008.15   86.12  457.41    460.997353
650   16.14  44.71  1014.83   39.41  468.88    468.605831
651   16.16  25.88  1009.58   72.24  461.86    468.045262
652   16.17  46.97  1014.22   85.80  456.08    461.167490
653   16.19  36.99  1007.37   92.40  462.94    462.096642
654   16.20  45.76  1014.73   89.84  460.87    460.863461
655   16.22  37.87  1022.36   83.13  461.06    464.391987
656   16.22  50.88  1014.33  100.09  454.94    458.020553
657   16.23  43.69  1016.40   68.90  466.22    464.512354
658   16.29  53.82  1014.97   73.15  459.95    461.134644
659   16.30  41.16  1007.88   76.61  463.47    463.189778
660   16.31  52.75  1024.40   55.69  456.58    464.677573
661   16.32  43.56  1014.40   59.77  463.57    465.540236
662   16.33  42.44  1013.98   84.90  462.44    462.100032
663   16.34  47.45  1009.41   92.96  448.59    459.283843
664   16.36  39.99  1008.91   72.48  462.50    464.052081
665   16.37  36.99  1006.37   90.11  463.76    462.002107
666   16.39  52.75  1024.42   54.61  459.48    464.682443
667   16.39  58.59  1014.58   90.34  455.05    457.213097
668   16.40  44.90  1009.22   82.31  456.11    461.342021
669   16.42  40.56  1020.36   50.62  472.17    467.915291
670   16.47  38.01  1022.30   72.29  461.54    465.451323
671   16.47  44.89  1010.04   82.01  459.69    461.320014
672   16.49  49.39  1018.10   93.13  461.54    459.193477
673   16.50  49.39  1018.35   93.42  462.48    459.152235
674   16.51  51.86  1022.37   81.18  442.48    460.629962
675   16.55  41.66  1011.45   55.53  465.14    465.948679
676   16.56  42.99  1007.48   74.45  464.62    462.514566
677   16.57  43.70  1015.67   71.95  465.78    463.349692
678   16.57  53.82  1015.17   63.69  462.52    461.990871
679   16.57  63.31  1016.19   81.02  454.78    457.179797
680   16.59  43.56  1012.88   59.61  465.03    464.919048
681   16.62  39.99  1007.07   77.14  463.74    462.720991
682   16.62  54.30  1017.99   63.76  459.59    461.994115
683   16.65  46.18  1010.60   95.69  465.60    458.701156
684   16.70  36.99  1006.19   89.33  464.70    461.464720
685   16.73  54.30  1017.96   59.44  460.54    462.409701
686   16.77  42.28  1007.53   73.19  465.52    462.474402
687   16.82  41.66  1010.49   63.14  465.64    464.239594
688   16.82  45.00  1022.05   37.28  468.22    468.120402
689   16.85  39.64  1008.82   80.81  464.20    461.971702
690   16.85  42.24  1017.43   66.01  472.63    464.183421
691   16.87  52.05  1012.70   71.63  460.31    460.494145
692   16.89  49.21  1015.19   70.39  458.25    461.547224
693   16.94  49.64  1024.43   69.22  459.25    462.266463
694   16.97  42.86  1013.92   74.80  463.62    462.229359
695   17.01  44.20  1019.18   61.23  457.26    464.225914
696   17.02  51.86  1021.53   81.28  460.00    459.563280
697   17.03  43.99  1021.50   82.32  460.25    461.351956
698   17.07  41.35  1005.88   83.43  464.60    460.499481
699   17.08  38.58  1015.41   73.42  461.49    463.406872
700   17.08  58.86  1016.04   87.46  449.98    456.353867
701   17.19  43.14  1014.34   68.62  464.72    462.670932
702   17.27  43.52  1021.37   76.73  460.08    461.811096
703   17.27  44.90  1007.85   78.80  454.19    460.064434
704   17.29  42.86  1014.38   72.30  464.27    462.014275
705   17.30  43.72  1009.64   77.86  456.55    460.583609
706   17.32  43.70  1015.13   61.66  464.50    463.360200
707   17.32  44.34  1019.52   56.24  468.80    464.348686
708   17.35  42.86  1014.62   74.16  465.16    461.646745
709   17.35  52.72  1026.31   58.01  463.65    462.496100
710   17.36  43.96  1013.02   79.59  466.36    460.430829
711   17.37  48.92  1011.91   58.40  455.53    462.175760
712   17.39  46.21  1013.94   82.73  454.06    459.428834
713   17.40  63.09  1020.84   92.58  453.00    454.325880
714   17.41  40.55  1003.91   76.87  461.47    460.839724
715   17.44  44.89  1009.90   80.54  457.67    459.652079
716   17.45  50.90  1012.16   83.80  458.67    457.842811
717   17.46  39.99  1008.52   69.73  461.01    462.299770
718   17.48  52.90  1020.03   76.47  458.34    458.996291
719   17.61  56.53  1019.50   82.30  457.01    456.946897
720   17.64  57.76  1016.28   85.04  455.75    455.920528
721   17.66  60.08  1017.22   86.96  456.62    455.099971
722   17.67  45.09  1014.26   51.92  457.67    463.688597
723   17.67  50.88  1015.64   90.55  456.16    456.722062
724   17.70  49.21  1015.16   67.91  455.97    460.344197
725   17.74  49.69  1006.09   80.70  457.05    457.543200
726   17.74  50.88  1015.56   89.78  457.71    456.692858
727   17.75  55.50  1020.15   81.26  459.43    457.138284
728   17.77  52.90  1020.11   81.51  457.98    457.708204
729   17.79  40.12  1012.74   79.03  459.13    460.617699
730   17.82  49.15  1020.73   70.25  457.35    460.239778
731   17.83  66.86  1011.65   77.31  456.56    454.035998
732   17.84  61.27  1020.10   70.68  454.57    457.065469
733   17.85  48.14  1017.16   86.68  451.90    457.746292
734   17.86  50.88  1015.59   88.28  457.33    456.682658
735   17.89  42.42  1008.92   65.08  467.59    461.575431
736   17.89  44.60  1014.48   42.51  463.99    464.777054
737   17.90  43.72  1008.64   74.73  452.55    459.801497
738   17.90  58.33  1013.60   85.81  452.28    454.946417
739   17.94  62.10  1019.81   82.65  453.55    454.895862
740   17.97  65.94  1012.92   88.22  448.88    452.507171
741   17.98  56.85  1012.28   84.52  448.71    455.241824
742   18.00  44.06  1016.80   78.88  454.59    459.582732
743   18.01  62.26  1011.89   89.29  451.14    453.107561
744   18.02  53.16  1013.41   82.84  458.01    456.421718
745   18.03  53.16  1013.02   81.95  456.55    456.500513
746   18.03  53.16  1013.06   82.03  458.04    456.492099
747   18.04  44.85  1015.13   48.40  463.31    463.619082
748   18.06  65.48  1018.79   77.95  454.34    454.424309
749   18.11  58.95  1016.61   89.17  454.29    454.141665
750   18.13  60.10  1009.67   84.75  455.82    453.896192
751   18.14  49.78  1002.95  100.09  451.44    453.664994
752   18.14  67.71  1003.82   95.69  442.45    449.907443
753   18.16  43.72  1008.64   75.22  454.98    459.228516
754   18.16  43.96  1012.78   78.33  465.26    459.052022
755   18.17  52.08  1001.91  100.09  451.06    452.949036
756   18.17  66.86  1011.29   78.48  452.77    453.180204
757   18.20  52.72  1025.87   54.26  463.47    461.367810
758   18.21  39.54  1009.81   70.92  461.73    460.896747
759   18.21  45.00  1022.86   48.84  467.54    463.818876
760   18.22  45.09  1013.62   75.56  454.74    459.127033
761   18.22  58.20  1017.09   81.92  451.04    455.213183
762   18.24  49.50  1014.37   79.36  464.13    457.495683
763   18.25  60.10  1009.72   90.15  456.25    452.881050
764   18.26  58.96  1014.04   69.70  457.43    456.480905
765   18.27  58.20  1018.34   72.73  448.17    456.559135
766   18.28  60.10  1009.72   85.79  452.93    453.459220
767   18.31  62.10  1020.38   79.02  455.24    454.758135
768   18.32  39.53  1008.15   64.85  454.44    461.437420
769   18.32  42.28  1007.86   45.62  460.27    463.533459
770   18.32  65.94  1012.74   86.77  450.50    452.028947
771   18.34  44.63  1000.76   89.27  455.22    455.963341
772   18.34  50.59  1018.42   83.95  457.17    456.691157
773   18.36  53.16  1013.31   83.18  458.47    455.708170
774   18.36  56.65  1020.29   82.00  456.49    455.578420
775   18.38  55.28  1020.22   68.33  451.29    457.869884
776   18.40  50.16  1011.51   98.07  453.78    454.060282
777   18.41  42.44  1012.66   65.93  463.20    460.747912
778   18.42  58.95  1016.95   86.77  452.10    453.921512
779   18.42  60.10  1009.77   86.75  451.93    453.053207
780   18.42  63.94  1020.47   74.47  450.55    454.758299
781   18.48  46.48  1007.53   82.57  461.49    456.760592
782   18.48  58.59  1015.61   85.14  452.52    454.024233
783   18.50  52.08  1006.23  100.09  451.23    452.664199
784   18.51  48.06  1015.14   79.83  455.44    457.328031
785   18.53  63.91  1010.26   97.80  440.64    450.319057
786   18.55  41.85  1015.24   62.47  467.51    461.339746
787   18.55  46.48  1007.34   80.67  452.37    456.887277
788   18.56  42.28  1007.75   60.89  462.05    460.833997
789   18.59  43.14  1011.92   52.63  464.48    462.106157
790   18.63  45.87  1007.98   79.90  453.79    457.049481
791   18.65  52.08  1005.48   99.94  449.55    452.335698
792   18.66  56.53  1020.13   80.04  459.45    455.302583
793   18.68  43.69  1016.68   48.88  463.02    462.729987
794   18.68  56.65  1020.38   80.26  455.79    455.222346
795   18.68  62.10  1019.78   83.67  453.25    453.317276
796   18.73  40.12  1013.19   74.12  454.71    459.557487
797   18.73  46.48  1007.19   79.23  450.74    456.737940
798   18.80  47.83  1005.86   76.77  453.90    456.516935
799   18.81  52.08  1004.43   99.60  450.87    451.991203
800   18.83  48.98  1016.33   74.23  453.28    457.395231
801   18.84  61.27  1019.64   71.95  454.47    454.913907
802   18.86  50.78  1008.46   91.67  446.70    453.703773
803   18.87  43.43  1009.16   69.50  454.58    458.808101
804   18.87  52.05  1012.02   53.46  458.64    459.231730
805   18.89  66.86  1012.38   71.96  454.02    452.831305
806   18.90  62.96  1020.69   80.57  455.88    453.204826
807   18.91  43.14  1013.56   58.34  460.19    460.789461
808   18.95  46.21  1013.47   81.22  457.58    456.601850
809   18.97  50.59  1016.01   74.90  459.68    456.600003
810   18.98  38.52  1018.85   63.16  454.60    461.533792
811   18.99  56.65  1020.46   77.16  457.55    455.083144
812   19.02  50.66  1013.04   85.25  455.42    454.734471
813   19.05  53.16  1013.22   82.80  455.76    454.425373
814   19.05  67.32  1013.20   83.14  447.47    450.843823
815   19.06  56.65  1020.82   82.14  455.70    454.250950
816   19.08  44.63  1020.05   41.07  455.95    463.137756
817   19.08  58.59  1013.42   68.88  451.05    455.060646
818   19.11  58.95  1017.07   85.49  449.89    452.787103
819   19.12  50.16  1011.52   99.71  451.49    452.433084
820   19.13  42.18  1001.45   98.77  456.04    453.720692
821   19.14  56.65  1020.84   82.97  458.06    453.977190
822   19.20  58.71  1009.80   84.62  448.17    452.208423
823   19.22  62.10  1019.43   79.19  451.80    452.900748
824   19.23  41.67  1012.53   48.86  465.66    461.837816
825   19.24  58.33  1013.65   85.47  449.26    452.415432
826   19.25  43.43  1012.01   73.26  451.08    457.758644
827   19.26  44.34  1019.45   51.32  467.72    461.318753
828   19.31  43.56  1013.65   41.54  463.35    462.371316
829   19.31  60.07  1014.86   69.37  453.47    454.293769
830   19.32  52.84  1004.29   83.51  450.88    453.153819
831   19.43  52.90  1018.35   61.12  456.08    457.337529
832   19.44  59.21  1018.50   88.35  448.04    451.784959
833   19.47  58.79  1016.80   87.26  450.17    451.852422
834   19.54  44.57  1007.19   78.93  450.54    455.695533
835   19.54  50.66  1014.70   84.53  456.61    453.971642
836   19.57  68.61  1011.13   96.40  448.73    447.416325
837   19.60  48.14  1013.18   68.71  456.57    456.668266
838   19.60  60.95  1015.40   84.26  456.06    451.386816
839   19.61  56.65  1020.64   63.74  457.41    455.859619
840   19.62  58.79  1017.59   87.39  446.29    451.608443
841   19.62  68.63  1012.26   68.05  453.84    451.542578
842   19.64  56.65  1020.79   73.88  456.03    454.334744
843   19.65  42.23  1013.04   75.90  461.16    456.985013
844   19.65  57.85  1011.73   93.89  450.50    450.359666
845   19.66  51.43  1010.17   84.19  459.12    453.229028
846   19.67  60.77  1017.33   88.13  444.87    450.889236
847   19.68  44.34  1019.49   49.50  468.27    460.777395
848   19.68  51.19  1008.64   94.88  452.04    451.566278
849   19.68  56.65  1020.75   67.25  456.89    455.221516
850   19.69  39.72  1001.49   60.34  456.55    458.863272
851   19.69  56.65  1020.84   72.14  455.07    454.496203
852   19.70  51.30  1014.88   88.10  454.94    452.997326
853   19.70  52.84  1004.86   89.72  444.64    451.561347
854   19.72  44.78  1009.27   39.18  464.54    461.264033
855   19.73  49.69  1007.78   73.02  454.28    454.962731
856   19.73  68.63  1012.41   74.12  450.26    450.457126
857   19.76  62.10  1020.07   73.55  450.44    452.734033
858   19.78  50.32  1008.62   96.40  449.23    451.366934
859   19.79  60.10  1010.47   84.04  452.41    450.863007
860   19.80  57.25  1010.84   88.90  451.75    450.875416
861   19.80  58.79  1017.04   87.71  449.66    451.169794
862   19.80  67.71  1005.58   69.65  446.03    450.647545
863   19.82  46.63  1013.17   87.10  456.36    453.936845
864   19.83  46.33  1013.27   96.40  451.22    452.643811
865   19.83  59.21  1012.67   96.42  440.03    449.380851
866   19.86  41.67  1012.31   53.90  462.86    459.869499
867   19.87  48.14  1016.94   81.56  451.14    454.579016
868   19.87  49.69  1012.23   68.57  456.03    455.704123
869   19.89  50.78  1008.85   92.97  446.35    451.559166
870   19.89  51.43  1007.38   91.79  448.85    451.449579
871   19.89  68.08  1012.65   80.25  448.71    449.410929
872   19.92  46.97  1014.32   69.17  459.39    456.368436
873   19.93  56.65  1020.70   62.82  456.53    455.381482
874   19.94  44.63  1004.73   78.48  455.58    454.774418
875   19.94  44.90  1008.52   74.69  459.47    455.568523
876   19.94  56.53  1020.48   76.43  453.80    453.388778
877   19.95  58.46  1017.45   89.46  447.10    450.740829
878   19.97  50.78  1008.75   92.70  446.57    451.436105
879   19.99  40.79  1003.15   87.55  455.28    454.183598
880   20.01  45.09  1014.21   38.19  453.96    461.173955
881   20.01  68.63  1012.34   69.49  454.50    450.586773
882   20.03  60.77  1017.23   87.82  449.31    450.231933
883   20.04  49.39  1020.62   78.84  449.63    454.635841
884   20.04  58.20  1017.56   74.31  448.92    452.851089
885   20.08  54.42  1011.79   89.35  457.14    451.052597
886   20.08  62.52  1017.99   75.74  450.98    451.523284
887   20.10  57.17  1011.96   87.68  452.67    450.585858
888   20.11  51.19  1007.82   92.06  449.03    451.081501
889   20.12  58.12  1015.47   79.38  453.33    451.806974
890   20.16  57.76  1019.34   72.10  455.13    453.196627
891   20.19  44.57  1009.20   72.13  454.36    455.597395
892   20.19  66.86  1012.97   64.70  454.84    451.430922
893   20.21  54.90  1016.82   66.56  454.23    454.416256
894   20.21  69.94  1009.33   83.96  447.06    447.518482
895   20.23  52.05  1012.15   47.49  457.57    457.489983
896   20.24  56.65  1020.72   62.90  455.49    454.773497
897   20.25  44.78  1007.93   40.16  462.44    459.989695
898   20.28  48.78  1017.40   82.51  451.59    453.527489
899   20.28  62.52  1017.89   75.67  452.45    451.139586
900   20.30  58.46  1015.93   82.13  448.79    451.011292
901   20.33  57.76  1016.47   75.35  450.25    452.160973
902   20.37  52.05  1012.34   62.57  456.11    455.035546
903   20.43  63.09  1016.46   91.78  445.58    448.241612
904   20.45  59.80  1015.13   79.21  452.96    450.748723
905   20.50  49.69  1009.60   70.81  452.94    453.948076
906   20.51  39.72  1002.25   47.97  452.39    459.148020
907   20.51  68.08  1012.73   78.05  445.96    448.542493
908   20.56  60.08  1017.79   78.08  452.80    450.848130
909   20.56  64.45  1012.24   53.09  458.97    452.952338
910   20.58  39.53  1005.68   62.09  460.10    457.279778
911   20.59  59.80  1015.27   77.94  453.83    450.675349
912   20.60  59.15  1013.32   91.07  443.76    448.743970
913   20.61  60.10  1010.84   80.57  450.46    449.817677
914   20.61  62.91  1013.24   79.54  446.53    449.462732
915   20.61  63.86  1015.43   73.86  446.34    450.232761
916   20.61  65.61  1014.91   83.82  449.72    448.301163
917   20.64  61.86  1012.81   99.97  447.14    446.651320
918   20.65  41.67  1012.76   45.27  455.50    459.641286
919   20.65  57.50  1016.04   87.45  448.22    449.808414
920   20.68  63.86  1015.73   74.36  447.84    450.049225
921   20.69  50.78  1008.71   91.95  447.58    450.153489
922   20.71  58.18  1007.63   98.44  447.06    447.235289
923   20.72  63.94  1017.17   59.83  447.69    452.188985
924   20.76  44.58  1017.09   57.47  462.01    457.276364
925   20.76  59.04  1012.51   85.39  448.92    449.225436
926   20.76  69.05  1001.89   77.86  442.82    446.963700
927   20.77  43.77  1010.76   63.12  453.46    456.119490
928   20.78  58.86  1016.02   77.29  446.20    450.699103
929   20.80  69.45  1013.70   82.48  443.77    447.074282
930   20.82  63.77  1014.28   86.37  448.90    447.931567
931   20.83  44.78  1008.51   35.90  460.60    459.539629
932   20.85  59.21  1012.90   75.97  444.44    450.415392
933   20.87  57.19  1006.50   77.00  445.95    450.209168
934   20.88  59.80  1015.66   75.34  453.18    450.527020
935   20.90  67.07  1005.43   82.85  443.46    446.747552
936   20.92  70.02  1010.23   95.58  444.64    444.507200
937   20.94  44.78  1008.14   35.70  465.57    459.326511
938   20.94  68.12  1012.43   78.20  446.41    447.656812
939   20.95  44.89  1010.48   67.97  450.39    454.762752
940   20.95  48.14  1013.30   67.72  452.38    454.218513
941   20.95  70.72  1009.96   87.73  445.66    445.397989
942   20.96  69.48  1011.04   82.63  444.31    446.519760
943   20.98  60.10  1011.07   79.44  450.95    449.287571
944   20.99  67.07  1005.17   82.41  442.02    446.616977
945   21.01  58.96  1014.33   61.80  453.88    452.352635
946   21.06  50.59  1016.42   66.12  454.15    453.882915
947   21.06  62.91  1011.92   75.52  455.22    449.073729
948   21.06  67.07  1004.90   84.09  446.44    446.214900
949   21.08  44.05  1008.13   72.52  449.60    453.866367
950   21.11  58.66  1011.70   68.71  457.89    451.012414
951   21.11  59.39  1013.87   85.29  446.02    448.588381
952   21.13  51.43  1007.43   88.72  445.40    449.509730
953   21.14  58.05  1012.98   87.27  449.74    448.503305
954   21.14  58.98  1009.05   94.36  448.31    446.917221
955   21.16  45.38  1014.65   73.06  458.63    453.832472
956   21.18  44.57  1007.27   73.67  449.93    453.306065
957   21.18  60.10  1011.02   78.19  452.39    449.080081
958   21.19  74.93  1015.75   80.84  443.29    445.361905
959   21.26  50.32  1008.41   87.22  446.22    449.834321
960   21.28  70.32  1011.06   90.12  439.00    444.602092
961   21.32  45.01  1012.23   59.94  452.75    455.333039
962   21.32  49.02  1008.81   85.81  445.65    450.280955
963   21.33  58.46  1016.17   79.73  445.27    449.394229
964   21.33  60.10  1010.97   78.36  451.95    448.761884
965   21.33  63.86  1020.33   72.13  445.02    449.495262
966   21.34  59.80  1016.92   77.06  450.74    449.491411
967   21.36  58.95  1018.35   78.87  443.93    449.517124
968   21.36  68.28  1007.60   72.37  445.91    447.264084
969   21.38  44.05  1005.69   81.66  445.71    451.755737
970   21.39  51.30  1013.39   89.05  452.70    449.477692
971   21.39  63.90  1013.44   70.95  449.38    448.980797
972   21.40  44.57  1005.70   73.09  445.09    452.838519
973   21.40  68.28  1008.20   60.34  450.22    448.990709
974   21.41  56.90  1007.03   79.41  441.41    448.931469
975   21.42  43.79  1015.76   43.08  462.19    458.191223
976   21.44  51.19  1009.10   84.94  446.17    449.659001
977   21.44  63.09  1016.56   90.11  444.19    446.545237
978   21.45  45.09  1013.83   52.26  453.15    456.312953
979   21.45  60.08  1017.92   72.70  451.49    449.926873
980   21.45  66.05  1014.81   73.73  453.38    448.035018
981   21.46  46.63  1012.97   71.29  452.10    453.063614
982   21.47  58.79  1017.00   76.97  446.33    449.512113
983   21.49  56.90  1007.47   66.66  452.46    450.672948
984   21.52  66.51  1015.32   72.85  444.87    447.955206
985   21.53  52.84  1005.06   88.22  444.04    448.266659
986   21.54  58.49  1010.85   78.90  449.12    448.669682
987   21.54  69.48  1011.04   80.48  443.15    445.714670
988   21.55  44.57  1006.03   71.54  446.84    452.802170
989   21.55  60.27  1017.42   92.59  443.93    446.744366
990   21.57  66.49  1014.76   68.19  455.18    448.497961
991   21.58  63.87  1015.27   63.15  451.88    449.908634
992   21.61  41.54  1014.50   75.62  458.47    453.536203
993   21.61  49.39  1019.41   78.20  449.26    451.602411
994   21.62  50.05  1007.20   92.90  444.16    448.280151
995   21.65  58.18  1008.33   95.28  441.05    445.940139
996   21.69  44.57  1005.84   71.53  447.88    452.518123
997   21.71  65.27  1013.24   63.58  444.91    449.080854
998   21.73  69.05  1001.31   86.64  439.01    443.764678
999   21.75  59.80  1016.65   72.94  453.17    449.279629
1000  21.75  60.27  1018.55   87.81  444.19    447.147893
1001  21.78  51.43  1007.45   88.71  446.56    448.259067
1002  21.79  58.20  1017.21   66.74  446.94    450.551424
1003  21.79  60.93  1006.44   87.68  443.01    445.939305
1004  21.80  51.30  1012.07   89.51  450.25    448.512302
1005  21.80  65.94  1012.02   63.52  448.66    448.649651
1006  21.81  43.77  1011.97   64.72  453.13    453.978586
1007  21.81  65.46  1013.97   52.16  444.66    450.565974
1008  21.82  50.66  1013.74   73.60  455.20    451.090185
1009  21.83  41.10  1001.91   41.79  453.38    457.131744
1010  21.83  62.91  1011.07   91.34  443.76    445.211503
1011  21.86  60.27  1016.06   90.48  446.31    446.343515
1012  21.88  59.39  1015.58   87.19  442.92    446.965205
1013  21.89  63.94  1019.55   55.09  447.74    450.817456
1014  21.91  70.32  1009.17   90.57  439.29    443.167412
1015  21.92  58.79  1010.09   89.70  446.71    446.224554
1016  21.93  61.45  1008.92   98.54  443.91    444.157259
1017  21.94  57.50  1014.64   78.52  451.10    448.508937
1018  21.94  58.79  1010.30   88.21  447.52    446.420434
1019  21.94  64.69  1007.39   77.58  449.36    446.263271
1020  21.95  59.43  1010.29   74.67  442.84    448.215980
1021  21.96  59.80  1016.72   72.60  452.48    448.929868
1022  21.97  58.12  1014.21   85.93  448.91    447.180521
1023  21.99  58.96  1014.09   61.30  453.38    450.515768
1024  21.99  71.85  1009.50   74.77  441.10    444.963414
1025  22.00  51.30  1012.87   85.79  450.18    448.734331
1026  22.00  59.54  1004.55   95.25  439.37    444.622627
1027  22.02  46.93  1014.32   55.92  451.92    454.260738
1028  22.04  69.51  1013.25   56.15  446.34    448.471933
1029  22.06  59.39  1015.26   85.04  441.31    446.905604
1030  22.07  60.08  1017.68   71.23  452.56    448.925893
1031  22.08  45.61  1014.02   75.71  456.71    451.562722
1032  22.09  65.59  1015.54   72.44  447.28    447.162855
1033  22.10  68.12  1012.71   79.77  440.08    445.213113
1034  22.12  69.71  1009.70   90.22  434.42    443.008641
1035  22.18  69.05  1002.75   70.84  442.14    445.318824
1036  22.19  58.49  1010.91   77.03  449.40    447.693612
1037  22.21  61.87  1010.90   54.22  446.62    450.139048
1038  22.21  69.71  1009.69   96.85  440.14    441.867048
1039  22.22  48.98  1015.87   53.18  447.10    453.889762
1040  22.23  46.93  1013.09   58.02  448.27    453.449201
1041  22.25  51.86  1013.08   83.64  451.04    448.443240
1042  22.25  59.80  1016.79   69.02  451.64    448.898451
1043  22.26  69.04  1010.48   84.33  444.73    443.828375
1044  22.28  58.12  1014.54   83.27  448.97    446.997483
1045  22.30  50.78  1008.85   81.27  449.86    448.617439
1046  22.32  59.80  1016.82   64.18  451.21    449.471932
1047  22.32  64.27  1014.35   82.98  446.62    445.413870
1048  22.34  63.73  1014.37   83.19  444.39    445.480917
1049  22.35  63.94  1010.32   93.02  443.90    443.645573
1050  22.35  65.61  1016.27   73.93  448.41    446.498435
1051  22.36  59.44  1013.10   84.74  446.75    446.182407
1052  22.36  64.15  1021.05   68.43  453.94    448.034617
1053  22.39  58.18  1008.52   87.48  448.37    445.666122
1054  22.39  59.04  1011.78   86.39  445.52    445.876108
1055  22.41  66.56  1003.30   88.71  435.75    442.933891
1056  22.45  57.76  1017.55   58.60  450.61    450.603225
1057  22.45  63.77  1014.57   87.44  444.26    444.655064
1058  22.46  48.41  1008.66   80.85  442.57    448.945506
1059  22.46  58.33  1013.21   68.68  445.90    448.618048
1060  22.49  71.29  1008.24   75.80  442.58    443.885778
1061  22.50  58.79  1017.48   73.02  443.35    448.140702
1062  22.50  64.69  1007.03   74.92  440.73    445.541850
1063  22.52  66.48  1003.87   78.29  435.02    444.308133
1064  22.53  58.62  1016.28   72.78  449.02    448.062542
1065  22.54  61.27  1019.12   54.02  450.01    450.350467
1066  22.54  63.07  1011.71   81.64  442.28    445.269266
1067  22.55  69.84  1006.57   76.29  438.54    443.924124
1068  22.55  70.79  1006.19   92.56  436.43    441.282875
1069  22.57  63.94  1013.49   81.61  443.58    445.143777
1070  22.57  68.30  1017.43   87.69  440.81    443.490555
1071  22.58  43.79  1015.66   44.18  460.30    455.785152
1072  22.58  52.30  1009.04   78.99  445.60    448.046474
1073  22.58  59.14  1017.20   80.91  439.78    446.725348
1074  22.61  42.80  1014.24   69.71  460.26    452.134201
1075  22.61  59.87  1019.12   66.12  441.20    448.799346
1076  22.69  49.21  1012.64   46.83  449.01    453.589250
1077  22.69  64.45  1012.82   45.03  450.65    450.066902
1078  22.69  65.18  1012.47   80.90  441.18    444.623702
1079  22.70  48.14  1014.06   60.09  448.96    452.017964
1080  22.70  60.84  1019.15   71.48  438.59    447.604439
1081  22.72  58.82  1012.54   77.72  448.67    446.621086
1082  22.72  69.13  1010.81   92.43  438.01    441.763905
1083  22.74  61.87  1009.66   55.03  444.59    448.897651
1084  22.75  58.79  1011.44   84.47  445.67    445.496463
1085  22.76  44.05  1006.95   74.07  450.31    450.303730
1086  22.76  49.21  1014.35   48.85  448.73    453.298761
1087  22.77  69.84  1005.75   84.26  436.75    442.270362
1088  22.78  58.59  1012.84   65.55  445.45    448.362477
1089  22.78  59.92  1011.28   88.78  440.87    444.515103
1090  22.84  59.39  1014.61   80.36  443.71    446.030906
1091  22.85  47.43  1008.13   66.36  448.15    450.508237
1092  22.86  58.96  1014.03   54.96  451.82    449.757664
1093  22.88  65.48  1017.33   66.26  447.14    446.713748
1094  22.88  69.45  1014.02   65.13  441.76    445.619345
1095  22.89  48.98  1014.55   48.21  448.56    453.214999
1096  22.89  62.39  1007.84   88.16  448.13    443.497520
1097  22.89  65.34  1015.53   61.00  450.53    447.350157
1098  22.92  60.37  1007.05   89.94  438.86    443.619296
1099  22.92  61.90  1013.27   78.32  446.08    445.439322
1100  22.98  58.46  1016.06   72.69  445.05    447.229671
1101  22.98  69.84  1005.55   84.10  437.49    441.872363
1102  22.98  73.17  1011.94   90.13  438.50    440.682680
1103  22.99  46.21  1010.71   60.11  444.36    451.664146
1104  22.99  46.93  1014.15   49.42  451.41    453.324136
1105  22.99  60.77  1017.97   78.47  447.62    445.946765
1106  22.99  62.96  1019.60   65.05  449.40    447.491163
1107  22.99  68.67  1006.65   77.62  446.67    443.179625
1108  23.00  49.50  1014.15   66.68  454.44    450.146219
1109  23.00  63.78  1015.85   70.46  444.62    446.172946
1110  23.01  44.05  1006.56   74.95  450.67    449.661395
1111  23.03  59.04  1011.85   81.24  444.85    445.398626
1112  23.03  68.08  1012.63   70.37  441.71    444.794015
1113  23.04  63.86  1019.83   59.78  446.22    447.957846
1114  23.04  74.99  1005.44   92.86  437.65    439.185791
1115  23.07  49.02  1009.07   84.10  444.22    447.176094
1116  23.07  65.46  1014.07   46.77  446.19    448.930060
1117  23.08  48.41  1008.44   82.35  443.50    447.512892
1118  23.08  61.86  1013.44   84.64  441.44    444.232558
1119  23.09  73.50  1011.40   89.76  438.56    440.398248
1120  23.13  71.25  1002.49   94.59  431.91    439.452113
1121  23.14  58.95  1017.52   66.25  442.27    447.857211
1122  23.17  51.19  1009.50   76.15  441.77    447.636942
1123  23.18  72.99  1009.01   90.09  439.12    440.109098
1124  23.19  49.82  1014.59   70.52  451.08    449.175598
1125  23.19  67.07  1005.67   65.19  442.45    444.926268
1126  23.20  48.41  1008.64   80.92  444.69    447.506320
1127  23.20  73.17  1012.00   89.92  438.64    440.293853
1128  23.22  66.56  1002.47   85.39  437.11    441.788278
1129  23.23  63.31  1012.52   75.10  441.50    444.898520
1130  23.23  64.69  1008.12   76.60  444.01    443.977449
1131  23.25  56.90  1006.82   76.37  442.76    445.808770
1132  23.25  63.86  1017.82   59.64  445.12    447.409581
1133  23.26  63.56  1013.64   71.30  446.67    445.423845
1134  23.27  64.69  1006.84   70.53  438.08    444.681583
1135  23.28  60.84  1017.91   67.50  444.13    446.965364
1136  23.29  62.91  1013.35   68.25  444.61    445.949360
1137  23.30  72.99  1008.54   92.11  437.62    439.544698
1138  23.33  73.18  1012.51   91.29  436.33    439.882273
1139  23.34  59.44  1012.67   80.76  445.24    444.837734
1140  23.34  73.50  1011.43   89.74  441.14    439.921396
1141  23.35  63.47  1011.78   84.24  437.87    443.233585
1142  23.35  71.77  1005.99   90.79  434.60    439.737393
1143  23.36  56.89  1014.23   78.34  440.51    445.914939
1144  23.36  59.15  1013.71   86.64  442.53    444.098350
1145  23.36  73.18  1011.96   89.15  435.85    440.091816
1146  23.38  59.07  1009.29   92.40  442.83    442.879628
1147  23.38  65.06  1014.12   59.36  443.80    446.599289
1148  23.39  74.22  1009.83   86.05  439.92    440.053490
1149  23.42  63.07  1011.72   75.81  444.23    444.423174
1150  23.44  72.24  1011.28   88.03  438.34    440.279894
1151  23.45  51.95  1005.23   76.17  449.07    446.556855
1152  23.45  66.48  1003.66   75.83  435.13    442.856074
1153  23.46  47.01  1014.41   69.19  457.76    449.534756
1154  23.47  65.61  1014.57   69.83  447.16    444.797841
1155  23.48  65.12  1015.82   60.83  445.66    446.315395
1156  23.48  70.79  1006.70   88.57  432.25    440.112626
1157  23.48  72.99  1009.61   88.16  437.10    439.860837
1158  23.48  73.67  1007.07   88.49  437.19    439.436385
1159  23.49  47.45  1008.46   66.18  446.72    449.321912
1160  23.50  50.23  1017.51   75.15  457.51    448.037723
1161  23.51  58.79  1016.44   65.38  445.75    447.222424
1162  23.51  70.04  1011.02   81.39  435.78    441.640847
1163  23.53  72.24  1010.84   94.33  436.69    439.151436
1164  23.54  67.83  1009.44   65.48  426.24    444.326293
1165  23.56  49.16  1002.54   69.07  443.02    447.857035
1166  23.56  49.16  1003.31   66.98  445.36    448.224607
1167  23.57  64.15  1020.95   68.19  450.08    445.727583
1168  23.57  70.04  1011.06   82.79  437.53    441.324140
1169  23.58  58.82  1009.68   81.38  445.01    444.195532
1170  23.59  43.77  1010.85   55.98  448.42    451.729051
1171  23.59  71.73  1009.69   87.06  435.67    440.129783
1172  23.61  49.16  1002.39   65.63  443.50    448.250207
1173  23.62  56.85  1011.11   64.44  442.96    447.197148
1174  23.62  68.63  1013.18   50.57  447.30    446.452065
1175  23.63  65.59  1013.10   76.95  440.56    443.335878
1176  23.63  73.50  1011.46   89.39  438.21    439.415531
1177  23.66  77.54  1008.50   85.32  435.38    438.703190
1178  23.67  71.77  1004.76   86.13  434.47    439.699830
1179  23.68  49.02  1007.53   86.05  440.68    445.589664
1180  23.68  51.30  1011.86   71.24  451.67    447.534198
1181  23.69  58.05  1012.08   74.26  444.46    445.409375
1182  23.71  50.23  1017.55   73.24  458.59    447.914552
1183  23.73  63.94  1010.70   87.10  441.78    441.878308
1184  23.74  65.34  1013.70   62.90  447.31    445.284489
1185  23.76  58.41  1013.85   85.38  445.85    443.706511
1186  23.76  61.50  1009.15   68.52  441.16    445.013038
1187  23.77  51.43  1006.67   84.09  441.54    445.031129
1188  23.77  69.13  1011.05   89.41  434.08    440.198711
1189  23.79  50.16  1005.32   75.82  435.49    446.405709
1190  23.80  48.60  1002.43   67.32  440.89    447.780063
1191  23.81  57.50  1015.53   70.66  448.72    446.121062
1192  23.83  50.32  1008.41   72.23  445.17    447.063923
1193  23.84  49.21  1013.10   44.72  445.44    451.716331
1194  23.85  72.43  1008.01   88.34  439.02    439.130270
1195  23.86  73.50  1011.34   87.32  438.62    439.264098
1196  23.87  60.27  1018.94   77.16  439.86    444.644106
1197  23.87  63.94  1019.02   44.28  445.11    448.532153
1198  23.88  69.94  1007.48   61.00  440.63    443.638409
1199  23.90  61.41  1011.95   67.87  451.99    445.088202
1200  23.92  61.87  1009.63   54.16  441.15    446.746085
1201  23.94  51.95  1008.18   71.87  451.84    446.479157
1202  23.94  62.08  1022.47   61.97  447.50    446.561107
1203  23.95  51.86  1014.24   68.28  449.81    447.499347
1204  23.95  58.79  1010.45   74.34  448.32    444.579015
1205  23.96  58.33  1013.37   59.97  446.01    447.008416
1206  23.97  44.57  1007.35   62.71  448.17    449.529938
1207  23.97  68.67  1006.63   76.83  441.53    441.402972
1208  23.99  50.32  1008.41   67.40  444.23    447.459907
1209  24.02  77.54  1008.33   83.92  438.52    438.199197
1210  24.03  62.44  1010.96   79.88  430.66    442.748046
1211  24.04  59.43  1007.60   76.98  437.51    443.628722
1212  24.06  58.20  1017.46   48.04  445.91    448.921246
1213  24.06  58.98  1010.66   81.16  443.75    443.341668
1214  24.11  68.63  1014.34   45.28  448.45    446.373067
1215  24.12  51.43  1006.55   83.77  441.49    444.392945
1216  24.12  58.66  1011.55   58.96  450.69    446.616702
1217  24.13  45.61  1012.63   71.36  453.19    448.130007
1218  24.15  63.13  1013.80   92.10  440.15    440.793104
1219  24.16  48.98  1015.19   42.55  459.27    451.643144
1220  24.17  59.44  1012.66   78.53  447.13    443.561289
1221  24.17  71.58  1010.16   89.96  436.27    438.663660
1222  24.18  59.92  1009.88   79.54  438.85    443.048676
1223  24.21  70.98  1007.02   95.57  441.78    437.662090
1224  24.21  71.77  1004.52   84.96  433.42    438.809394
1225  24.22  49.82  1014.61   66.82  452.20    447.730269
1226  24.22  71.14  1009.38   64.53  438.88    442.323141
1227  24.23  58.79  1009.80   75.75  444.01    443.780333
1228  24.24  72.43  1008.02   86.40  436.60    438.661841
1229  24.26  56.57  1013.86   70.35  442.90    445.394217
1230  24.26  66.44  1011.33   55.32  445.63    444.920073
1231  24.27  57.85  1012.81   63.48  445.10    445.972519
1232  24.27  74.99  1007.73   82.49  438.26    438.512506
1233  24.28  68.31  1009.94   77.08  440.07    441.127774
1234  24.31  65.34  1013.82   63.85  449.88    444.056230
1235  24.32  65.48  1017.55   59.02  443.31    445.010288
1236  24.33  46.93  1013.51   52.63  449.07    450.219106
1237  24.33  46.93  1013.72   48.27  447.43    450.872237
1238  24.33  49.16  1003.46   61.04  441.20    447.618132
1239  24.34  48.78  1018.00   73.44  448.54    447.068346
1240  24.34  66.05  1019.26   74.58  440.67    442.698919
1241  24.35  59.21  1018.21   54.46  444.35    447.234578
1242  24.35  66.49  1012.48   62.12  439.15    443.835648
1243  24.37  63.47  1012.77   75.22  445.60    442.662590
1244  24.38  57.17  1009.85   74.46  444.59    444.087154
1245  24.38  60.84  1017.85   62.23  440.85    445.607534
1246  24.39  58.41  1013.65   80.93  445.39    443.124221
1247  24.40  67.45  1015.63   57.10  435.47    444.488612
1248  24.41  73.67  1007.39   86.92  435.56    437.897640
1249  24.43  58.05  1011.88   71.39  445.68    444.384422
1250  24.43  58.95  1017.18   57.73  441.40    446.584216
1251  24.43  59.87  1019.08   60.57  441.61    446.095221
1252  24.44  47.93  1003.13   67.04  440.53    446.810476
1253  24.45  65.12  1015.92   57.19  445.01    444.983557
1254  24.46  61.90  1013.88   87.16  441.34    441.228980
1255  24.48  69.13  1002.88   69.43  432.71    441.078805
1256  24.48  69.45  1013.86   62.39  435.74    442.919876
1257  24.49  60.27  1018.96   72.62  440.87    444.112144
1258  24.49  65.06  1014.07   63.32  441.40    443.876515
1259  24.49  65.59  1011.52   85.12  441.80    440.356608
1260  24.51  68.63  1014.15   45.10  447.66    445.612319
1261  24.52  56.85  1012.59   54.47  438.89    447.036091
1262  24.53  74.78  1009.90   78.34  446.30    438.845419
1263  24.54  44.89  1010.05   59.13  445.11    449.092765
1264  24.54  58.66  1011.63   57.62  448.11    446.008578
1265  24.54  66.49  1011.10   69.14  437.38    442.332748
1266  24.54  72.24  1011.43   74.10  435.08    440.202479
1267  24.56  71.94  1006.81   89.59  437.97    437.602915
1268  24.57  49.82  1016.82   65.25  452.30    447.464115
1269  24.58  49.02  1008.85   79.32  442.47    444.942932
1270  24.60  48.78  1018.10   73.71  442.23    446.535599
1271  24.60  63.94  1012.87   80.28  439.63    441.371766
1272  24.62  58.66  1011.43   56.61  449.80    445.985327
1273  24.63  63.90  1014.53   75.24  440.23    442.194244
1274  24.64  58.79  1009.82   73.96  444.26    443.252259
1275  24.65  64.63  1020.52   53.45  446.04    445.640019
1276  24.66  69.94  1006.56   60.91  432.68    442.072143
1277  24.67  61.50  1009.06   72.77  437.37    442.630472
1278  24.67  69.14  1006.25   88.51  440.03    438.200790
1279  24.70  44.57  1008.24   57.62  444.65    448.936861
1280  24.70  58.82  1009.40   75.91  442.98    442.810392
1281  24.74  59.39  1015.23   74.64  437.49    443.251002
1282  24.75  63.57  1010.47   84.24  445.30    440.401624
1283  24.77  57.17  1010.66   73.00  441.12    443.613829
1284  24.77  69.71  1009.86   85.56  441.29    438.590023
1285  24.78  66.49  1010.55   68.12  436.62    441.973848
1286  24.78  68.94  1007.29   70.56  435.93    440.741686
1287  24.80  66.51  1016.74   65.72  441.34    442.784311
1288  24.82  66.48  1006.40   70.21  433.62    441.256456
1289  24.82  72.99  1007.81   84.72  435.68    437.631475
1290  24.86  44.05  1005.69   66.65  447.20    447.233006
1291  24.87  68.61  1011.19   55.69  450.54    443.137087
1292  24.89  66.49  1010.15   65.65  436.39    442.089435
1293  24.93  47.01  1014.28   66.04  455.06    447.148289
1294  24.94  59.07  1008.89   84.79  440.12    440.948209
1295  24.94  74.33  1014.30   75.34  435.21    438.962618
1296  24.95  64.33  1011.34   81.05  440.97    440.362555
1297  24.96  65.18  1012.68   76.19  436.24    440.949409
1298  24.97  54.20  1012.68   74.25  439.71    443.950624
1299  24.97  58.95  1017.19   56.24  440.03    445.760814
1300  24.97  59.87  1018.70   59.94  443.70    445.114613
1301  24.97  68.61  1011.08   58.94  447.83    442.461138
1302  24.98  58.05  1011.69   69.97  447.15    443.515238
1303  24.98  58.98  1010.34   78.56  441.33    441.920366
1304  25.00  69.71  1009.23   80.92  438.38    438.771983
1305  25.02  69.75  1010.04   91.86  437.87    437.193449
1306  25.03  59.21  1017.28   56.96  446.33    445.482554
1307  25.04  65.48  1017.66   57.08  440.92    443.913480
1308  25.04  66.48  1004.12   63.01  433.83    441.696834
1309  25.04  70.47  1006.82   84.75  433.10    437.750436
1310  25.07  77.95  1012.87   83.00  438.55    436.575490
1311  25.09  65.46  1015.29   40.13  442.99    446.101749
1312  25.09  69.68  1012.18   91.33  439.77    437.327411
1313  25.09  71.58  1010.17   86.01  434.51    437.466160
1314  25.10  43.77  1010.90   49.68  444.99    449.739605
1315  25.10  71.77  1004.34   82.80  429.70    437.393168
1316  25.13  68.63  1013.57   43.44  446.36    444.611378
1317  25.14  60.93  1007.44   76.71  437.40    441.159378
1318  25.14  67.32  1013.96   41.78  435.39    445.192604
1319  25.14  69.13  1011.15   85.67  433.95    438.109922
1320  25.15  73.67  1007.42   85.48  435.90    436.682802
1321  25.16  43.21  1011.73   88.69  442.29    444.140291
1322  25.17  68.08  1012.83   60.87  437.01    442.068422
1323  25.18  61.08  1013.08   80.75  445.64    440.914613
1324  25.18  69.23  1013.26   57.45  438.72    442.296334
1325  25.18  71.98  1006.71   89.86  432.88    436.349529
1326  25.19  64.44  1014.75   64.38  444.35    442.581623
1327  25.21  59.21  1013.19   62.85  438.70    443.943172
1328  25.21  63.21  1012.24   85.14  441.04    439.616908
1329  25.23  60.84  1017.79   56.42  442.02    444.810692
1330  25.24  67.45  1013.56   50.91  438.99    443.602863
1331  25.24  68.28  1000.26   78.17  435.90    438.336523
1332  25.24  71.14  1008.73   79.39  435.09    438.135029
1333  25.26  61.08  1013.68   71.72  447.46    442.126444
1334  25.27  69.89  1015.21   79.33  436.33    438.925085
1335  25.30  58.46  1015.91   69.71  439.25    443.177257
1336  25.30  59.43  1009.15   58.30  442.50    444.049591
1337  25.30  71.29  1007.86   62.98  437.17    440.304963
1338  25.31  65.59  1011.16   79.71  440.96    439.534857
1339  25.32  71.94  1009.94   62.93  435.06    440.280952
1340  25.33  71.32  1007.05   85.31  434.68    436.916183
1341  25.34  59.39  1014.02   73.58  439.80    442.149823
1342  25.35  74.33  1015.29   77.84  435.66    437.887685
1343  25.36  61.41  1011.89   55.64  452.29    444.051311
1344  25.37  58.33  1013.49   51.42  444.46    445.545783
1345  25.38  70.94  1007.87   73.59  446.31    438.690946
1346  25.38  71.73  1009.97   72.60  434.44    438.809363
1347  25.41  48.06  1013.12   46.52  444.01    448.713800
1348  25.41  77.54  1009.68   89.09  434.09    434.873803
1349  25.42  69.71  1009.29   82.50  435.59    437.736262
1350  25.42  73.17  1012.29   85.86  437.06    436.627694
1351  25.42  73.21  1001.91   93.78  432.04    434.617340
1352  25.42  75.60  1017.39   77.63  438.24    437.637625
1353  25.43  70.17  1000.46   87.84  436.43    436.104459
1354  25.44  61.25  1012.57   87.65  441.77    439.322640
1355  25.45  74.33  1015.53   80.95  435.12    437.260652
1356  25.46  56.89  1012.59   62.90  443.50    443.983236
1357  25.47  70.36  1005.79   77.73  437.02    437.888683
1358  25.48  58.95  1017.02   51.16  440.42    445.504332
1359  25.52  69.75  1010.36   90.06  435.12    436.517660
1360  25.52  71.98  1006.89   86.94  433.42    436.134344
1361  25.54  49.16  1003.64   47.40  443.55    447.288681
1362  25.54  70.47  1009.28   73.50  436.16    438.627423
1363  25.56  50.05  1005.67   69.29  442.49    444.000163
1364  25.56  60.32  1016.28   59.84  445.01    443.681982
1365  25.56  69.13  1002.46   68.26  434.48    439.132139
1366  25.56  70.32  1009.07   90.63  433.72    436.110228
1367  25.56  74.67  1016.62   76.10  435.81    437.759963
1368  25.58  47.01  1014.50   63.53  454.39    446.278607
1369  25.59  61.08  1013.19   77.28  443.91    440.638943
1370  25.59  65.46  1014.47   37.89  444.90    445.397342
1371  25.60  66.48  1006.16   69.34  435.12    439.859333
1372  25.61  58.86  1013.90   54.90  444.77    444.476437
1373  25.63  71.58  1010.14   87.57  433.76    436.194568
1374  25.64  63.47  1012.33   68.35  442.62    441.179330
1375  25.64  70.72  1010.16   84.00  441.68    436.912111
1376  25.65  49.30  1003.73   68.48  440.05    443.973785
1377  25.65  78.92  1010.83   86.56  434.78    434.529518
1378  25.66  71.77  1006.76   84.76  429.25    436.224096
1379  25.67  58.59  1013.00   62.34  451.03    443.269410
1380  25.68  59.44  1012.33   67.29  444.36    442.261554
1381  25.69  57.32  1012.34   44.18  441.43    446.142912
1382  25.69  59.07  1006.89   82.34  440.60    439.696164
1383  25.71  66.05  1018.58   66.23  444.35    441.219138
1384  25.72  74.67  1016.64   75.93  434.83    437.477775
1385  25.73  66.54  1010.07   55.97  437.07    441.862341
1386  25.74  65.38  1009.60   54.34  452.94    442.331782
1387  25.76  71.06  1007.93   90.40  433.75    435.480712
1388  25.77  62.96  1019.86   58.07  442.83    443.168376
1389  25.77  65.48  1018.07   51.47  440.96    443.357184
1390  25.79  67.17  1007.89   81.38  440.75    437.705267
1391  25.79  75.60  1017.46   75.63  434.65    437.221410
1392  25.80  71.58  1010.08   85.14  435.20    436.216268
1393  25.82  61.08  1013.64   66.40  448.46    441.819114
1394  25.84  67.83  1009.26   59.55  433.32    440.740360
1395  25.86  61.08  1013.51   67.50  449.67    441.570909
1396  25.87  47.01  1014.67   61.87  452.32    445.975241
1397  25.87  57.32  1012.06   44.13  442.87    445.780219
1398  25.88  63.47  1011.95   65.87  443.94    441.047253
1399  25.88  69.13  1002.44   85.67  426.14    435.973513
1400  25.89  58.86  1014.16   52.95  445.17    444.241992
1401  25.89  66.49  1013.08   63.16  434.67    440.762354
1402  25.92  50.16  1003.95   71.30  440.98    442.845113
1403  25.94  66.49  1012.83   61.81  433.38    440.842497
1404  25.95  59.92  1010.05   76.05  443.93    440.157577
1405  25.95  65.61  1014.36   52.54  443.88    442.519466
1406  25.97  57.32  1012.13   47.48  442.73    445.104336
1407  26.02  70.79  1004.21   79.12  428.72    436.389214
1408  26.06  54.50  1015.52   67.12  451.67    443.044707
1409  26.06  64.05  1012.00   84.05  442.24    437.907434
1410  26.08  48.60  1003.61   57.80  438.61    444.867130
1411  26.09  70.40  1007.41   85.37  432.52    435.700185
1412  26.11  47.43  1009.01   56.09  445.36    445.790022
1413  26.15  63.21  1012.31   76.44  441.23    439.078645
1414  26.15  64.27  1013.03   59.77  439.11    441.304798
1415  26.16  67.90  1005.81   61.02  444.06    439.610376
1416  26.19  65.61  1014.51   54.52  443.73    441.779913
1417  26.19  73.77  1001.31   91.87  433.34    433.222297
1418  26.20  60.07  1014.75   59.41  440.89    442.448024
1419  26.20  71.14  1007.92   72.95  431.70    437.156862
1420  26.20  72.24  1011.30   78.29  432.65    436.378774
1421  26.22  49.82  1015.48   55.80  454.20    445.550996
1422  26.22  69.89  1015.46   76.63  433.61    437.506908
1423  26.23  59.07  1008.20   78.93  440.18    439.258681
1424  26.24  77.95  1014.19   85.21  438.01    434.103803
1425  26.25  52.09  1013.20   53.12  450.53    445.132529
1426  26.26  65.06  1013.58   52.72  440.92    441.968892
1427  26.31  48.60  1002.64   60.04  440.06    444.017759
1428  26.31  63.77  1014.15   69.36  440.10    439.813031
1429  26.34  69.45  1013.87   54.15  438.50    440.535084
1430  26.35  59.44  1012.16   63.73  443.73    441.474720
1431  26.36  54.50  1015.35   66.87  451.81    442.488684
1432  26.38  44.89  1009.14   51.79  442.13    446.540363
1433  26.38  59.92  1009.99   71.91  444.85    439.927231
1434  26.39  49.02  1007.62   70.82  438.53    442.591565
1435  26.39  49.16  1005.68   56.18  442.87    444.534409
1436  26.39  66.05  1018.24   61.27  442.22    440.603407
1437  26.42  59.39  1013.95   66.03  438.54    441.162363
1438  26.43  51.43  1006.30   71.48  441.01    441.709820
1439  26.43  77.17  1008.67   92.59  431.26    432.405826
1440  26.45  71.37  1008.00   77.06  438.36    436.024254
1441  26.47  63.13  1013.72   79.40  441.81    438.164340
1442  26.53  63.87  1017.38   48.53  445.11    442.665376
1443  26.54  69.34  1009.50   87.18  435.51    435.002579
1444  26.54  69.48  1010.70   66.09  432.56    438.141968
1445  26.56  56.57  1013.73   63.90  442.74    441.888211
1446  26.58  62.39  1006.36   68.98  438.66    439.057567
1447  26.58  70.98  1008.96   77.36  434.41    435.905125
1448  26.59  66.49  1013.32   49.76  439.72    441.386488
1449  26.60  61.41  1012.35   54.42  451.40    441.874962
1450  26.62  71.73  1009.32   80.10  431.93    435.270580
1451  26.65  58.41  1013.53   65.83  442.66    440.958043
1452  26.65  63.78  1015.32   53.95  440.26    441.497984
1453  26.65  74.67  1015.73   77.32  435.90    435.407094
1454  26.70  49.02  1007.68   67.97  438.92    442.414265
1455  26.71  70.40  1007.59   82.63  432.64    434.918664
1456  26.74  69.89  1013.96   51.82  436.02    440.001073
1457  26.80  49.30  1003.86   62.75  438.56    442.602086
1458  26.81  71.29  1009.65   80.69  434.48    434.954594
1459  26.82  69.23  1013.28   50.86  436.36    440.096001
1460  26.84  71.94  1006.60   79.12  427.20    434.715410
1461  26.85  57.19  1007.90   60.04  438.01    441.262757
1462  26.86  71.32  1007.38   81.14  430.44    434.600231
1463  26.87  69.23  1012.71   54.54  433.89    439.416319
1464  26.87  74.99  1002.48   71.91  437.78    434.613522
1465  26.88  61.50  1009.17   61.26  440.13    440.055752
1466  26.90  59.14  1016.18   70.88  436.16    439.772868
1467  26.91  70.02  1010.75   59.48  445.31    438.262000
1468  26.92  73.17  1011.42   76.94  431.29    434.964847
1469  26.94  71.14  1011.63   62.74  434.03    437.520971
1470  26.98  74.78  1009.77   69.54  442.28    435.392903
1471  26.99  72.99  1008.00   76.10  430.81    434.718829
1472  27.00  59.15  1013.12   61.39  440.58    440.712781
1473  27.00  73.42  1012.20   87.28  432.79    433.303311
1474  27.01  69.75  1009.78   81.29  442.57    434.875828
1475  27.02  71.77  1006.38   72.10  428.10    435.416768
1476  27.03  65.12  1015.94   45.10  441.62    441.772447
1477  27.03  71.14  1010.33   66.25  430.41    436.729506
1478  27.04  73.67  1006.82   77.45  431.10    434.159852
1479  27.06  70.47  1007.00   72.37  430.82    435.674811
1480  27.07  74.87  1010.09   58.97  440.47    436.764868
1481  27.08  66.05  1017.33   54.68  439.47    440.159769
1482  27.11  70.04  1009.76   71.25  431.96    436.073646
1483  27.12  70.32  1009.94   52.67  429.08    438.709648
1484  27.14  63.13  1013.38   75.68  438.82    437.387007
1485  27.14  75.23  1011.47   63.14  439.33    436.044119
1486  27.16  47.43  1009.17   45.79  442.85    445.280319
1487  27.16  56.85  1012.07   39.05  437.40    444.151069
1488  27.16  59.87  1011.78   58.84  446.38    440.487565
1489  27.16  65.61  1014.21   47.93  441.33    440.845857
1490  27.16  71.32  1007.81   89.07  430.53    432.899756
1491  27.17  67.17  1006.76   81.59  431.73    434.920833
1492  27.18  59.27  1012.57   64.18  439.69    439.883892
1493  27.18  61.41  1012.17   46.11  449.70    441.953838
1494  27.20  65.12  1016.20   44.95  442.54    441.487591
1495  27.20  65.18  1011.47   47.14  436.99    440.768096
1496  27.20  72.43  1006.75   80.67  430.32    433.684958
1497  27.20  78.05  1010.15   90.20  430.55    431.170351
1498  27.21  66.49  1013.57   40.11  439.04    441.618694
1499  27.21  68.12  1012.96   54.69  435.20    439.035723
1500  27.23  71.77  1006.59   77.94  427.39    434.176868
1501  27.24  69.13  1009.28   70.85  432.36    436.069050
1502  27.25  73.03  1014.15   68.52  439.78    435.813783
1503  27.26  66.56  1007.83   60.95  434.88    437.997385
1504  27.27  72.24  1010.69   78.09  432.35    434.294425
1505  27.28  51.43  1011.46   51.38  450.53    443.422548
1506  27.31  64.44  1014.65   57.27  442.77    439.521533
1507  27.33  68.94  1007.04   61.83  431.96    437.076306
1508  27.33  73.18  1012.26   82.18  429.38    433.475499
1509  27.34  71.29  1008.32   56.51  434.94    437.351405
1510  27.35  60.75  1008.98   67.56  435.14    438.401672
1511  27.35  77.95  1012.14   74.14  431.72    433.410786
1512  27.36  58.33  1013.86   56.70  439.14    440.967254
1513  27.36  63.31  1013.70   51.58  440.40    440.459536
1514  27.36  66.54  1011.31   45.30  436.69    440.375804
1515  27.37  76.09  1007.52   89.12  433.34    431.274555
1516  27.38  69.40  1004.57   74.12  434.47    434.871238
1517  27.39  69.14  1008.82   78.35  435.22    434.645684
1518  27.40  66.48  1004.71   51.50  439.66    438.871863
1519  27.40  69.84  1002.98   76.48  430.54    434.249247
1520  27.41  63.07  1011.50   55.30  445.02    439.701160
1521  27.41  74.67  1016.57   80.16  429.21    433.595255
1522  27.42  65.74  1013.43   69.42  440.52    437.113491
1523  27.43  56.85  1011.86   36.76  436.64    443.947250
1524  27.44  47.93  1002.71   59.44  437.76    442.098431
1525  27.44  59.74  1010.99   56.42  452.00    440.268616
1526  27.44  65.59  1010.76   68.67  441.08    437.004363
1527  27.47  63.78  1016.07   48.47  446.69    440.776807
1528  27.47  69.98  1008.53   58.72  431.11    437.121961
1529  27.49  63.76  1010.09   62.80  436.73    438.165941
1530  27.49  71.94  1008.25   68.29  428.27    435.175861
1531  27.50  68.24  1010.38   73.44  430.90    435.501162
1532  27.52  67.90  1005.65   59.52  439.01    437.192939
1533  27.53  70.32  1007.75   49.31  433.72    438.230693
1534  27.53  72.58  1009.13   89.06  428.83    431.980861
1535  27.55  65.59  1011.60   63.99  440.53    437.543289
1536  27.57  60.07  1016.52   54.75  440.12    440.629396
1537  27.60  67.25  1017.78   54.25  438.42    438.956951
1538  27.60  69.05  1003.87   42.01  436.08    439.161366
1539  27.61  49.16  1005.01   35.63  441.18    445.124502
1540  27.62  63.90  1013.11   43.56  442.89    440.932864
1541  27.62  67.51  1012.38   60.25  442.13    437.538671
1542  27.69  65.34  1014.31   46.59  442.84    440.094503
1543  27.71  54.20  1012.72   47.25  440.74    442.607594
1544  27.71  62.39  1006.43   68.21  435.84    436.995996
1545  27.71  66.93  1016.85   58.77  447.06    438.089473
1546  27.71  69.51  1009.65   58.38  435.04    436.916993
1547  27.72  69.88  1007.58   72.25  434.02    434.613591
1548  27.78  73.56  1007.05   95.32  436.50    430.171783
1549  27.78  77.17  1009.11   86.54  430.33    430.720275
1550  27.82  52.84  1006.23   52.18  440.31    441.486967
1551  27.83  69.04  1009.69   63.79  443.24    436.016757
1552  27.84  71.32  1007.72   79.25  431.37    433.013352
1553  27.85  66.44  1008.48   77.15  429.00    434.578946
1554  27.86  63.07  1011.11   56.81  440.48    438.581152
1555  27.88  63.87  1017.79   40.00  443.24    441.339164
1556  27.88  68.94  1007.68   75.68  435.04    434.047106
1557  27.88  70.79  1005.06   72.50  429.62    433.836480
1558  27.91  64.79  1017.70   48.29  440.53    439.835258
1559  27.92  68.30  1015.02   51.04  437.28    438.321526
1560  27.92  74.99  1005.47   75.13  431.76    432.361910
1561  27.94  49.16  1004.22   35.46  436.75    444.448470
1562  27.97  58.84  1002.25   57.88  446.11    438.546223
1563  27.99  66.91  1008.47   59.63  439.74    436.746728
1564  27.99  71.58  1010.68   68.99  435.99    434.396897
1565  28.01  64.69  1007.61   58.45  440.23    437.363761
1566  28.01  73.18  1012.25   75.02  431.02    433.207568
1567  28.02  63.90  1013.96   46.20  444.42    439.845400
1568  28.04  69.14  1007.16   80.38  436.37    432.960661
1569  28.04  70.32  1011.28   78.16  435.42    433.325720
1570  28.04  74.33  1013.53   48.65  432.92    436.814040
1571  28.07  66.17  1010.58   64.11  443.77    436.295144
1572  28.07  70.32  1007.17   67.02  430.29    434.558369
1573  28.08  59.14  1016.16   58.08  438.83    439.362462
1574  28.08  73.17  1011.19   73.10  430.80    433.268839
1575  28.14  51.43  1012.16   52.67  445.33    441.632540
1576  28.16  70.98  1008.51   72.12  435.04    433.585324
1577  28.18  73.03  1014.18   67.72  439.74    434.139101
1578  28.19  71.97  1008.85   84.67  438.80    431.477523
1579  28.23  62.26  1010.88   60.86  435.76    437.459888
1580  28.24  64.69  1007.35   61.14  438.03    436.506544
1581  28.28  68.67  1006.36   69.90  435.29    434.078610
1582  28.29  61.86  1011.87   64.17  438.25    437.041616
1583  28.30  64.33  1011.23   68.88  441.51    435.667320
1584  28.31  71.85  1009.00   77.56  429.57    432.325395
1585  28.32  71.64  1004.73   72.71  436.31    432.718369
1586  28.34  63.77  1013.70   61.13  439.75    437.061429
1587  28.37  71.64  1007.39   71.06  434.91    433.079173
1588  28.41  61.47  1008.94   56.56  442.54    437.779007
1589  28.42  73.40  1011.39   62.72  438.25    434.086202
1590  28.42  75.23  1010.25   56.80  435.64    434.400756
1591  28.43  68.08  1011.32   58.19  433.05    436.048414
1592  28.43  73.18  1012.52   71.05  427.11    432.998576
1593  28.44  77.54  1011.73   77.30  433.21    430.916206
1594  28.47  69.23  1013.18   40.73  434.12    438.383026
1595  28.52  64.96  1005.90   70.79  431.36    434.373371
1596  28.53  49.30  1003.83   59.69  438.17    439.709131
1597  28.55  74.33  1011.77   73.34  426.48    432.085279
1598  28.56  74.22  1007.45   69.60  434.54    432.287324
1599  28.57  65.27  1013.27   51.11  440.51    437.670530
1600  28.59  68.08  1013.20   42.96  436.70    438.114594
1601  28.61  72.29  1011.61   45.33  446.77    436.551221
1602  28.62  70.94  1007.38   53.00  432.71    435.405257
1603  28.63  66.56  1005.88   64.73  427.35    434.644694
1604  28.64  66.54  1010.43   43.39  437.97    438.113872
1605  28.64  73.40  1011.48   52.84  441.32    435.110474
1606  28.68  61.86  1011.78   62.67  440.57    436.500858
1607  28.68  73.77  1004.72   87.01  431.66    429.406045
1608  28.69  58.33  1013.67   34.10  448.54    441.683303
1609  28.69  67.25  1017.71   44.60  436.21    438.256549
1610  28.72  76.86   999.31   71.74  431.74    430.345670
1611  28.73  68.30  1016.53   55.73  434.15    436.197910
1612  28.75  57.55  1004.77   57.55  435.33    437.616629
1613  28.75  70.02  1010.33   46.55  440.31    436.564956
1614  28.76  69.48  1008.62   55.86  430.14    435.182950
1615  28.79  70.79  1003.83   65.90  425.64    432.943904
1616  28.82  71.43  1011.51   58.58  443.68    434.419528
1617  28.83  71.32  1006.28   75.65  437.99    431.511734
1618  28.85  58.33  1013.78   41.39  444.00    440.320179
1619  28.85  68.12  1012.05   46.31  436.15    437.020805
1620  28.87  71.97  1008.74   82.61  435.86    430.457465
1621  28.88  71.98  1005.37   74.24  428.61    431.382352
1622  28.92  66.51  1015.50   34.51  439.09    439.289424
1623  28.94  62.26  1010.64   50.41  436.04    437.595312
1624  28.99  54.20  1012.79   41.90  442.60    440.924825
1625  28.99  68.24  1008.75   66.57  428.28    433.496679
1626  29.00  69.13  1001.22   52.96  425.50    434.627921
1627  29.01  65.71  1013.61   48.07  446.22    437.183291
1628  29.01  66.56  1006.44   57.62  428.32    434.994526
1629  29.03  67.79  1010.67   55.42  444.09    435.314580
1630  29.04  62.26  1010.63   56.60  433.97    436.498618
1631  29.04  70.72  1009.55   66.58  437.95    432.845599
1632  29.06  71.64  1005.54   69.84  435.98    431.775638
1633  29.09  67.07  1005.99   41.39  429.93    437.044061
1634  29.10  73.90  1007.47   59.48  436.56    432.803460
1635  29.12  58.84  1001.31   52.86  446.51    436.983842
1636  29.12  73.06  1009.98   80.21  434.90    430.154555
1637  29.14  67.45  1015.51   46.47  433.34    436.886812
1638  29.16  73.17  1010.96   67.77  429.06    431.944500
1639  29.17  64.79  1016.43   61.05  441.20    435.440098
1640  29.17  67.45  1014.10   46.85  435.08    436.658728
1641  29.18  68.24  1010.04   68.04  428.52    433.020771
1642  29.19  67.51  1011.48   55.55  446.97    435.122749
1643  29.22  60.23  1009.73   61.50  436.32    435.869460
1644  29.23  69.59  1009.00   71.41  437.95    432.011473
1645  29.23  72.99  1007.04   63.47  431.00    432.162522
1646  29.23  75.60  1017.72   52.26  438.92    434.016554
1647  29.24  64.33  1011.50   64.14  440.29    434.567655
1648  29.25  71.94  1007.18   63.62  427.49    432.375243
1649  29.26  69.34  1009.76   58.64  435.32    433.940691
1650  29.28  77.17  1009.40   76.30  433.14    429.344422
1651  29.29  70.36  1006.64   60.82  431.26    433.056512
1652  29.29  71.14  1011.49   49.97  432.58    434.839669
1653  29.29  72.58  1007.39   72.85  428.73    430.809152
1654  29.30  69.48  1010.10   53.69  429.42    434.578416
1655  29.30  70.04  1010.95   61.23  426.25    433.408062
1656  29.35  54.20  1013.07   42.45  439.47    440.173001
1657  29.37  74.78  1009.47   55.65  434.20    432.784808
1658  29.38  69.68  1011.35   49.25  430.20    435.123711
1659  29.41  59.27  1011.36   52.37  441.99    437.206900
1660  29.42  74.90  1004.11   64.53  434.66    430.926689
1661  29.43  66.75  1017.63   42.72  434.60    437.221602
1662  29.44  64.33  1011.40   61.78  442.32    434.518021
1663  29.45  69.13  1009.30   52.97  432.04    434.416257
1664  29.45  75.60  1018.12   50.68  437.31    433.855261
1665  29.47  71.32  1008.07   67.00  437.14    431.684852
1666  29.53  64.44  1013.22   59.75  440.10    434.761298
1667  29.55  66.25  1009.38   69.55  436.29    432.529230
1668  29.56  70.40  1006.49   82.95  432.85    429.285221
1669  29.59  74.78  1009.45   55.75  436.77    432.344245
1670  29.60  67.79  1010.37   51.05  442.43    434.828210
1671  29.60  71.14  1011.46   52.69  430.55    433.842491
1672  29.60  71.58  1010.34   52.56  434.64    433.660579
1673  29.61  67.07  1005.91   39.28  434.14    436.342355
1674  29.62  71.80  1011.05   63.13  438.55    432.083003
1675  29.65  74.90  1003.22   71.09  433.32    429.453630
1676  29.70  57.19  1008.41   55.07  436.29    436.532085
1677  29.70  67.17  1007.31   66.56  438.04    432.278198
1678  29.74  70.32  1008.10   52.72  432.69    433.498985
1679  29.76  73.56  1008.07   84.85  432.51    427.963064
1680  29.79  62.66  1008.50   48.51  440.27    435.959025
1681  29.79  67.69  1006.86   55.93  428.71    433.489026
1682  29.83  71.43  1011.93   55.80  439.34    432.911130
1683  29.85  61.85  1005.45   61.85  436.46    433.850911
1684  29.85  71.58  1010.04   58.66  432.26    432.264079
1685  29.86  69.34  1007.76   54.12  433.57    433.279944
1686  29.90  74.99  1002.28   59.76  436.77    430.525274
1687  29.92  67.22  1014.09   50.62  444.78    434.718655
1688  29.98  47.93  1002.46   42.73  438.79    439.616459
1689  29.98  67.22  1014.22   52.69  445.30    434.311536
1690  29.98  76.09  1007.62   75.60  432.00    428.220701
1691  29.99  74.90  1003.84   64.43  435.87    429.819854
1692  30.04  67.25  1017.57   38.14  434.83    436.583592
1693  30.06  67.25  1017.63   53.59  435.02    434.296058
1694  30.06  69.14  1007.50   72.48  436.89    430.244519
1695  30.08  73.42  1011.17   63.86  434.95    430.695118
1696  30.09  64.96  1001.29   56.04  430.30    433.121518
1697  30.09  69.48  1009.51   53.24  435.20    433.072242
1698  30.15  69.88  1007.20   73.67  434.75    429.688410
1699  30.15  72.51  1009.37   50.64  443.72    432.568973
1700  30.17  64.79  1017.06   43.81  439.75    436.077505
1701  30.20  56.90  1006.89   42.69  436.17    437.322215
1702  30.21  79.74  1006.82   54.03  430.83    429.948560
1703  30.22  70.32  1011.63   65.97  435.98    430.927602
1704  30.28  58.90  1005.03   54.59  439.06    434.781886
1705  30.28  67.22  1014.39   53.32  447.67    433.654817
1706  30.28  79.74  1006.96   70.21  433.45    427.464604
1707  30.30  71.98  1004.40   55.60  426.52    431.283623
1708  30.33  68.67  1006.00   54.99  435.53    432.270235
1709  30.36  69.82  1010.02   54.22  439.05    432.365242
1710  30.36  71.80  1010.90   63.27  437.40    430.623022
1711  30.37  67.45  1015.35   45.60  431.38    434.628221
1712  30.38  71.58  1010.17   50.45  433.75    432.450046
1713  30.38  74.16  1007.44   74.77  432.84    428.036770
1714  30.39  66.54  1002.70   59.15  428.89    431.810042
1715  30.45  43.21  1011.35   63.59  438.68    437.567340
1716  30.46  66.75  1017.81   54.48  432.45    433.533998
1717  30.47  70.02  1009.65   62.03  435.72    430.933764
1718  30.47  77.30  1002.13   63.70  434.68    428.262933
1719  30.48  70.04  1010.73   53.70  429.85    432.212588
1720  30.49  64.44  1013.43   51.73  438.09    434.096657
1721  30.52  70.40  1003.90   64.33  438.29    429.938963
1722  30.53  65.18  1012.69   41.85  437.89    435.216059
1723  30.55  66.25  1009.15   63.52  440.74    431.461315
1724  30.56  69.04  1009.29   55.73  442.24    431.894234
1725  30.56  71.25  1000.30   70.55  431.92    428.449449
1726  30.58  68.84  1011.34   51.29  439.71    432.720112
1727  30.59  70.04  1010.28   50.56  429.13    432.421844
1728  30.62  64.69  1006.23   52.06  435.84    433.149301
1729  30.66  66.25  1007.67   63.03  439.55    431.200139
1730  30.68  71.80  1010.81   61.40  435.40    430.271260
1731  30.70  71.58  1010.00   48.96  429.27    432.036336
1732  30.70  74.22  1008.12   50.39  432.51    431.016486
1733  30.71  71.85  1008.07   72.05  425.16    428.424252
1734  30.72  71.58  1009.98   50.39  430.46    431.787523
1735  30.74  73.67  1005.79   57.89  428.92    429.792678
1736  30.75  73.50  1011.02   54.76  429.18    430.698140
1737  30.80  69.14  1007.68   63.78  433.62    430.100980
1738  30.80  73.56  1007.39   75.78  432.43    427.224835
1739  30.81  71.97  1008.36   75.00  430.53    427.794712
1740  30.85  67.45  1014.53   32.99  430.80    435.475164
1741  30.86  70.32  1011.88   62.68  433.71    430.193436
1742  30.90  73.68  1014.95   40.90  430.29    432.705762
1743  30.92  78.05  1011.00   59.62  434.12    428.525241
1744  30.93  73.42  1010.98   56.42  432.44    430.125476
1745  30.98  69.82  1009.17   50.63  438.44    431.623869
1746  31.01  67.69  1005.06   46.16  426.64    432.414544
1747  31.03  69.98  1011.33   52.16  436.13    431.440181
1748  31.05  62.70  1009.35   55.27  441.67    432.601755
1749  31.05  69.13  1000.38   58.49  426.31    429.798688
1750  31.09  64.05  1011.32   61.14  440.62    431.492083
1751  31.10  68.51  1012.99   54.30  428.68    431.494611
1752  31.12  67.69  1005.30   50.46  425.21    431.594626
1753  31.14  67.32  1013.93   38.37  436.64    434.114532
1754  31.15  69.59  1007.82   64.96  431.37    429.152950
1755  31.18  69.04  1008.19   49.72  441.26    431.485537
1756  31.18  74.34  1003.81   63.59  434.15    427.784241
1757  31.19  68.30  1014.86   39.10  430.48    433.742977
1758  31.20  68.24  1005.71   34.84  428.67    433.615213
1759  31.20  73.17  1010.28   53.23  431.23    430.075387
1760  31.23  66.75  1017.48   36.55  433.90    434.637545
1761  31.23  68.67  1005.82   52.10  436.58    430.941212
1762  31.23  72.58  1006.61   60.80  427.58    428.761542
1763  31.23  75.08  1004.93   46.19  439.14    430.132789
1764  31.24  71.98  1004.66   57.17  426.93    429.262642
1765  31.25  68.94  1005.99   49.61  434.51    431.212399
1766  31.25  74.34   999.06   69.85  432.22    426.349327
1767  31.26  68.94  1005.94   39.49  438.03    432.665343
1768  31.30  70.79  1004.30   54.37  428.75    429.822754
1769  31.32  74.33  1012.92   36.48  429.57    432.213121
1770  31.35  70.80  1010.11   66.37  432.19    428.446241
1771  31.38  70.83  1010.35   47.28  431.33    431.185279
1772  31.41  64.44  1013.84   49.49  439.30    432.682266
1773  31.43  69.89  1014.80   56.22  426.15    430.381294
1774  31.44  72.86  1003.74   61.45  433.59    427.958213
1775  31.46  77.17  1009.26   59.61  435.56    427.562872
1776  31.53  74.99  1003.93   58.29  432.34    427.730020
1777  31.54  67.32  1013.79   36.99  433.02    433.532910
1778  31.54  71.06  1008.40   71.77  431.87    427.087980
1779  31.54  72.58  1007.61   65.57  427.31    427.549161
1780  31.55  69.75  1010.12   58.36  435.01    429.491565
1781  31.56  66.44  1008.91   64.16  430.11    429.352909
1782  31.61  69.04  1008.11   47.96  439.19    430.906369
1783  31.61  75.08  1004.83   42.29  436.67    429.960617
1784  31.65  66.25  1008.57   59.05  437.35    429.944450
1785  31.67  69.68  1012.38   46.52  439.72    431.188754
1786  31.68  70.79  1004.05   54.50  429.55    429.050476
1787  31.68  73.68  1014.85   64.00  431.11    427.823299
1788  31.70  69.13  1000.29   46.27  427.95    430.320262
1789  31.71  69.04  1008.79   49.32  441.15    430.570445
1790  31.74  79.74  1007.07   61.47  431.72    425.932432
1791  31.75  74.99  1003.25   53.33  430.82    427.973880
1792  31.76  66.54  1003.02   49.64  430.18    430.580890
1793  31.79  76.20  1007.89   56.30  434.01    427.539523
1794  31.80  69.05  1000.77   49.82  426.50    429.668525
1795  31.81  69.88  1007.94   55.91  432.60    429.137590
1796  31.85  73.91  1003.60   60.22  431.26    427.073639
1797  31.88  67.32  1013.64   35.10  436.64    433.140604
1798  31.92  75.33  1001.81   61.97  436.38    426.183580
1799  31.93  72.58  1006.90   56.27  425.14    428.095793
1800  31.95  70.80  1008.38   66.26  432.79    427.164145
1801  31.97  69.04  1008.50   47.69  441.18    430.283121
1802  31.98  64.05  1010.49   58.01  439.56    430.164445
1803  31.99  53.53  1004.98   53.53  432.43    432.972951
1804  32.00  58.90  1003.48   51.38  437.81    431.806362
1805  32.00  71.85  1008.44   53.59  427.95    428.659101
1806  32.07  71.29  1008.43   44.95  426.96    429.923286
1807  32.09  69.40  1003.10   56.91  430.62    428.177292
1808  32.16  68.14  1004.86   37.77  429.64    431.291828
1809  32.16  76.20  1008.04   51.74  433.29    427.503273
1810  32.20  69.68  1012.12   42.47  437.35    430.736112
1811  32.20  72.29  1008.61   69.94  432.52    425.792338
1812  32.31  68.94  1006.11   71.78  431.14    425.943437
1813  32.38  67.17  1006.97   60.04  438.67    428.032347
1814  32.38  69.05  1000.76   45.85  429.31    429.128123
1815  32.41  67.83  1008.54   55.96  426.85    428.532932
1816  32.42  75.08  1004.82   41.62  436.26    428.495177
1817  32.45  66.44  1011.21   50.18  429.99    429.862872
1818  32.46  74.33  1012.61   37.07  427.87    429.902931
1819  32.48  69.75  1009.05   40.47  438.17    430.220420
1820  32.56  68.94  1007.12   58.18  425.61    427.527412
1821  32.63  69.89  1013.85   41.66  425.72    430.113350
1822  32.69  72.86  1003.57   56.84  431.76    426.205821
1823  32.73  69.88  1007.86   46.95  434.32    428.663622
1824  32.82  68.31  1010.44   41.85  441.06    429.835471
1825  32.83  74.16  1007.57   60.20  432.05    425.447147
1826  32.84  74.67  1015.89   31.81  430.88    430.119546
1827  32.87  70.80  1009.54   59.85  433.10    426.419128
1828  32.89  73.68  1014.45   52.34  426.46    427.157789
1829  32.91  73.56  1007.02   55.03  434.03    426.151853
1830  32.95  75.08  1005.32   47.70  436.30    426.626643
1831  33.01  68.67  1005.20   51.41  433.94    427.558049
1832  33.13  74.34   999.57   48.34  433.73    425.902487
1833  33.24  74.34  1002.58   45.05  435.50    426.415296
1834  33.34  69.88  1007.65   42.72  437.84    428.087001
1835  33.37  73.88  1005.80   47.94  436.76    426.119772
1836  33.41  77.95  1010.30   59.72  432.90    423.675772
1837  33.50  70.80  1008.99   57.24  433.19    425.539927
1838  33.63  70.40  1004.02   53.60  430.05    425.515308
1839  33.71  69.98  1013.09   42.62  431.99    427.805843
1840  33.75  64.96  1002.54   39.28  432.62    428.608644
1841  33.80  64.96  1004.88   49.37  427.28    427.230769
1842  33.87  71.32  1007.91   39.48  435.89    427.199513
1843  33.94  74.67  1015.94   28.16  427.98    428.534347
1844  33.95  80.18  1010.30   56.69  432.22    422.520234
1845  33.97  72.29  1008.98   44.32  432.33    426.145839
1846  34.15  68.51  1010.75   37.02  430.19    427.950078
1847  34.18  67.90  1005.87   30.34  425.50    428.621502
1848  34.40  77.95  1009.83   57.86  430.87    421.999288
1849  34.53  73.03  1013.53   36.74  437.03    426.357365
1850  34.63  74.33  1011.70   31.45  428.54    426.463096
1851  34.65  74.67  1016.03   26.67  427.69    427.389553
1852  34.66  74.33  1012.00   32.19  425.89    426.321702
1853  34.76  68.94  1006.75   41.31  427.42    425.714820
1854  34.96  68.94  1006.17   59.26  431.48    422.663292
1855  35.03  68.27  1006.55   43.82  426.22    424.978633
\end{Verbatim}
\end{tcolorbox}
        
    From a visual inspection of the predictions, we can see that they are
close to the actual values.

However, we would like a scientific measure of how well the Linear
Regression model is performing in accurately predicting values. To
perform this measurement, we can use an evaluation metric such as
\href{https://en.wikipedia.org/wiki/Root-mean-square_deviation}{Root
Mean Squared Error} (RMSE) to validate our Linear Regression model.

RSME is defined as follows: \textbackslash( RMSE =
\sqrt{\frac{\sum_{i = 1}^{n} (x_i - y_i)^2}{n}}\textbackslash) where
\textbackslash(y\_i\textbackslash) is the observed value and
\textbackslash(x\_i\textbackslash) is the predicted value

RMSE is a frequently used measure of the differences between values
predicted by a model or an estimator and the values actually observed.
The lower the RMSE, the better our model.

Spark ML Pipeline provides several regression analysis metrics,
including
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.evaluation.RegressionEvaluator.html?highlight=regressionevaluator\#pyspark.ml.evaluation.RegressionEvaluator}{RegressionEvaluator()}.

After we create an instance of
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.evaluation.RegressionEvaluator.html?highlight=regressionevaluator\#pyspark.ml.evaluation.RegressionEvaluator}{RegressionEvaluator},
we set the label column name to ``PE'' and set the prediction column
name to ``Predicted\_PE''. We then invoke the evaluator on the
predictions.

\hypertarget{exercise-6f}{%
\subsubsection{Exercise 6(f)}\label{exercise-6f}}

Run the next cell and ensure that you understand what's going on.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{53}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Now let\PYZsq{}s compute an evaluation metric for our test dataset}
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{evaluation}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{RegressionEvaluator}

\PY{c+c1}{\PYZsh{} Create an RMSE evaluator using the label and predicted columns}
\PY{n}{regEval} \PY{o}{=} \PY{n}{RegressionEvaluator}\PY{p}{(}\PY{n}{predictionCol}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Predicted\PYZus{}PE}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{labelCol}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{PE}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{metricName}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{rmse}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Run the evaluator on the DataFrame}
\PY{n}{rmse} \PY{o}{=} \PY{n}{regEval}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{predictionsAndLabelsDF}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Root Mean Squared Error: }\PY{l+s+si}{\PYZpc{}.2f}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{n}{rmse}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Root Mean Squared Error: 4.43
    \end{Verbatim}

    Another useful statistical evaluation metric is the coefficient of
determination, denoted \textbackslash(R\^{}2\textbackslash) or
\textbackslash(r\^{}2\textbackslash) and pronounced ``R squared''. It is
a number that indicates the proportion of the variance in the dependent
variable that is predictable from the independent variable and it
provides a measure of how well observed outcomes are replicated by the
model, based on the proportion of total variation of outcomes explained
by the model. The coefficient of determination ranges from 0 to 1
(closer to 1), and the higher the value, the better our model.

To compute \textbackslash(r\^{}2\textbackslash), we invoke the evaluator
with \texttt{regEval.metricName:\ "r2"}

\hypertarget{exercise-6g}{%
\subsubsection{Exercise 6(g)}\label{exercise-6g}}

Run the next cell and ensure that you understand what's going on.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{54}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Now let\PYZsq{}s compute another evaluation metric for our test dataset}
\PY{n}{r2} \PY{o}{=} \PY{n}{regEval}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{predictionsAndLabelsDF}\PY{p}{,} \PY{p}{\PYZob{}}\PY{n}{regEval}\PY{o}{.}\PY{n}{metricName}\PY{p}{:} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{r2}\PY{l+s+s2}{\PYZdq{}}\PY{p}{\PYZcb{}}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{r2: }\PY{l+s+si}{\PYZob{}0:.2f\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{r2}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
r2: 0.93
    \end{Verbatim}

    Generally, assuming a Gaussian distribution of errors, a good model will
have 68\% of predictions within 1 RMSE and 95\% within 2 RMSE of the
actual value.

Let's examine the predictions and see if a RMSE of 4.59 meets this
criteria.

We create a new DataFrame using
\href{https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.selectExpr.html?highlight=selectexpr\#pyspark.sql.DataFrame.selectExpr}{selectExpr()}
to project a set of SQL expressions, and register the DataFrame as a SQL
table using
\href{https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.createOrReplaceTempView.html?highlight=createorreplacetempview\#pyspark.sql.DataFrame.createOrReplaceTempView}{createOrReplaceTempView()}.

\hypertarget{exercise-6h}{%
\subsubsection{Exercise 6(h)}\label{exercise-6h}}

Run the next cell and ensure that you understand what's going on.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{55}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Calculate the residual error and divide it by the RMSE}
\PY{n}{predictionsAndLabelsDF}\PY{o}{.}\PY{n}{selectExpr}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{PE}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Predicted\PYZus{}PE}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{PE \PYZhy{} Predicted\PYZus{}PE Residual\PYZus{}Error}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{(PE \PYZhy{} Predicted\PYZus{}PE) / }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{ Within\PYZus{}RSME}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{rmse}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{createOrReplaceTempView}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Power\PYZus{}Plant\PYZus{}RMSE\PYZus{}Evaluation}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    We can use SQL to explore the \texttt{Power\_Plant\_RMSE\_Evaluation}
table. First let's look at at the table using a SQL SELECT statement.

\hypertarget{exercise-6i}{%
\subsubsection{Exercise 6(i)}\label{exercise-6i}}

Run the next cell and ensure that you understand what's going on.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{56}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{rmseDF} \PY{o}{=} \PY{n}{spark}\PY{o}{.}\PY{n}{sql}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{SELECT * from Power\PYZus{}Plant\PYZus{}RMSE\PYZus{}Evaluation}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{rmseDF}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
+------+------------------+--------------------+--------------------+
|    PE|      Predicted\_PE|      Residual\_Error|         Within\_RSME|
+------+------------------+--------------------+--------------------+
|490.34|493.23742177145346| -2.8974217714534802| -0.6545286058917738|
|482.66|488.93663844862806|  -6.276638448628034|  -1.417894851879411|
|489.04| 488.2642491377767|  0.7757508622233331| 0.17524239493640179|
|489.64| 487.6850017397038|   1.954998260296179|  0.4416348004421164|
| 489.0|487.84320058785806|   1.156799412141936| 0.26132139752158323|
|488.03|486.78756854756284|  1.2424314524371312| 0.28066570579809824|
| 491.9| 485.8682911927762|   6.031708807223765|   1.362565159009226|
|489.36|485.34119715268844|   4.018802847311576|  0.9078489886838934|
|481.47| 482.9938172155268| -1.5238172155267762|  -0.344230849488058|
|482.05|482.56483906211207| -0.5148390621120598|-0.11630232674540568|
|494.75|487.00024243767604|   7.749757562323964|  1.7506729821811777|
|482.98|483.34675257798034|-0.36675257798032135|-0.08284953745351807|
|475.34|482.83365300532864|  -7.493653005328667| -1.6928188719152182|
|483.73|483.61453434986964|  0.1154656501303748|0.026083731320314243|
|488.42| 484.5318759947065|  3.8881240052934913|  0.8783285919200003|
|495.35|487.26575386983336|   8.084246130166662|  1.8262340683005074|
|491.32|487.10787889447676|   4.212121105523238|  0.9515196517842229|
|486.46| 482.0547750131382|   4.405224986861754|  0.9951418870728689|
|483.12|483.68809525895665| -0.5680952589566459|-0.12833292050266135|
|495.23|487.01940772826526|   8.210592271734754|  1.8547757064959307|
+------+------------------+--------------------+--------------------+
only showing top 20 rows
    \end{Verbatim}

    Now we can display the RMSE as a Histogram.

\hypertarget{exercise-6j}{%
\subsubsection{Exercise 6(j)}\label{exercise-6j}}

Display the histogram of RMSE using the method
\href{https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.hist.html?highlight=hist\#pandas.DataFrame.plot.hist}{DataFrame.plot.hist()}.
This can be done in two steps:

\begin{itemize}
\tightlist
\item
  Select the `Within\_RSME' column from rmseDF and convert it to a
  Pandas DataFrame
\item
  Use the method
  \href{https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.hist.html?highlight=hist\#pandas.DataFrame.plot.hist}{DataFrame.plot.hist()}
  to plot a histogram with 100 bins (bars).
\end{itemize}

\textbf{PS.}: Notice that the histogram clearly shows that the RMSE is
centered around 0 with the vast majority of the error within 2 RMSEs.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{58}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} TODO: Replace \PYZlt{}FILL IN\PYZgt{} with appropriate code}

\PY{n}{rmseDF\PYZus{}pd} \PY{o}{=} \PY{n}{rmseDF}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Within\PYZus{}RSME}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{toPandas}\PY{p}{(}\PY{p}{)}

\PY{n}{rmseDF\PYZus{}pd}\PY{o}{.}\PY{n}{plot}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{)}\PY{c+c1}{\PYZsh{} plot}

\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_68_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Using a complex SQL SELECT statement, we can count the number of
predictions within + or - 1.0 and + or - 2.0 and then display the
results as a pie chart.

\hypertarget{exercise-6k}{%
\subsubsection{Exercise 6(k)}\label{exercise-6k}}

Run the following cell

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{59}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{complex\PYZus{}query} \PY{o}{=} \PYZbs{}
\PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
\PY{l+s+sd}{SELECT case when Within\PYZus{}RSME \PYZlt{}= 1.0 AND Within\PYZus{}RSME \PYZgt{}= \PYZhy{}1.0 then 1}
\PY{l+s+sd}{            when Within\PYZus{}RSME \PYZlt{}= 2.0 AND Within\PYZus{}RSME \PYZgt{}= \PYZhy{}2.0 then 2 else 3}
\PY{l+s+sd}{       end RSME\PYZus{}Multiple, COUNT(*) AS count}
\PY{l+s+sd}{FROM Power\PYZus{}Plant\PYZus{}RMSE\PYZus{}Evaluation}
\PY{l+s+sd}{GROUP BY case when Within\PYZus{}RSME \PYZlt{}= 1.0 AND Within\PYZus{}RSME \PYZgt{}= \PYZhy{}1.0 then 1 when Within\PYZus{}RSME \PYZlt{}= 2.0 AND Within\PYZus{}RSME \PYZgt{}= \PYZhy{}2.0 then 2 else 3 end}
\PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}

\PY{n}{wrmseDF} \PY{o}{=} \PY{n}{spark}\PY{o}{.}\PY{n}{sql}\PY{p}{(}\PY{n}{complex\PYZus{}query}\PY{p}{)}
\PY{n}{wrmseDF}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
+-------------+-----+
|RSME\_Multiple|count|
+-------------+-----+
|            1| 1267|
|            3|   77|
|            2|  512|
+-------------+-----+

    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{60}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{wrmseDF\PYZus{}pd} \PY{o}{=} \PY{n}{wrmseDF}\PY{o}{.}\PY{n}{toPandas}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{set\PYZus{}index}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RSME\PYZus{}Multiple}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{n}{ax} \PY{o}{=} \PY{n}{wrmseDF\PYZus{}pd}\PY{o}{.}\PY{n}{plot}\PY{o}{.}\PY{n}{pie}\PY{p}{(}\PY{n}{y}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{autopct}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZpc{}1.1f}\PY{l+s+si}{\PYZpc{}\PYZpc{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
        \PY{n}{shadow}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}

\PY{n}{ax}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RSME\PYZus{}Multiple}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_71_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    From the pie chart, we can see that 68.3\% of our test data predictions
are within 1 RMSE of the actual values, and 95.9\% (68.3\% + 27.6\%) of
our test data predictions are within 2 RMSE. So the model is pretty
decent. Let's see if we can tune the model to improve it further.

    \hypertarget{part-7-tuning-and-evaluation}{%
\subsection{Part 7: Tuning and
Evaluation}\label{part-7-tuning-and-evaluation}}

Now that we have a model with all of the data let's try to make a better
model by tuning over several parameters. The process of tuning a model
is known as
\href{https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html?highlight=tuning\#tuning}{Model
Selection} or
\href{https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html?highlight=tuning\#tuning}{Hyperparameter
Tuning}, and Spark ML Pipeline makes the tuning process very simple and
easy.

An important task in ML is model selection, or using data to find the
best model or parameters for a given task. This is also called tuning.
Tuning may be done for individual Estimators such as
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.LinearRegression.html?highlight=linearregression\#pyspark.ml.regression.LinearRegression}{LinearRegression},
or for entire Pipelines which include multiple algorithms,
featurization, and other steps. Users can tune an entire Pipeline at
once, rather than tuning each element in the Pipeline separately.

Spark ML Pipeline supports model selection using tools such as
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.CrossValidator.html\#pyspark.ml.tuning.CrossValidator}{CrossValidator},
which requires the following items: -
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.Estimator.html}{Estimator}:
algorithm or Pipeline to tune -
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.ParamGridBuilder.html?highlight=paramgridbuilder\#pyspark.ml.tuning.ParamGridBuilder}{Set
of ParamMaps}: parameters to choose from, sometimes called a
\emph{parameter grid} to search over -
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.evaluation.Evaluator.html?highlight=evaluator\#pyspark.ml.evaluation.Evaluator}{Evaluator}:
metric to measure how well a fitted Model does on held-out test data

At a high level, model selection tools such as
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.CrossValidator.html\#pyspark.ml.tuning.CrossValidator}{CrossValidator}
work as follows: - They split the input data into separate training and
test datasets. - For each (training, test) pair, they iterate through
the set of ParamMaps: - For each
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.ParamGridBuilder.html?highlight=paramgridbuilder\#pyspark.ml.tuning.ParamGridBuilder}{ParamMap},
they fit the
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.Estimator.html}{Estimator}
using those parameters, get the fitted Model, and evaluate the Model's
performance using the
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.evaluation.Evaluator.html?highlight=evaluator\#pyspark.ml.evaluation.Evaluator}{Evaluator}.
- They select the Model produced by the best-performing set of
parameters.

The
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.evaluation.Evaluator.html?highlight=evaluator\#pyspark.ml.evaluation.Evaluator}{Evaluator}
can be a
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.evaluation.RegressionEvaluator.html?highlight=regressionevaluator\#pyspark.ml.evaluation.RegressionEvaluator}{RegressionEvaluator}
for regression problems. To help construct the parameter grid, users can
use the
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.ParamGridBuilder.html?highlight=paramgridbuilder\#pyspark.ml.tuning.ParamGridBuilder}{ParamGridBuilder}
utility.

Note that cross-validation over a grid of parameters is expensive. For
example, in the next cell, the parameter grid has 10 values for
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.LinearRegression.html?highlight=linearregression\%20regparam\#pyspark.ml.regression.LinearRegression.regParam}{lr.regParam},
and
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.CrossValidator.html\#pyspark.ml.tuning.CrossValidator}{CrossValidator}
uses 3 folds. This multiplies out to (10 x 3) = 30 different models
being trained. In realistic settings, it can be common to try many more
parameters (e.g., multiple values for multiple parameters) and use more
folds (\emph{k} = 3 and \emph{k} = 10 are common). In other words, using
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.CrossValidator.html\#pyspark.ml.tuning.CrossValidator}{CrossValidator}
can be very expensive. However, it is also a well-established method for
choosing parameters which is more statistically sound than heuristic
hand-tuning.

We perform the following steps: - Create a
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.CrossValidator.html\#pyspark.ml.tuning.CrossValidator}{CrossValidator}
using the Pipeline and
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.evaluation.RegressionEvaluator.html?highlight=regressionevaluator\#pyspark.ml.evaluation.RegressionEvaluator}{RegressionEvaluator}
that we created earlier, and set the number of folds to 3 - Create a
list of 10 regularization parameters - Use
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.ParamGridBuilder.html?highlight=paramgridbuilder\#pyspark.ml.tuning.ParamGridBuilder}{ParamGridBuilder}
to build a parameter grid with the regularization parameters and add the
grid to the
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.CrossValidator.html\#pyspark.ml.tuning.CrossValidator}{CrossValidator}
- Run the
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.CrossValidator.html\#pyspark.ml.tuning.CrossValidator}{CrossValidator}
to find the parameters that yield the best model (i.e., lowest RMSE) and
return the best model.

\hypertarget{exercise-7a}{%
\subsubsection{Exercise 7(a)}\label{exercise-7a}}

Run the next cell. \emph{Note that it will take some time to run the
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.CrossValidator.html\#pyspark.ml.tuning.CrossValidator}{CrossValidator}
as it will run almost 200 Spark jobs}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{66}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{tuning}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{ParamGridBuilder}\PY{p}{,} \PY{n}{CrossValidator}

\PY{c+c1}{\PYZsh{} We can reuse the RegressionEvaluator, regEval, to judge the model based on the best Root Mean Squared Error}
\PY{c+c1}{\PYZsh{} Let\PYZsq{}s create our CrossValidator with 3 fold cross validation}
\PY{n}{crossval} \PY{o}{=} \PY{n}{CrossValidator}\PY{p}{(}\PY{n}{estimator}\PY{o}{=}\PY{n}{lrPipeline}\PY{p}{,} \PY{n}{evaluator}\PY{o}{=}\PY{n}{regEval}\PY{p}{,} \PY{n}{numFolds}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Let\PYZsq{}s tune over our regularization parameter from 0.01 to 0.10}
\PY{n}{regParam} \PY{o}{=} \PY{p}{[}\PY{n}{x} \PY{o}{/} \PY{l+m+mf}{100.0} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{11}\PY{p}{)}\PY{p}{]}

\PY{c+c1}{\PYZsh{} We\PYZsq{}ll create a paramter grid using the ParamGridBuilder, and add the grid to the CrossValidator}
\PY{n}{paramGrid} \PY{o}{=} \PY{p}{(}\PY{n}{ParamGridBuilder}\PY{p}{(}\PY{p}{)}
             \PY{o}{.}\PY{n}{addGrid}\PY{p}{(}\PY{n}{lr}\PY{o}{.}\PY{n}{regParam}\PY{p}{,} \PY{n}{regParam}\PY{p}{)}
             \PY{o}{.}\PY{n}{build}\PY{p}{(}\PY{p}{)}\PY{p}{)}

\PY{n}{crossval}\PY{o}{.}\PY{n}{setEstimatorParamMaps}\PY{p}{(}\PY{n}{paramGrid}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Now let\PYZsq{}s find and return the best model}
\PY{n}{cvModel} \PY{o}{=} \PY{n}{crossval}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{trainingSetDF}\PY{p}{)}\PY{o}{.}\PY{n}{bestModel}
\end{Verbatim}
\end{tcolorbox}

    Now that we have tuned our Linear Regression model, let's see what the
new RMSE and \textbackslash(r\^{}2\textbackslash) values are versus our
intial model.

\hypertarget{exercise-7b}{%
\subsubsection{Exercise 7(b)}\label{exercise-7b}}

Complete and run the next cell.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{63}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} TODO: Replace \PYZlt{}FILL\PYZus{}IN\PYZgt{} with the appropriate code.}

\PY{c+c1}{\PYZsh{} Now let\PYZsq{}s use cvModel to compute an evaluation metric for our test dataset: testSetDF}
\PY{n}{predictionsAndLabelsDF} \PY{o}{=} \PY{n}{cvModel}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{testSetDF}\PY{p}{)}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AT}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{V}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{RH}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{PE}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Predicted\PYZus{}PE}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Run the previously created RMSE evaluator, regEval, on the predictionsAndLabelsDF DataFrame}
\PY{n}{rmseNew} \PY{o}{=} \PY{n}{regEval}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{predictionsAndLabelsDF}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Now let\PYZsq{}s compute the r2 evaluation metric for our test dataset}
\PY{n}{r2New} \PY{o}{=} \PY{n}{regEval}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{predictionsAndLabelsDF}\PY{p}{,} \PY{p}{\PYZob{}}\PY{n}{regEval}\PY{o}{.}\PY{n}{metricName}\PY{p}{:} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{r2}\PY{l+s+s2}{\PYZdq{}}\PY{p}{\PYZcb{}}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Original Root Mean Squared Error: }\PY{l+s+si}{\PYZob{}0:2.2f\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{rmse}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{New Root Mean Squared Error: }\PY{l+s+si}{\PYZob{}0:2.2f\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{rmseNew}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Old r2: }\PY{l+s+si}{\PYZob{}0:2.2f\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{r2}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{New r2: }\PY{l+s+si}{\PYZob{}0:2.2f\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{r2New}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Original Root Mean Squared Error: 4.43
New Root Mean Squared Error: 4.43
Old r2: 0.93
New r2: 0.93
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{64}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} TEST}
\PY{n}{testmti850}\PY{o}{.}\PY{n}{Test}\PY{o}{.}\PY{n}{assertEquals}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{rmse}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,} \PY{l+m+mf}{4.43}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Incorrect value for rmse}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{testmti850}\PY{o}{.}\PY{n}{Test}\PY{o}{.}\PY{n}{assertEquals}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{rmseNew}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,} \PY{l+m+mf}{4.43}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Incorrect value for rmseNew}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{testmti850}\PY{o}{.}\PY{n}{Test}\PY{o}{.}\PY{n}{assertEquals}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{r2}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,} \PY{l+m+mf}{0.93}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Incorrect value for r2}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{testmti850}\PY{o}{.}\PY{n}{Test}\PY{o}{.}\PY{n}{assertEquals}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{r2New}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,} \PY{l+m+mf}{0.93}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Incorrect value for r2New}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
1 test passed.
1 test passed.
1 test passed.
1 test passed.
    \end{Verbatim}

    So our initial untuned and tuned linear regression models are
statistically identical. Let's look at the regularization parameter that
the
\href{https://spark.apache.org/docs/3.0.0/api/python/pyspark.ml.html?highlight=crossvalidator\#pyspark.ml.tuning.CrossValidator}{CrossValidator}
has selected.

Recall that the orginal regularization parameter we used was 0.01.

\textbf{NOTE}: The ML Python API currently doesn't provide a way to
query the regularization parameter, so we cheat, by ``reaching through''
to the JVM version of the API.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{65}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Regularization parameter of the best model: }\PY{l+s+si}{\PYZob{}0:.5f\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{cvModel}\PY{o}{.}\PY{n}{stages}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{\PYZus{}java\PYZus{}obj}\PY{o}{.}\PY{n}{parent}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{getRegParam}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Regularization parameter of the best model: 0.01000
    \end{Verbatim}

    Given that the only linearly correlated variable is Temperature, it
makes sense try another Machine Learning method such as
\href{https://en.wikipedia.org/wiki/Decision_tree_learning}{Decision
Tree} to handle non-linear data and see if we can improve our model.

\href{https://en.wikipedia.org/wiki/Decision_tree_learning}{Decision
Tree Learning} uses a
\href{https://en.wikipedia.org/wiki/Decision_tree}{Decision Tree} as a
predictive model which maps observations about an item to conclusions
about the item's target value. It is one of the predictive modelling
approaches used in statistics, data mining and machine learning.
Decision trees where the target variable can take continuous values
(typically real numbers) are called regression trees.

Spark ML Pipeline provides
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.DecisionTreeRegressor.html?highlight=decisiontreeregression}{DecisionTreeRegressor()}
as an implementation of
\href{https://en.wikipedia.org/wiki/Decision_tree_learning}{Decision
Tree Learning}.

The cell below is based on the
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.DecisionTreeRegressor.html?highlight=decisiontreeregression}{Spark
ML Pipeline API for Decision Tree Regressor}.

\hypertarget{exercise-7c}{%
\subsubsection{Exercise 7(c)}\label{exercise-7c}}

\begin{itemize}
\item
  Read the
  \href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.DecisionTreeRegressor.html?highlight=decisiontreeregression}{Decision
  Tree Regressor} documentation
\item
  In the next cell, create a
  \href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.DecisionTreeRegressor.html?highlight=decisiontreeregression}{DecisionTreeRegressor()}
\item
  The next step is to set the parameters for the method (we do this for
  you):

  \begin{itemize}
  \tightlist
  \item
    Set the name of the prediction column to ``Predicted\_PE''
  \item
    Set the name of the features column to ``features''
  \item
    Set the maximum number of bins to 100
  \end{itemize}
\item
  Create the
  \href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.Pipeline.html}{ML
  Pipeline} and set the stages to the Vectorizer we created earlier and
  \href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.DecisionTreeRegressor.html?highlight=decisiontreeregression}{DecisionTreeRegressor()}
  learner we just created.
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{97}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} TODO: Replace \PYZlt{}FILL\PYZus{}IN\PYZgt{} with the appropriate code.}
\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{regression}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{DecisionTreeRegressor}

\PY{c+c1}{\PYZsh{} Create a DecisionTreeRegressor}
\PY{n}{dt} \PY{o}{=} \PY{n}{DecisionTreeRegressor}\PY{p}{(}\PY{p}{)}

\PY{n}{dt}\PY{o}{.}\PY{n}{setLabelCol}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{PE}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PYZbs{}
    \PY{o}{.}\PY{n}{setPredictionCol}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Predicted\PYZus{}PE}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PYZbs{}
    \PY{o}{.}\PY{n}{setMaxBins}\PY{p}{(}\PY{l+m+mi}{100}\PY{p}{)}\PYZbs{}
    \PY{o}{.}\PY{n}{setFeaturesCol}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{features}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PYZbs{}
    \PY{c+c1}{\PYZsh{}.setSeed(1800009193) \PYZhy{}\PYZhy{}\PYZgt{} la seed n\PYZsq{}est pas indiquée dans l\PYZsq{}énoncé }

\PY{c+c1}{\PYZsh{} Create a Pipeline}
\PY{n}{dtPipeline} \PY{o}{=} \PY{n}{Pipeline}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Set the stages of the Pipeline}
\PY{n}{dtPipeline}\PY{o}{.}\PY{n}{setStages}\PY{p}{(}\PY{p}{[}\PY{n}{vectorizer}\PY{p}{,} \PY{n}{dt}\PY{p}{]}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{97}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
Pipeline\_3af91dd7b355
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{98}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} TEST}

\PY{n}{testmti850}\PY{o}{.}\PY{n}{Test}\PY{o}{.}\PY{n}{assertEqualsHashed}\PY{p}{(}\PY{n+nb}{str}\PY{p}{(}\PY{n}{dtPipeline}\PY{o}{.}\PY{n}{getStages}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n+nv+vm}{\PYZus{}\PYZus{}class\PYZus{}\PYZus{}}\PY{o}{.}\PY{n+nv+vm}{\PYZus{}\PYZus{}name\PYZus{}\PYZus{}}\PY{p}{)}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{4617be70bcf475326c0b07400b97b13457cc4949}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Incorrect pipeline stage 0}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{testmti850}\PY{o}{.}\PY{n}{Test}\PY{o}{.}\PY{n}{assertEqualsHashed}\PY{p}{(}\PY{n+nb}{str}\PY{p}{(}\PY{n}{dtPipeline}\PY{o}{.}\PY{n}{getStages}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n+nv+vm}{\PYZus{}\PYZus{}class\PYZus{}\PYZus{}}\PY{o}{.}\PY{n+nv+vm}{\PYZus{}\PYZus{}name\PYZus{}\PYZus{}}\PY{p}{)}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{46b18f257cf2f778d0d3b6e30ccc7b3398d7846a}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Incorrect pipeline stage 1}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
1 test passed.
1 test passed.
    \end{Verbatim}

    Instead of guessing what parameters to use, we will use
\href{https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html?highlight=tuning\#tuning}{Model
Selection} or
\href{https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html?highlight=tuning\#tuning}{Hyperparameter
Tuning} to create the best model.

We can reuse the exiting
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.CrossValidator.html\#pyspark.ml.tuning.CrossValidator}{CrossValidator}
by replacing the Estimator with our new \texttt{dtPipeline} (the number
of folds remains 3).

\hypertarget{exercise-7d}{%
\subsubsection{Exercise 7(d)}\label{exercise-7d}}

\begin{itemize}
\tightlist
\item
  Use
  \href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.ParamGridBuilder.html?highlight=paramgridbuilder\#pyspark.ml.tuning.ParamGridBuilder}{ParamGridBuilder}
  to build a parameter grid with the parameter \texttt{dt.maxDepth} and
  a list of the values 2 and 3, and add the grid to the
  \href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.CrossValidator.html\#pyspark.ml.tuning.CrossValidator}{CrossValidator}
\item
  Run the
  \href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.CrossValidator.html\#pyspark.ml.tuning.CrossValidator}{CrossValidator}
  to find the parameters that yield the best model (i.e.~lowest RMSE)
  and return the best model.
\end{itemize}

\emph{Note that it will take some time to run the
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.CrossValidator.html\#pyspark.ml.tuning.CrossValidator}{CrossValidator}
as it will run almost 50 Spark jobs}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{99}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} TODO: Replace \PYZlt{}FILL\PYZus{}IN\PYZgt{} with the appropriate code.}

\PY{c+c1}{\PYZsh{} Let\PYZsq{}s just reuse our CrossValidator with the new dtPipeline,  RegressionEvaluator regEval, and 3 fold cross validation}
\PY{n}{crossval}\PY{o}{.}\PY{n}{setEstimator}\PY{p}{(}\PY{n}{dtPipeline}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Let\PYZsq{}s tune over our dt.maxDepth parameter on the values 2 and 3, create a paramter grid using the ParamGridBuilder}
\PY{n}{maxDepth} \PY{o}{=} \PY{p}{[}\PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{]}

\PY{n}{paramGrid} \PY{o}{=} \PY{p}{(}\PY{n}{ParamGridBuilder}\PY{p}{(}\PY{p}{)}
             \PY{o}{.}\PY{n}{addGrid}\PY{p}{(}\PY{n}{dt}\PY{o}{.}\PY{n}{maxDepth}\PY{p}{,} \PY{n}{maxDepth}\PY{p}{)}
             \PY{o}{.}\PY{n}{build}\PY{p}{(}\PY{p}{)}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Add the grid to the CrossValidator}
\PY{n}{crossval}\PY{o}{.}\PY{n}{setEstimatorParamMaps}\PY{p}{(}\PY{n}{paramGrid}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Now let\PYZsq{}s find and return the best model}
\PY{n}{dtModel} \PY{o}{=} \PY{n}{crossval}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{trainingSetDF}\PY{p}{)}\PY{o}{.}\PY{n}{bestModel}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{100}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} TEST}

\PY{n}{testmti850}\PY{o}{.}\PY{n}{Test}\PY{o}{.}\PY{n}{assertEqualsHashed}\PY{p}{(}\PY{n+nb}{str}\PY{p}{(}\PY{n}{dtModel}\PY{o}{.}\PY{n}{stages}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n+nv+vm}{\PYZus{}\PYZus{}class\PYZus{}\PYZus{}}\PY{o}{.}\PY{n+nv+vm}{\PYZus{}\PYZus{}name\PYZus{}\PYZus{}}\PY{p}{)}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{4617be70bcf475326c0b07400b97b13457cc4949}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Incorrect pipeline stage 0}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{testmti850}\PY{o}{.}\PY{n}{Test}\PY{o}{.}\PY{n}{assertEqualsHashed}\PY{p}{(}\PY{n+nb}{str}\PY{p}{(}\PY{n}{dtModel}\PY{o}{.}\PY{n}{stages}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n+nv+vm}{\PYZus{}\PYZus{}class\PYZus{}\PYZus{}}\PY{o}{.}\PY{n+nv+vm}{\PYZus{}\PYZus{}name\PYZus{}\PYZus{}}\PY{p}{)}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{a2bf7b0c1a0fb9ad35650d0478ad51a9b880befa}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Incorrect pipeline stage 1}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
1 test passed.
1 test passed.
    \end{Verbatim}

    \hypertarget{exercise-7e}{%
\subsubsection{Exercise 7(e)}\label{exercise-7e}}

Now let's see how our tuned DecisionTreeRegressor model's RMSE and
\textbackslash(r\^{}2\textbackslash) values compare to our tuned
LinearRegression model.

Complete and run the next cell.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{101}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} TODO: Replace \PYZlt{}FILL\PYZus{}IN\PYZgt{} with the appropriate code.}

\PY{c+c1}{\PYZsh{} Now let\PYZsq{}s use dtModel to compute an evaluation metric for our test dataset: testSetDF}
\PY{n}{predictionsAndLabelsDF} \PY{o}{=} \PY{n}{dtModel}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{testSetDF}\PY{p}{)}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AT}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{V}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{RH}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{PE}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Predicted\PYZus{}PE}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Run the previously created RMSE evaluator, regEval, on the predictionsAndLabelsDF DataFrame}
\PY{n}{rmseDT} \PY{o}{=} \PY{n}{regEval}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{predictionsAndLabelsDF}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Now let\PYZsq{}s compute the r2 evaluation metric for our test dataset}
\PY{n}{r2DT} \PY{o}{=} \PY{n}{regEval}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{predictionsAndLabelsDF}\PY{p}{,} \PY{p}{\PYZob{}}\PY{n}{regEval}\PY{o}{.}\PY{n}{metricName}\PY{p}{:} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{r2}\PY{l+s+s2}{\PYZdq{}}\PY{p}{\PYZcb{}}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Linear Regression Root Mean Squared Error: }\PY{l+s+si}{\PYZob{}0:.2f\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{rmseNew}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Decision Tree Regressor Root Mean Squared Error: }\PY{l+s+si}{\PYZob{}0:.2f\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{rmseDT}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Linear Regression r2: }\PY{l+s+si}{\PYZob{}0:.2f\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{r2New}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Decision Tree Regressor r2: }\PY{l+s+si}{\PYZob{}0:.2f\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{r2DT}\PY{p}{)}\PY{p}{)}

\PY{c+c1}{\PYZsh{} pour cette question, étant donné que nous n\PYZsq{}avons pas la même seed que celle utilisée lors des tests, le test affiche une erreur}
\PY{c+c1}{\PYZsh{} d\PYZsq{}autres groupes ont eu le même probleme }
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Linear Regression Root Mean Squared Error: 4.43
Decision Tree Regressor Root Mean Squared Error: 5.11
Linear Regression r2: 0.93
Decision Tree Regressor r2: 0.91
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{102}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} TEST}
\PY{n}{testmti850}\PY{o}{.}\PY{n}{Test}\PY{o}{.}\PY{n}{assertEquals}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{rmseDT}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,} \PY{l+m+mf}{4.35}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Incorrect value for rmseDT}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{testmti850}\PY{o}{.}\PY{n}{Test}\PY{o}{.}\PY{n}{assertEquals}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{r2DT}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,} \PY{l+m+mf}{0.93}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Incorrect value for r2DT}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
1 test failed. Incorrect value for rmseDT
1 test failed. Incorrect value for r2DT
    \end{Verbatim}

    The line below will pull the Decision Tree model from the Pipeline and
display it as an if-then-else string. Again, we have to ``reach
through'' to the JVM API to make this one work.

\textbf{ToDo}: Run the next cell

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{103}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nb}{print}\PY{p}{(}\PY{n}{dtModel}\PY{o}{.}\PY{n}{stages}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{\PYZus{}java\PYZus{}obj}\PY{o}{.}\PY{n}{toDebugString}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
DecisionTreeRegressionModel: uid=DecisionTreeRegressor\_1c0f11236ff0, depth=3,
numNodes=15, numFeatures=4
  If (feature 0 <= 18.595)
   If (feature 0 <= 11.885000000000002)
    If (feature 0 <= 8.575)
     Predict: 483.994943457189
    Else (feature 0 > 8.575)
     Predict: 476.04374262101527
   Else (feature 0 > 11.885000000000002)
    If (feature 0 <= 15.475000000000001)
     Predict: 467.5564649956784
    Else (feature 0 > 15.475000000000001)
     Predict: 459.5010376134889
  Else (feature 0 > 18.595)
   If (feature 1 <= 66.21000000000001)
    If (feature 0 <= 22.055)
     Predict: 452.01076923076914
    Else (feature 0 > 22.055)
     Predict: 443.46937926330156
   Else (feature 1 > 66.21000000000001)
    If (feature 0 <= 25.325)
     Predict: 440.73731707317074
    Else (feature 0 > 25.325)
     Predict: 433.86131215469624

    \end{Verbatim}

    So our DecisionTree has slightly better RMSE than our LinearRegression
model (LR: 4.43 vs DT: 4.35). Maybe we can try an
\href{https://en.wikipedia.org/wiki/Ensemble_learning}{Ensemble
Learning} method such as
\href{https://en.wikipedia.org/wiki/Gradient_boosting}{Gradient-Boosted
Decision Trees} to see if we can strengthen our model by using an
ensemble of weaker trees with weighting to reduce the error in our
model.

\href{https://en.wikipedia.org/wiki/Random_forest}{Random forests} or
random decision tree forests are an ensemble learning method for
regression that operate by constructing a multitude of decision trees at
training time and outputting the class that is the mean prediction
(regression) of the individual trees. Random decision forests correct
for decision trees' habit of overfitting to their training set.

Spark ML Pipeline provides
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.RandomForestRegressor.html?highlight=randomforestregressor\#pyspark.ml.regression.RandomForestRegressor}{RandomForestRegressor()}
as an implementation of
\href{https://en.wikipedia.org/wiki/Random_forest}{Random forests}.

The cell below is based on the
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.RandomForestRegressor.html?highlight=randomforestregressor\#pyspark.ml.regression.RandomForestRegressor}{Spark
ML Pipeline API for Random Forest Regressor}.

\hypertarget{exercise-7f}{%
\subsubsection{Exercise 7(f)}\label{exercise-7f}}

\begin{itemize}
\tightlist
\item
  Read the
  \href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.RandomForestRegressor.html?highlight=randomforestregressor\#pyspark.ml.regression.RandomForestRegressor}{Random
  Forest Regressor} documentation
\item
  In the next cell, create a
  \href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.RandomForestRegressor.html?highlight=randomforestregressor\#pyspark.ml.regression.RandomForestRegressor}{RandomForestRegressor()}
\item
  The next step is to set the parameters for the method (we do this for
  you):

  \begin{itemize}
  \tightlist
  \item
    Set the name of the prediction column to ``Predicted\_PE''
  \item
    Set the name of the features column to ``features''
  \item
    Set the random number generator seed to 100088121
  \item
    Set the maximum depth to 8
  \item
    Set the number of trees to 30
  \end{itemize}
\item
  Create the
  \href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.Pipeline.html}{ML
  Pipeline} and set the stages to the Vectorizer we created earlier and
  \href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.RandomForestRegressor.html?highlight=randomforestregressor\#pyspark.ml.regression.RandomForestRegressor}{RandomForestRegressor()}
  learner we just created.
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{112}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} TODO: Replace \PYZlt{}FILL\PYZus{}IN\PYZgt{} with the appropriate code.}

\PY{k+kn}{from}\PY{+w}{ }\PY{n+nn}{pyspark}\PY{n+nn}{.}\PY{n+nn}{ml}\PY{n+nn}{.}\PY{n+nn}{regression}\PY{+w}{ }\PY{k+kn}{import} \PY{n}{RandomForestRegressor}

\PY{c+c1}{\PYZsh{} Create a RandomForestRegressor}
\PY{n}{rf} \PY{o}{=} \PY{n}{RandomForestRegressor}\PY{p}{(}\PY{p}{)} 

\PY{n}{rf}\PY{o}{.}\PY{n}{setPredictionCol}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Predicted\PYZus{}PE}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PYZbs{}
  \PY{o}{.}\PY{n}{setFeaturesCol}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{features}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PYZbs{}
  \PY{o}{.}\PY{n}{setSeed}\PY{p}{(}\PY{l+m+mi}{100088121}\PY{p}{)}\PYZbs{}
  \PY{o}{.}\PY{n}{setMaxDepth}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{)}\PYZbs{}
  \PY{o}{.}\PY{n}{setNumTrees}\PY{p}{(}\PY{l+m+mi}{30}\PY{p}{)}\PYZbs{}
  \PY{o}{.}\PY{n}{setLabelCol}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{PE}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Create a Pipeline}
\PY{n}{rfPipeline} \PY{o}{=} \PY{n}{Pipeline}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Set the stages of the Pipeline}
\PY{n}{rfPipeline}\PY{o}{.}\PY{n}{setStages}\PY{p}{(}\PY{p}{[}\PY{n}{vectorizer}\PY{p}{,} \PY{n}{rf}\PY{p}{]}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{112}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
Pipeline\_15ed2d199ea3
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{113}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} TEST}
\PY{n}{testmti850}\PY{o}{.}\PY{n}{Test}\PY{o}{.}\PY{n}{assertEqualsHashed}\PY{p}{(}\PY{n}{rfPipeline}\PY{o}{.}\PY{n}{getStages}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n+nv+vm}{\PYZus{}\PYZus{}class\PYZus{}\PYZus{}}\PY{o}{.}\PY{n+nv+vm}{\PYZus{}\PYZus{}name\PYZus{}\PYZus{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{4617be70bcf475326c0b07400b97b13457cc4949}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Stage 0 of pipeline is not correct}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{testmti850}\PY{o}{.}\PY{n}{Test}\PY{o}{.}\PY{n}{assertEqualsHashed}\PY{p}{(}\PY{n}{rfPipeline}\PY{o}{.}\PY{n}{getStages}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n+nv+vm}{\PYZus{}\PYZus{}class\PYZus{}\PYZus{}}\PY{o}{.}\PY{n+nv+vm}{\PYZus{}\PYZus{}name\PYZus{}\PYZus{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ecdcce2d075f00c97a6d2a2b8b1f66de322e57d2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Stage 1 of pipeline is not correct}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
1 test passed.
1 test passed.
    \end{Verbatim}

    As with Decision Trees, instead guessing what parameters to use, we will
use
\href{https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html?highlight=tuning\#tuning}{Model
Selection} or
\href{https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html?highlight=tuning\#tuning}{Hyperparameter
Tuning} to create the best model.

We can reuse the existing
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.CrossValidator.html\#pyspark.ml.tuning.CrossValidator}{CrossValidator}
by replacing the Estimator with our new \texttt{rfPipeline} (the number
of folds remains 3).

\hypertarget{exercise-7g}{%
\subsubsection{Exercise 7(g)}\label{exercise-7g}}

\begin{itemize}
\tightlist
\item
  Use
  \href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.ParamGridBuilder.html?highlight=paramgridbuilder\#pyspark.ml.tuning.ParamGridBuilder}{ParamGridBuilder}
  to build a parameter grid with the parameter \texttt{rf.maxBins} and a
  list of the values 50 and 100, and add the grid to the
  \href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.CrossValidator.html\#pyspark.ml.tuning.CrossValidator}{CrossValidator}
\item
  Run the
  \href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.CrossValidator.html\#pyspark.ml.tuning.CrossValidator}{CrossValidator}
  to find the parameters that yield the best model (i.e., lowest RMSE)
  and return the best model.
\end{itemize}

\emph{Note that it will take some time to run the
\href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.CrossValidator.html\#pyspark.ml.tuning.CrossValidator}{CrossValidator}
as it will run almost 100 Spark jobs, and each job takes longer to run
than the prior CrossValidator runs.}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{114}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} TODO: Replace \PYZlt{}FILL\PYZus{}IN\PYZgt{} with the appropriate code.}
\PY{c+c1}{\PYZsh{} Let\PYZsq{}s just reuse our CrossValidator with the new rfPipeline,  RegressionEvaluator regEval, and 3 fold cross validation}
\PY{n}{crossval}\PY{o}{.}\PY{n}{setEstimator}\PY{p}{(}\PY{n}{rfPipeline}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Let\PYZsq{}s tune over our rf.maxBins parameter on the values 50 and 100, create a parameter grid using the ParamGridBuilder}
\PY{n}{paramGrid} \PY{o}{=} \PY{p}{(}\PY{n}{ParamGridBuilder}\PY{p}{(}\PY{p}{)}
             \PY{o}{.}\PY{n}{addGrid}\PY{p}{(}\PY{n}{rf}\PY{o}{.}\PY{n}{maxBins}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{50}\PY{p}{,} \PY{l+m+mi}{100}\PY{p}{]}\PY{p}{)}
             \PY{o}{.}\PY{n}{build}\PY{p}{(}\PY{p}{)}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Add the grid to the CrossValidator}
\PY{n}{crossval}\PY{o}{.}\PY{n}{setEstimatorParamMaps}\PY{p}{(}\PY{n}{paramGrid}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Now let\PYZsq{}s find and return the best model}
\PY{n}{rfModel} \PY{o}{=} \PY{n}{crossval}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{trainingSetDF}\PY{p}{)}\PY{o}{.}\PY{n}{bestModel}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
25/10/06 23:53:38 WARN CacheManager: Asked to cache already cached data.
25/10/06 23:53:38 WARN CacheManager: Asked to cache already cached data.
25/10/06 23:53:39 WARN DAGScheduler: Broadcasting large task binary with size
1195.1 KiB
25/10/06 23:53:41 WARN DAGScheduler: Broadcasting large task binary with size
1195.4 KiB
25/10/06 23:53:43 WARN DAGScheduler: Broadcasting large task binary with size
1176.9 KiB
25/10/06 23:53:45 WARN DAGScheduler: Broadcasting large task binary with size
1187.0 KiB
25/10/06 23:53:47 WARN DAGScheduler: Broadcasting large task binary with size
1191.2 KiB
25/10/06 23:53:49 WARN DAGScheduler: Broadcasting large task binary with size
1196.3 KiB
25/10/06 23:53:50 WARN DAGScheduler: Broadcasting large task binary with size
1205.6 KiB
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{115}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} TEST}
\PY{n}{testmti850}\PY{o}{.}\PY{n}{Test}\PY{o}{.}\PY{n}{assertEqualsHashed}\PY{p}{(}\PY{n}{rfModel}\PY{o}{.}\PY{n}{stages}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n+nv+vm}{\PYZus{}\PYZus{}class\PYZus{}\PYZus{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{f0c3b910468d87808e019409e7ae5e587d6aca3d}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rfModel has incorrect stage 0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{testmti850}\PY{o}{.}\PY{n}{Test}\PY{o}{.}\PY{n}{assertEqualsHashed}\PY{p}{(}\PY{n}{rfModel}\PY{o}{.}\PY{n}{stages}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n+nv+vm}{\PYZus{}\PYZus{}class\PYZus{}\PYZus{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{0ed43512ea7e35ebeebeed3ddac0186248999a87}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rfModel has incorrect stage 1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
1 test passed.
1 test passed.
    \end{Verbatim}

    \hypertarget{exercise-7h}{%
\subsubsection{Exercise 7(h)}\label{exercise-7h}}

Now let's see how our tuned RandomForestRegressor model's RMSE and
\textbackslash(r\^{}2\textbackslash) values compare to our tuned
\texttt{LinearRegression} and tuned \texttt{DecisionTreeRegressor}
models.

Complete and run the next cell.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{116}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} TODO: Replace \PYZlt{}FILL\PYZus{}IN\PYZgt{} with the appropriate code.}

\PY{c+c1}{\PYZsh{} Now let\PYZsq{}s use rfModel to compute an evaluation metric for our test dataset: testSetDF}
\PY{n}{predictionsAndLabelsDF} \PY{o}{=} \PY{n}{rfModel}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{testSetDF}\PY{p}{)}\PY{o}{.}\PY{n}{select}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AT}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{V}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AP}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{RH}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{PE}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Predicted\PYZus{}PE}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Run the previously created RMSE evaluator, regEval, on the predictionsAndLabelsDF DataFrame}
\PY{n}{rmseRF} \PY{o}{=} \PY{n}{regEval}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{predictionsAndLabelsDF}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Now let\PYZsq{}s compute the r2 evaluation metric for our test dataset}
\PY{n}{r2RF} \PY{o}{=} \PY{n}{regEval}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{predictionsAndLabelsDF}\PY{p}{,} \PY{p}{\PYZob{}}\PY{n}{regEval}\PY{o}{.}\PY{n}{metricName}\PY{p}{:} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{r2}\PY{l+s+s2}{\PYZdq{}}\PY{p}{\PYZcb{}}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Linear Regression Root Mean Squared Error: }\PY{l+s+si}{\PYZob{}0:.2f\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{rmseNew}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Decision Tree Regressor Root Mean Squared Error: }\PY{l+s+si}{\PYZob{}0:.2f\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{rmseDT}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Random Forest Regressor Root Mean Squared Error: }\PY{l+s+si}{\PYZob{}0:.2f\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{rmseRF}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Linear Regression r2: }\PY{l+s+si}{\PYZob{}0:.2f\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{r2New}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Decision Tree Regressor r2: }\PY{l+s+si}{\PYZob{}0:.2f\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{r2DT}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Random Forest Regressor r2: }\PY{l+s+si}{\PYZob{}0:.2f\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{r2RF}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Linear Regression Root Mean Squared Error: 4.43
Decision Tree Regressor Root Mean Squared Error: 5.11
Random Forest Regressor Root Mean Squared Error: 3.61
Linear Regression r2: 0.93
Decision Tree Regressor r2: 0.91
Random Forest Regressor r2: 0.95
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{117}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} TEST}
\PY{n}{testmti850}\PY{o}{.}\PY{n}{Test}\PY{o}{.}\PY{n}{assertEquals}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{rmseRF}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,} \PY{l+m+mf}{3.61}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Incorrect value for rmseRF}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{testmti850}\PY{o}{.}\PY{n}{Test}\PY{o}{.}\PY{n}{assertEquals}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{r2RF}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,} \PY{l+m+mf}{0.95}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Incorrect value for r2RF}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
1 test passed.
1 test passed.
    \end{Verbatim}

    Note that the \texttt{r2} values are quite close for all three. However,
the RMSE for the Random Forest model is better.

    The line below will pull the Random Forest model from the Pipeline and
display it as an if-then-else string.

\textbf{ToDo}: Run the next cell

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nb}{print}\PY{p}{(}\PY{n}{rfModel}\PY{o}{.}\PY{n}{stages}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{\PYZus{}java\PYZus{}obj}\PY{o}{.}\PY{n}{toDebugString}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{end-of-the-assignment}{%
\subsection{End of the assignment}\label{end-of-the-assignment}}


    % Add a bibliography block to the postdoc
    
    
    
\end{document}
